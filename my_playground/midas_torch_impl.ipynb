{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda Available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if (torch.cuda.is_available()):\n",
    "    print(\"Cuda Available\")\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"Cuda not available\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/intel-isl_MiDaS_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights:  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master\n"
     ]
    },
    {
     "ename": "TracingCheckError",
     "evalue": "Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%self.1 : __torch__.midas.midas_net_custom.MidasNet_small,\n\t\t        %x.1 : Tensor):\n\t\t    %scratch : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %output_conv : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"output_conv\"](%scratch)\n\t\t    %scratch.17 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %refinenet1 : __torch__.midas.blocks.FeatureFusionBlock_custom = prim::GetAttr[name=\"refinenet1\"](%scratch.17)\n\t\t    %scratch.15 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %refinenet2 : __torch__.midas.blocks.FeatureFusionBlock_custom = prim::GetAttr[name=\"refinenet2\"](%scratch.15)\n\t\t    %scratch.13 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %refinenet3 : __torch__.midas.blocks.FeatureFusionBlock_custom = prim::GetAttr[name=\"refinenet3\"](%scratch.13)\n\t\t    %scratch.11 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %output_conv.1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"output_conv\"](%scratch.11)\n\t\t    %_3.9 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name=\"3\"](%output_conv.1)\n\t\t    %scratch.9 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %refinenet4 : __torch__.midas.blocks.FeatureFusionBlock_custom = prim::GetAttr[name=\"refinenet4\"](%scratch.9)\n\t\t    %scratch.7 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %layer4_rn : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"layer4_rn\"](%scratch.7)\n\t\t    %scratch.5 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %layer3_rn : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"layer3_rn\"](%scratch.5)\n\t\t    %scratch.3 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %layer2_rn : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"layer2_rn\"](%scratch.3)\n\t\t    %scratch.1 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %layer1_rn : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"layer1_rn\"](%scratch.1)\n\t\t    %pretrained : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"pretrained\"](%self.1)\n\t\t    %layer4 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"layer4\"](%pretrained)\n\t\t    %pretrained.5 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"pretrained\"](%self.1)\n\t\t    %layer3 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"layer3\"](%pretrained.5)\n\t\t    %pretrained.3 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"pretrained\"](%self.1)\n\t\t    %layer2 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"layer2\"](%pretrained.3)\n\t\t    %pretrained.1 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"pretrained\"](%self.1)\n\t\t    %layer1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"layer1\"](%pretrained.1)\n\t\t    %46 : int = prim::Constant[value=144](), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t    %47 : int = prim::Constant[value=192](), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %48 : int = prim::Constant[value=32](), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %49 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer1/__module.pretrained.layer1.2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t    %50 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer1/__module.pretrained.layer1.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %51 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer1/__module.pretrained.layer1.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %52 : int = prim::Constant[value=2](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %53 : int = prim::Constant[value=3](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %54 : Tensor = prim::Constant[value={-2}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %55 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %56 : int = prim::Constant[value=1](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %57 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %58 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %59 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?     ^^^\n\t\t+   %52 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?     ^^^                                                                                                   +++++++++++++++++++++++++++++++++\n\t\t+   %53 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %54 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %55 : Tensor = prim::Constant[value={0}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %60 : NoneType = prim::Constant(), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?     -\n\t\t+   %56 : NoneType = prim::Constant(), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    +\n\t\t+   %57 : int = prim::Constant[value=2](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t-   %61 : int = prim::Constant[value=0](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^\n\t\t+   %58 : int = prim::Constant[value=0](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^\n\t\t+   %59 : int = prim::Constant[value=1](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t-   %62 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?     ^^^\n\t\t+   %60 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?     ^^^\n\t\t-   %63 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?     ^^^\n\t\t+   %61 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?     ^^^\n\t\t    %_4.1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"4\"](%layer1)\n\t\t    %_3.1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"3\"](%layer1)\n\t\t    %_2.1 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"2\"](%layer1)\n\t\t    %_1.1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"1\"](%layer1)\n\t\t    %_0.1 : __torch__.geffnet.conv2d_layers.Conv2dSameExport = prim::GetAttr[name=\"0\"](%layer1)\n\t\t    %weight.329 : Tensor = prim::GetAttr[name=\"weight\"](%_0.1)\n\t\t+   %pad.1 : __torch__.torch.nn.modules.padding.ZeroPad2d = prim::GetAttr[name=\"pad\"](%_0.1)\n\t\t-   %70 : int = aten::size(%x.1, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.1 : Tensor = prim::NumToTensor(%70), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %72 : int = aten::size(%x.1, %53), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.3 : Tensor = prim::NumToTensor(%72), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %74 : int = aten::size(%weight.329, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.1 : Tensor = prim::NumToTensor(%74), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %76 : int = aten::size(%weight.329, %53), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.3 : Tensor = prim::NumToTensor(%76), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %78 : Tensor = aten::floor_divide(%i.1, %54), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %79 : Tensor = aten::neg(%78), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %80 : Tensor = aten::sub(%79, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %81 : Tensor = aten::mul(%80, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %82 : Tensor = aten::sub(%k.1, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %83 : Tensor = aten::mul(%82, %55), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %84 : Tensor = aten::add(%81, %83, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %85 : Tensor = aten::add(%84, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_h.1 : Tensor = aten::sub(%85, %i.1, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %87 : Tensor = aten::floor_divide(%i.3, %54), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %88 : Tensor = aten::neg(%87), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %89 : Tensor = aten::sub(%88, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %90 : Tensor = aten::mul(%89, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %91 : Tensor = aten::sub(%k.3, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %92 : Tensor = aten::mul(%91, %55), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %93 : Tensor = aten::add(%90, %92, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %94 : Tensor = aten::add(%93, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_w.1 : Tensor = aten::sub(%94, %i.3, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %96 : Tensor = aten::floor_divide(%pad_w.1, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %97 : int = aten::Int(%96), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?     -                    ^^\n\t\t+   %69 : int = aten::Int(%55), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad\n\t\t?    +                     ^^                                                                 +++++++++++++++++++++++++++++++++\n\t\t-   %98 : Tensor = aten::floor_divide(%pad_w.1, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %99 : Tensor = aten::sub(%pad_w.1, %98, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %100 : int = aten::Int(%99), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %101 : Tensor = aten::floor_divide(%pad_h.1, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %102 : int = aten::Int(%101), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %103 : Tensor = aten::floor_divide(%pad_h.1, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %104 : Tensor = aten::sub(%pad_h.1, %103, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %105 : int = aten::Int(%104), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    ^ -                    ^^\n\t\t+   %70 : int = aten::Int(%54), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad\n\t\t?    ^                     ^                                                                  +++++++++++++++++++++++++++++++++\n\t\t+   %71 : int = aten::Int(%55), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad\n\t\t+   %72 : int = aten::Int(%54), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad\n\t\t+   %73 : int[] = prim::ListConstruct(%69, %70, %71, %72), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad\n\t\t+   %x.3 : Tensor = aten::pad(%x.1, %73, %53, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %106 : int[] = prim::ListConstruct(%97, %100, %102, %105), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    ^^^                                ^    --------------\n\t\t+   %75 : int[] = prim::ListConstruct(%57, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    ^^                                ^     +\n\t\t-   %x.3 : Tensor = aten::pad(%x.1, %106, %58, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %76 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t+   %77 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %108 : int[] = prim::ListConstruct(%52, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    ^^                                  ^    ^\n\t\t+   %78 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    ^                                  ^    ^\n\t\t-   %109 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %110 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %111 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %input.1 : Tensor = aten::_convolution(%x.3, %weight.329, %60, %108, %109, %110, %62, %111, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                              ^^^^^^^    ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.1 : Tensor = aten::_convolution(%x.3, %weight.329, %56, %75, %76, %77, %60, %78, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^    ^    ^^^^^^^^^^^^^^^^^\n\t\t    %running_var.145 : Tensor = prim::GetAttr[name=\"running_var\"](%_1.1)\n\t\t    %running_mean.145 : Tensor = prim::GetAttr[name=\"running_mean\"](%_1.1)\n\t\t    %bias.187 : Tensor = prim::GetAttr[name=\"bias\"](%_1.1)\n\t\t    %weight.331 : Tensor = prim::GetAttr[name=\"weight\"](%_1.1)\n\t\t-   %input.3 : Tensor = aten::batch_norm(%input.1, %weight.331, %bias.187, %running_mean.145, %running_var.145, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                 -----     ^^   ^\n\t\t+   %input.3 : Tensor = aten::batch_norm(%input.1, %weight.331, %bias.187, %running_mean.145, %running_var.145, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                      ^^^^^^^   ^\n\t\t-   %input.5 : Tensor = aten::hardtanh_(%input.3, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                   ^\n\t\t+   %input.5 : Tensor = aten::hardtanh_(%input.3, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                   ^\n\t\t    %_0.3 : __torch__.geffnet.efficientnet_builder.DepthwiseSeparableConv = prim::GetAttr[name=\"0\"](%_3.1)\n\t\t    %act2.1 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"act2\"](%_0.3)\n\t\t    %bn2.1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.3)\n\t\t    %conv_pw.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.3)\n\t\t    %se.1 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.3)\n\t\t    %act1.1 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.3)\n\t\t    %bn1.1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.3)\n\t\t    %conv_dw.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_0.3)\n\t\t    %weight.333 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.1)\n\t\t-   %128 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t-   %129 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?    --                                  ^    ^\n\t\t+   %95 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?     +                                 ^    ^\n\t\t-   %130 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?    ^^^                                 ^    ^\n\t\t+   %96 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?    ^^                                 ^    ^\n\t\t-   %131 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?    ^^^                                ^^   ^^\n\t\t+   %97 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?    ^^                                ^^   ^^\n\t\t+   %98 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t-   %input.7 : Tensor = aten::_convolution(%input.5, %weight.333, %60, %128, %129, %130, %62, %131, %48, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                  ^^^^^^^  -----------------------        ^^^^^^^^^^^^^^^^\n\t\t+   %input.7 : Tensor = aten::_convolution(%input.5, %weight.333, %56, %95, %96, %97, %60, %98, %48, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^          ^^^^^^^^^^^^^^^^\n\t\t    %running_var.147 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.1)\n\t\t    %running_mean.147 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.1)\n\t\t    %bias.189 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.1)\n\t\t    %weight.335 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.1)\n\t\t-   %input.9 : Tensor = aten::batch_norm(%input.7, %weight.335, %bias.189, %running_mean.147, %running_var.147, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                 ^^             ^\n\t\t+   %input.9 : Tensor = aten::batch_norm(%input.7, %weight.335, %bias.189, %running_mean.147, %running_var.147, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                 ^^             ^\n\t\t-   %input.11 : Tensor = aten::hardtanh_(%input.9, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^\n\t\t+   %input.11 : Tensor = aten::hardtanh_(%input.9, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^\n\t\t    %weight.337 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.1)\n\t\t-   %140 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?     -                                  ^    ^\n\t\t+   %107 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?      +                                 ^    ^\n\t\t-   %141 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t-   %142 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?     ^^                                 ^    ^\n\t\t+   %108 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?     ^^                                 ^    ^\n\t\t-   %143 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?     ^^                                ^^   ^^\n\t\t+   %109 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?     ^^                                ^^   ^^\n\t\t+   %110 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t-   %input.13 : Tensor = aten::_convolution(%input.11, %weight.337, %60, %140, %141, %142, %62, %143, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                   ----------------------------------      ^^^^^^^^^^^^^^^^^\n\t\t+   %input.13 : Tensor = aten::_convolution(%input.11, %weight.337, %56, %107, %108, %109, %60, %110, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.149 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.1)\n\t\t    %running_mean.149 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.1)\n\t\t    %bias.191 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.1)\n\t\t    %weight.339 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.1)\n\t\t-   %input.15 : Tensor = aten::batch_norm(%input.13, %weight.339, %bias.191, %running_mean.149, %running_var.149, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.15 : Tensor = aten::batch_norm(%input.13, %weight.339, %bias.191, %running_mean.149, %running_var.149, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %_2.3 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"2\"](%_4.1)\n\t\t    %_1.3 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"1\"](%_4.1)\n\t\t    %_0.5 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_4.1)\n\t\t    %bn3.1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.5)\n\t\t    %conv_pwl.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.5)\n\t\t    %se.3 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.5)\n\t\t    %act2.3 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.5)\n\t\t    %bn2.3 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.5)\n\t\t    %conv_dw.3 : __torch__.geffnet.conv2d_layers.Conv2dSameExport = prim::GetAttr[name=\"conv_dw\"](%_0.5)\n\t\t    %act1.3 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.5)\n\t\t    %bn1.3 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.5)\n\t\t    %conv_pw.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.5)\n\t\t    %weight.341 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.3)\n\t\t-   %163 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?     -                                  ^    ^\n\t\t+   %130 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?      +                                 ^    ^\n\t\t-   %164 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t-   %165 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?     ^^                                 ^    ^\n\t\t+   %131 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?     ^^                                 ^    ^\n\t\t-   %166 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?     ^^                                ^^   ^^\n\t\t+   %132 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?     ^^                                ^^   ^^\n\t\t+   %133 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t-   %input.17 : Tensor = aten::_convolution(%input.15, %weight.341, %60, %163, %164, %165, %62, %166, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ------------------- ^^^^    ^^^^   ^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.17 : Tensor = aten::_convolution(%input.15, %weight.341, %56, %130, %131, %132, %60, %133, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                     ^^^^^^^^^^^^^^^^^^    ^^^^^^^^^   ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.151 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.3)\n\t\t    %running_mean.151 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.3)\n\t\t    %bias.193 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.3)\n\t\t    %weight.343 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.3)\n\t\t-   %input.19 : Tensor = aten::batch_norm(%input.17, %weight.343, %bias.193, %running_mean.151, %running_var.151, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^             ^\n\t\t+   %input.19 : Tensor = aten::batch_norm(%input.17, %weight.343, %bias.193, %running_mean.151, %running_var.151, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^             ^\n\t\t-   %x.5 : Tensor = aten::hardtanh_(%input.19, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                ^\n\t\t+   %x.5 : Tensor = aten::hardtanh_(%input.19, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                ^\n\t\t    %weight.345 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.3)\n\t\t+   %pad.3 : __torch__.torch.nn.modules.padding.ZeroPad2d = prim::GetAttr[name=\"pad\"](%conv_dw.3)\n\t\t-   %175 : int = aten::size(%x.5, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.5 : Tensor = prim::NumToTensor(%175), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %177 : int = aten::size(%x.5, %53), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.7 : Tensor = prim::NumToTensor(%177), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %179 : int = aten::size(%weight.345, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.5 : Tensor = prim::NumToTensor(%179), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %181 : int = aten::size(%weight.345, %53), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.7 : Tensor = prim::NumToTensor(%181), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %183 : Tensor = aten::floor_divide(%i.5, %54), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %184 : Tensor = aten::neg(%183), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %185 : Tensor = aten::sub(%184, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %186 : Tensor = aten::mul(%185, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %187 : Tensor = aten::sub(%k.5, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %188 : Tensor = aten::mul(%187, %55), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %189 : Tensor = aten::add(%186, %188, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %190 : Tensor = aten::add(%189, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_h.3 : Tensor = aten::sub(%190, %i.5, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %192 : Tensor = aten::floor_divide(%i.7, %54), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %193 : Tensor = aten::neg(%192), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %194 : Tensor = aten::sub(%193, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %195 : Tensor = aten::mul(%194, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %196 : Tensor = aten::sub(%k.7, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %197 : Tensor = aten::mul(%196, %55), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %198 : Tensor = aten::add(%195, %197, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %199 : Tensor = aten::add(%198, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_w.3 : Tensor = aten::sub(%199, %i.7, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %201 : Tensor = aten::floor_divide(%pad_w.3, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %202 : int = aten::Int(%201), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    ^^^^^^^^^              ^^^\n\t\t+   %143 : int = aten::Int(%55), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad\n\t\t?    ^^^^^^^^^              ^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t+   %144 : int = aten::Int(%54), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad\n\t\t-   %203 : Tensor = aten::floor_divide(%pad_w.3, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %204 : Tensor = aten::sub(%pad_w.3, %203, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %205 : int = aten::Int(%204), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    ^^                     ^^^\n\t\t+   %145 : int = aten::Int(%55), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad\n\t\t?    ^^                     ^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %206 : Tensor = aten::floor_divide(%pad_h.3, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %207 : int = aten::Int(%206), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    ^^^^^^^^^              ^^^\n\t\t+   %146 : int = aten::Int(%54), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad\n\t\t?    ^^^^^^^^^              ^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t+   %147 : int[] = prim::ListConstruct(%143, %144, %145, %146), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad\n\t\t+   %x.7 : Tensor = aten::pad(%x.5, %147, %53, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %208 : Tensor = aten::floor_divide(%pad_h.3, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %209 : Tensor = aten::sub(%pad_h.3, %208, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %210 : int = aten::Int(%209), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %211 : int[] = prim::ListConstruct(%202, %205, %207, %210), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %x.7 : Tensor = aten::pad(%x.5, %211, %58, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %213 : int[] = prim::ListConstruct(%52, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    - ^                                 ^    ^\n\t\t+   %149 : int[] = prim::ListConstruct(%57, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?     ^^                                 ^    ^\n\t\t-   %214 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %215 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    -                                   ^    ^\n\t\t+   %150 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?      +                                 ^    ^\n\t\t-   %216 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    - ^                                ^^   ^^\n\t\t+   %151 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?     ^^                                ^^   ^^\n\t\t+   %152 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %input.21 : Tensor = aten::_convolution(%x.7, %weight.345, %60, %213, %214, %215, %62, %216, %46, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                               ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.21 : Tensor = aten::_convolution(%x.7, %weight.345, %56, %149, %150, %151, %60, %152, %46, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.153 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.3)\n\t\t    %running_mean.153 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.3)\n\t\t    %bias.195 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.3)\n\t\t    %weight.347 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.3)\n\t\t-   %input.23 : Tensor = aten::batch_norm(%input.21, %weight.347, %bias.195, %running_mean.153, %running_var.153, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^^^^^^^^^^^   ^\n\t\t+   %input.23 : Tensor = aten::batch_norm(%input.21, %weight.347, %bias.195, %running_mean.153, %running_var.153, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^^^^^^^^^^^   ^\n\t\t-   %input.25 : Tensor = aten::hardtanh_(%input.23, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t+   %input.25 : Tensor = aten::hardtanh_(%input.23, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t    %weight.349 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.1)\n\t\t+   %161 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t-   %225 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?     --                                 ^    ^\n\t\t+   %162 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?    ++                                  ^    ^\n\t\t-   %226 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t-   %227 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?    ^^^                                 ^    ^\n\t\t+   %163 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?    ^^^                                 ^    ^\n\t\t-   %228 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?    ^^^                                ^^   ^^\n\t\t+   %164 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?    ^^^                                ^^   ^^\n\t\t-   %input.27 : Tensor = aten::_convolution(%input.25, %weight.349, %60, %225, %226, %227, %62, %228, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.27 : Tensor = aten::_convolution(%input.25, %weight.349, %56, %161, %162, %163, %60, %164, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.155 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.1)\n\t\t    %running_mean.155 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.1)\n\t\t    %bias.197 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.1)\n\t\t    %weight.351 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.1)\n\t\t-   %input.29 : Tensor = aten::batch_norm(%input.27, %weight.351, %bias.197, %running_mean.155, %running_var.155, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.29 : Tensor = aten::batch_norm(%input.27, %weight.351, %bias.197, %running_mean.155, %running_var.155, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %bn3.3 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_1.3)\n\t\t    %conv_pwl.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_1.3)\n\t\t    %se.5 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_1.3)\n\t\t    %act2.5 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_1.3)\n\t\t    %bn2.5 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.3)\n\t\t    %conv_dw.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_1.3)\n\t\t    %act1.5 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_1.3)\n\t\t    %bn1.5 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.3)\n\t\t    %conv_pw.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_1.3)\n\t\t    %weight.353 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.5)\n\t\t+   %181 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t-   %245 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?     --                                 ^    ^\n\t\t+   %182 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?    ++                                  ^    ^\n\t\t-   %246 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?    ^^^                                ^^   ^^\n\t\t+   %183 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?    ^^^                                ^^   ^^\n\t\t-   %247 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?    ^ -                                 ^    ^\n\t\t+   %184 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?    ^^                                  ^    ^\n\t\t-   %248 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t-   %input.31 : Tensor = aten::_convolution(%input.29, %weight.353, %60, %245, %246, %247, %62, %248, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                         ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.31 : Tensor = aten::_convolution(%input.29, %weight.353, %56, %181, %182, %183, %60, %184, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                   +++++++++++++++++++++++      ^^^^^^ ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.157 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.5)\n\t\t    %running_mean.157 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.5)\n\t\t    %bias.199 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.5)\n\t\t    %weight.355 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.5)\n\t\t-   %input.33 : Tensor = aten::batch_norm(%input.31, %weight.355, %bias.199, %running_mean.157, %running_var.157, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   -----     ^^   ^\n\t\t+   %input.33 : Tensor = aten::batch_norm(%input.31, %weight.355, %bias.199, %running_mean.157, %running_var.157, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                        ^^^^^^^   ^\n\t\t-   %input.35 : Tensor = aten::hardtanh_(%input.33, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t+   %input.35 : Tensor = aten::hardtanh_(%input.33, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t    %weight.357 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.5)\n\t\t-   %257 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t-   %258 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t-   %259 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t?    ^^                                  ^    ^\n\t\t+   %193 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t?    ^ +                                 ^    ^\n\t\t+   %194 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t+   %195 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t-   %260 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t?    ^ -                                ^^   ^^\n\t\t+   %196 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t?    ^^                                 ^^   ^^\n\t\t-   %input.37 : Tensor = aten::_convolution(%input.35, %weight.357, %60, %257, %258, %259, %62, %260, %47, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                         ^^    ------------------     ^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.37 : Tensor = aten::_convolution(%input.35, %weight.357, %56, %193, %194, %195, %60, %196, %47, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                   +++++++++++++++++++++++      ^^^^^^^         ^^^^^^^^^^^^\n\t\t    %running_var.159 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.5)\n\t\t    %running_mean.159 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.5)\n\t\t    %bias.201 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.5)\n\t\t    %weight.359 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.5)\n\t\t-   %input.39 : Tensor = aten::batch_norm(%input.37, %weight.359, %bias.201, %running_mean.159, %running_var.159, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.39 : Tensor = aten::batch_norm(%input.37, %weight.359, %bias.201, %running_mean.159, %running_var.159, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.41 : Tensor = aten::hardtanh_(%input.39, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t+   %input.41 : Tensor = aten::hardtanh_(%input.39, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t    %weight.361 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.3)\n\t\t+   %205 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t-   %269 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?      -                                 ^    ^\n\t\t+   %206 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?     +                                  ^    ^\n\t\t-   %270 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t-   %271 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?      -                                 ^    ^\n\t\t+   %207 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?     +                                  ^    ^\n\t\t-   %272 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?     ^^                                ^^   ^^\n\t\t+   %208 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?     ^^                                ^^   ^^\n\t\t-   %input.43 : Tensor = aten::_convolution(%input.41, %weight.361, %60, %269, %270, %271, %62, %272, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.43 : Tensor = aten::_convolution(%input.41, %weight.361, %56, %205, %206, %207, %60, %208, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.161 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.3)\n\t\t    %running_mean.161 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.3)\n\t\t    %bias.203 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.3)\n\t\t    %weight.363 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.3)\n\t\t-   %x.9 : Tensor = aten::batch_norm(%input.43, %weight.363, %bias.203, %running_mean.161, %running_var.161, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                              ^^             ^\n\t\t+   %x.9 : Tensor = aten::batch_norm(%input.43, %weight.363, %bias.203, %running_mean.161, %running_var.161, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                              ^^             ^\n\t\t-   %input.45 : Tensor = aten::add_(%x.9, %input.29, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                      ^\n\t\t+   %input.45 : Tensor = aten::add_(%x.9, %input.29, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                      ^\n\t\t    %bn3.5 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_2.3)\n\t\t    %conv_pwl.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_2.3)\n\t\t    %se.7 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_2.3)\n\t\t    %act2.7 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_2.3)\n\t\t    %bn2.7 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_2.3)\n\t\t    %conv_dw.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_2.3)\n\t\t    %act1.7 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_2.3)\n\t\t    %bn1.7 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_2.3)\n\t\t    %conv_pw.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_2.3)\n\t\t    %weight.365 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.7)\n\t\t-   %290 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t-   %291 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t-   %292 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t?     -                                  ^    ^\n\t\t+   %226 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t?      +                                 ^    ^\n\t\t+   %227 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t+   %228 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t-   %293 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t?      -                                ^^   ^^\n\t\t+   %229 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t?     +                                 ^^   ^^\n\t\t-   %input.47 : Tensor = aten::_convolution(%input.45, %weight.365, %60, %290, %291, %292, %62, %293, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.47 : Tensor = aten::_convolution(%input.45, %weight.365, %56, %226, %227, %228, %60, %229, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                   +++++++++++++++++++++++      +  +++++++++    ^^^^^^^^^^^^\n\t\t    %running_var.163 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.7)\n\t\t    %running_mean.163 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.7)\n\t\t    %bias.205 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.7)\n\t\t    %weight.367 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.7)\n\t\t-   %input.49 : Tensor = aten::batch_norm(%input.47, %weight.367, %bias.205, %running_mean.163, %running_var.163, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^             ^\n\t\t+   %input.49 : Tensor = aten::batch_norm(%input.47, %weight.367, %bias.205, %running_mean.163, %running_var.163, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^             ^\n\t\t-   %input.51 : Tensor = aten::hardtanh_(%input.49, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t+   %input.51 : Tensor = aten::hardtanh_(%input.49, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t    %weight.369 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.7)\n\t\t-   %302 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?     ^^                                 ^    ^\n\t\t+   %238 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    + ^                                 ^    ^\n\t\t-   %303 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?     ^^                                 ^    ^\n\t\t+   %239 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    + ^                                 ^    ^\n\t\t-   %304 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    ^ -                                 ^    ^\n\t\t+   %240 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    ^^                                  ^    ^\n\t\t-   %305 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    ^^^                                ^^   ^^\n\t\t+   %241 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    ^^^                                ^^   ^^\n\t\t-   %input.53 : Tensor = aten::_convolution(%input.51, %weight.369, %60, %302, %303, %304, %62, %305, %47, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ------------------------------ ^        ^^^^^^^^^^^^^^^^\n\t\t+   %input.53 : Tensor = aten::_convolution(%input.51, %weight.369, %56, %238, %239, %240, %60, %241, %47, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^        ^^^^^^^^^^^^^^^^\n\t\t    %running_var.165 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.7)\n\t\t    %running_mean.165 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.7)\n\t\t    %bias.207 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.7)\n\t\t    %weight.371 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.7)\n\t\t-   %input.55 : Tensor = aten::batch_norm(%input.53, %weight.371, %bias.207, %running_mean.165, %running_var.165, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   -----     ^^   ^\n\t\t+   %input.55 : Tensor = aten::batch_norm(%input.53, %weight.371, %bias.207, %running_mean.165, %running_var.165, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                        ^^^^^^^   ^\n\t\t-   %input.57 : Tensor = aten::hardtanh_(%input.55, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t+   %input.57 : Tensor = aten::hardtanh_(%input.55, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t    %weight.373 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.5)\n\t\t+   %250 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t-   %314 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?    ^ -                                 ^    ^\n\t\t+   %251 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?    ^^                                  ^    ^\n\t\t-   %315 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?    ^^                                 ^^   ^^\n\t\t+   %252 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?    ^ +                                ^^   ^^\n\t\t-   %316 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?     --                                 ^    ^\n\t\t+   %253 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?    ++                                  ^    ^\n\t\t+   %input.59 : Tensor = aten::_convolution(%input.57, %weight.373, %56, %250, %251, %252, %60, %253, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %317 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t-   %input.59 : Tensor = aten::_convolution(%input.57, %weight.373, %60, %314, %315, %316, %62, %317, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.167 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.5)\n\t\t    %running_mean.167 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.5)\n\t\t    %bias.209 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.5)\n\t\t    %weight.375 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.5)\n\t\t-   %x.11 : Tensor = aten::batch_norm(%input.59, %weight.375, %bias.209, %running_mean.167, %running_var.167, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.11 : Tensor = aten::batch_norm(%input.59, %weight.375, %bias.209, %running_mean.167, %running_var.167, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.61 : Tensor = aten::add_(%x.11, %input.45, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                       ^\n\t\t+   %input.61 : Tensor = aten::add_(%x.11, %input.45, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                       ^\n\t\t+   %261 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %262 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %263 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %264 : int = prim::Constant[value=2](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t-   %325 : int = prim::Constant[value=2](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t?    ^^                                                                                                                                                                                                                                                                       ^^\n\t\t+   %265 : int = prim::Constant[value=192](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^                               ++                                                                                                                                                                                                                                        ^^\n\t\t-   %326 : int = prim::Constant[value=3](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %327 : Tensor = prim::Constant[value={-2}](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %328 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %329 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %330 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %331 : int = prim::Constant[value=192](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t-   %332 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^\n\t\t+   %266 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^\n\t\t-   %333 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^\n\t\t+   %267 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^\n\t\t-   %334 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t+   %268 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t-   %335 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t+   %269 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t-   %336 : NoneType = prim::Constant(), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t?    ^^^\n\t\t+   %270 : NoneType = prim::Constant(), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t?    ^^^\n\t\t-   %337 : int = prim::Constant[value=1](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^ ^^^^^^\n\t\t+   %271 : int = prim::Constant[value=1](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^ ^^^^^^^\n\t\t-   %338 : int = prim::Constant[value=0](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t+   %272 : int = prim::Constant[value=0](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t-   %339 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^\n\t\t+   %273 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ++ ^^\n\t\t-   %340 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^ ^^^\n\t\t+   %274 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^ ^^\n\t\t-   %341 : int = prim::Constant[value=288](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t+   %275 : int = prim::Constant[value=288](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t    %_0.9 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"0\"](%layer2)\n\t\t    %_2.5 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"2\"](%_0.9)\n\t\t    %_1.5 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"1\"](%_0.9)\n\t\t    %_0.7 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_0.9)\n\t\t    %bn3.7 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.7)\n\t\t    %conv_pwl.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.7)\n\t\t    %se.9 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.7)\n\t\t    %act2.9 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.7)\n\t\t    %bn2.9 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.7)\n\t\t    %conv_dw.9 : __torch__.geffnet.conv2d_layers.Conv2dSameExport = prim::GetAttr[name=\"conv_dw\"](%_0.7)\n\t\t    %act1.9 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.7)\n\t\t    %bn1.9 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.7)\n\t\t    %conv_pw.9 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.7)\n\t\t    %weight.377 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.9)\n\t\t+   %290 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t+   %291 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t+   %292 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t-   %356 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t?     --                                ^^    ^^\n\t\t+   %293 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t?    ++                                 ^ +   ^ +\n\t\t-   %357 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t-   %358 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t-   %359 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t-   %input.63 : Tensor = aten::_convolution(%input.61, %weight.377, %336, %356, %357, %358, %339, %359, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^ ^^^^^^^^^^^ ^^^^^ ^^^^ ^^^^^ -\n\t\t+   %input.63 : Tensor = aten::_convolution(%input.61, %weight.377, %270, %290, %291, %292, %273, %293, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^ ^^^^^ ^^^^^ ^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^\n\t\t    %running_var.169 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.9)\n\t\t    %running_mean.169 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.9)\n\t\t    %bias.211 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.9)\n\t\t    %weight.379 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.9)\n\t\t-   %input.65 : Tensor = aten::batch_norm(%input.63, %weight.379, %bias.211, %running_mean.169, %running_var.169, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^    ^^ ------------\n\t\t+   %input.65 : Tensor = aten::batch_norm(%input.63, %weight.379, %bias.211, %running_mean.169, %running_var.169, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ++ ^^^^^^^^^^^    ^^\n\t\t-   %x.13 : Tensor = aten::hardtanh_(%input.65, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                ^^^   ^^^\n\t\t+   %x.13 : Tensor = aten::hardtanh_(%input.65, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                ^^^   ^^^\n\t\t    %weight.381 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.9)\n\t\t-   %368 : int = aten::size(%x.13, %325), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t+   %pad.5 : __torch__.torch.nn.modules.padding.ZeroPad2d = prim::GetAttr[name=\"pad\"](%conv_dw.9)\n\t\t-   %i.9 : Tensor = prim::NumToTensor(%368), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^^^^^^^^^^^   ^^^^^^^^^^^^^^^^^   --\n\t\t+   %303 : int = aten::Int(%263), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad\n\t\t?    ^^^^^^^^^   ^^^^^^^^^  ++                                                                                                                                        +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %370 : int = aten::size(%x.13, %326), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.11 : Tensor = prim::NumToTensor(%370), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %372 : int = aten::size(%weight.381, %325), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.9 : Tensor = prim::NumToTensor(%372), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^^^^^^^^^^^   ^^^^^^^^^^^^^^^^^  ^^\n\t\t+   %304 : int = aten::Int(%262), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad\n\t\t?    ^^^^^^^^^   ^^^^^^^^^  ^^                                                                                                                                        +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %374 : int = aten::size(%weight.381, %326), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.11 : Tensor = prim::NumToTensor(%374), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %376 : Tensor = aten::floor_divide(%i.9, %327), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %377 : Tensor = aten::neg(%376), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %378 : Tensor = aten::sub(%377, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %379 : Tensor = aten::mul(%378, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %380 : Tensor = aten::sub(%k.9, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %381 : Tensor = aten::mul(%380, %328), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %382 : Tensor = aten::add(%379, %381, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %383 : Tensor = aten::add(%382, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_h.5 : Tensor = aten::sub(%383, %i.9, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %385 : Tensor = aten::floor_divide(%i.11, %327), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %386 : Tensor = aten::neg(%385), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %387 : Tensor = aten::sub(%386, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %388 : Tensor = aten::mul(%387, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %389 : Tensor = aten::sub(%k.11, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %390 : Tensor = aten::mul(%389, %328), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %391 : Tensor = aten::add(%388, %390, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %392 : Tensor = aten::add(%391, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_w.5 : Tensor = aten::sub(%392, %i.11, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %394 : Tensor = aten::floor_divide(%pad_w.5, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %395 : int = aten::Int(%394), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?     ^                      --\n\t\t+   %305 : int = aten::Int(%263), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad\n\t\t?     ^                     ++                                                                                                                                        +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %396 : Tensor = aten::floor_divide(%pad_w.5, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %397 : Tensor = aten::sub(%pad_w.5, %396, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %398 : int = aten::Int(%397), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %399 : Tensor = aten::floor_divide(%pad_h.5, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %400 : int = aten::Int(%399), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %401 : Tensor = aten::floor_divide(%pad_h.5, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %402 : Tensor = aten::sub(%pad_h.5, %401, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %403 : int = aten::Int(%402), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    -- ^^^^^^              ^^\n\t\t+   %306 : int = aten::Int(%262), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad\n\t\t?     ^^^^^^^^              ^^                                                                                                                                        +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %404 : int[] = prim::ListConstruct(%395, %398, %400, %403), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^^^^                               ^     ^^^^^^^^^^^^^^\n\t\t+   %307 : int[] = prim::ListConstruct(%303, %304, %305, %306), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad\n\t\t?    ^^^^^                               ^^^^^^^^^^^^^     ^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %x.15 : Tensor = aten::pad(%x.13, %404, %330, %332), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?                                      ^^^   ^^^   ^^^\n\t\t+   %x.15 : Tensor = aten::pad(%x.13, %307, %261, %266), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?                                      ^^^   ^^^   ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %406 : int[] = prim::ListConstruct(%325, %325), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^ ^                                - ^   - ^\n\t\t+   %309 : int[] = prim::ListConstruct(%264, %264), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^ ^                                 ^^    ^^\n\t\t-   %407 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %408 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^ -                                ^^    ^^\n\t\t+   %310 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^                                 ^ +   ^ +\n\t\t-   %409 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^^                                ^^^   ^^^\n\t\t+   %311 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^^                                ^^^   ^^^\n\t\t+   %312 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %input.67 : Tensor = aten::_convolution(%x.15, %weight.381, %336, %406, %407, %408, %339, %409, %331, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                ^^ ^^^ ^^^^^ --------------------------------------------------\n\t\t+   %input.67 : Tensor = aten::_convolution(%x.15, %weight.381, %270, %309, %310, %311, %273, %312, %265, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^ ^^^^^\n\t\t    %running_var.171 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.9)\n\t\t    %running_mean.171 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.9)\n\t\t    %bias.213 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.9)\n\t\t    %weight.383 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.9)\n\t\t-   %input.69 : Tensor = aten::batch_norm(%input.67, %weight.383, %bias.213, %running_mean.171, %running_var.171, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ^^    ^^ ------------\n\t\t+   %input.69 : Tensor = aten::batch_norm(%input.67, %weight.383, %bias.213, %running_mean.171, %running_var.171, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ^^^^^^^^^^^^^^    ^^\n\t\t-   %input.71 : Tensor = aten::hardtanh_(%input.69, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t+   %input.71 : Tensor = aten::hardtanh_(%input.69, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t    %weight.385 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.7)\n\t\t-   %418 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^ -                                ^^    ^^\n\t\t+   %321 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^^                                 ^ +   ^ +\n\t\t-   %419 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t-   %420 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %322 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %421 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %323 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %324 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t-   %input.73 : Tensor = aten::_convolution(%input.71, %weight.385, %336, %418, %419, %420, %339, %421, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^  ^^^^ ^^^^^ --------------------------------------------\n\t\t+   %input.73 : Tensor = aten::_convolution(%input.71, %weight.385, %270, %321, %322, %323, %273, %324, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ +++++ ^^^^^^^^^^^^^^^^^ ^^^^^\n\t\t    %running_var.173 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.7)\n\t\t    %running_mean.173 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.7)\n\t\t    %bias.215 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.7)\n\t\t    %weight.387 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.7)\n\t\t-   %input.75 : Tensor = aten::batch_norm(%input.73, %weight.387, %bias.215, %running_mean.173, %running_var.173, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ^^    ^^ ------------\n\t\t+   %input.75 : Tensor = aten::batch_norm(%input.73, %weight.387, %bias.215, %running_mean.173, %running_var.173, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ^^^^^^^^^^^^^^    ^^\n\t\t    %bn3.9 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_1.5)\n\t\t    %conv_pwl.9 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_1.5)\n\t\t    %se.11 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_1.5)\n\t\t    %act2.11 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_1.5)\n\t\t    %bn2.11 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.5)\n\t\t    %conv_dw.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_1.5)\n\t\t    %act1.11 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_1.5)\n\t\t    %bn1.11 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.5)\n\t\t    %conv_pw.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_1.5)\n\t\t    %weight.389 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.11)\n\t\t+   %341 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t+   %342 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t-   %438 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t?      -                                ^^    ^^\n\t\t+   %343 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t?    +                                  ^ +   ^ +\n\t\t-   %439 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t-   %440 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t?      -                                ^^    ^^\n\t\t+   %344 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t?    +                                  ^ +   ^ +\n\t\t-   %441 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t-   %input.77 : Tensor = aten::_convolution(%input.75, %weight.389, %336, %438, %439, %440, %339, %441, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.77 : Tensor = aten::_convolution(%input.75, %weight.389, %270, %341, %342, %343, %273, %344, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.175 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.11)\n\t\t    %running_mean.175 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.11)\n\t\t    %bias.217 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.11)\n\t\t    %weight.391 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.11)\n\t\t-   %input.79 : Tensor = aten::batch_norm(%input.77, %weight.391, %bias.217, %running_mean.175, %running_var.175, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^    ^^ ^^^^^^^^^^^ ------------------------------------                                                            -------------------------------\n\t\t+   %input.79 : Tensor = aten::batch_norm(%input.77, %weight.391, %bias.217, %running_mean.175, %running_var.175, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ++ ^^^^^^^^^^^    ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                              ++\n\t\t-   %input.81 : Tensor = aten::hardtanh_(%input.79, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t+   %input.81 : Tensor = aten::hardtanh_(%input.79, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t    %weight.393 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.11)\n\t\t-   %450 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %353 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %451 : int[] = prim::ListConstruct(%325, %325), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?     --                                - ^   - ^\n\t\t+   %354 : int[] = prim::ListConstruct(%264, %264), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ++                                  ^^    ^^\n\t\t-   %452 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %355 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %453 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %356 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t-   %input.83 : Tensor = aten::_convolution(%input.81, %weight.393, %336, %450, %451, %452, %339, %453, %341, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.83 : Tensor = aten::_convolution(%input.81, %weight.393, %270, %353, %354, %355, %273, %356, %275, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.177 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.11)\n\t\t    %running_mean.177 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.11)\n\t\t    %bias.219 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.11)\n\t\t    %weight.395 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.11)\n\t\t-   %input.85 : Tensor = aten::batch_norm(%input.83, %weight.395, %bias.219, %running_mean.177, %running_var.177, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^    ^^ ^^^^^^^^^^^ ------------------------------------                                                            -------------------------------\n\t\t+   %input.85 : Tensor = aten::batch_norm(%input.83, %weight.395, %bias.219, %running_mean.177, %running_var.177, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ++ ^^^^^^^^^^^    ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                              ++\n\t\t-   %input.87 : Tensor = aten::hardtanh_(%input.85, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t+   %input.87 : Tensor = aten::hardtanh_(%input.85, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t    %weight.397 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.9)\n\t\t-   %462 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %365 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %463 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t-   %464 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %366 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %465 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %367 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %368 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t-   %input.89 : Tensor = aten::_convolution(%input.87, %weight.397, %336, %462, %463, %464, %339, %465, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^ ^^^^^ --------------------------------------------------\n\t\t+   %input.89 : Tensor = aten::_convolution(%input.87, %weight.397, %270, %365, %366, %367, %273, %368, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^\n\t\t    %running_var.179 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.9)\n\t\t    %running_mean.179 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.9)\n\t\t    %bias.221 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.9)\n\t\t    %weight.399 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.9)\n\t\t-   %x.17 : Tensor = aten::batch_norm(%input.89, %weight.399, %bias.221, %running_mean.179, %running_var.179, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.17 : Tensor = aten::batch_norm(%input.89, %weight.399, %bias.221, %running_mean.179, %running_var.179, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.91 : Tensor = aten::add_(%x.17, %input.75, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                      ^^\n\t\t+   %input.91 : Tensor = aten::add_(%x.17, %input.75, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                      ^ +\n\t\t    %bn3.11 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_2.5)\n\t\t    %conv_pwl.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_2.5)\n\t\t    %se.13 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_2.5)\n\t\t    %act2.13 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_2.5)\n\t\t    %bn2.13 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_2.5)\n\t\t    %conv_dw.13 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_2.5)\n\t\t    %act1.13 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_2.5)\n\t\t    %bn1.13 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_2.5)\n\t\t    %conv_pw.13 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_2.5)\n\t\t    %weight.401 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.13)\n\t\t-   %483 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %386 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %484 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t-   %485 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %387 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %486 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %388 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %389 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t-   %input.93 : Tensor = aten::_convolution(%input.91, %weight.401, %336, %483, %484, %485, %339, %486, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^     ^^^^^ --------------------------------------------------\n\t\t+   %input.93 : Tensor = aten::_convolution(%input.91, %weight.401, %270, %386, %387, %388, %273, %389, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^    ++++++++++++++++++++++++++++++++++++++++++++ ^^^^^\n\t\t    %running_var.181 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.13)\n\t\t    %running_mean.181 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.13)\n\t\t    %bias.223 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.13)\n\t\t    %weight.403 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.13)\n\t\t-   %input.95 : Tensor = aten::batch_norm(%input.93, %weight.403, %bias.223, %running_mean.181, %running_var.181, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.95 : Tensor = aten::batch_norm(%input.93, %weight.403, %bias.223, %running_mean.181, %running_var.181, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.97 : Tensor = aten::hardtanh_(%input.95, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t+   %input.97 : Tensor = aten::hardtanh_(%input.95, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t    %weight.405 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.13)\n\t\t-   %495 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %398 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %496 : int[] = prim::ListConstruct(%325, %325), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?    ^ ^                                - ^   - ^\n\t\t+   %399 : int[] = prim::ListConstruct(%264, %264), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?    ^ ^                                 ^^    ^^\n\t\t-   %497 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?     ^^                                ^^    ^^\n\t\t+   %400 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?     ^^                                ^ +   ^ +\n\t\t-   %498 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?     ^^                                ^^^   ^^^\n\t\t+   %401 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?     ^^                                ^^^   ^^^\n\t\t-   %input.99 : Tensor = aten::_convolution(%input.97, %weight.405, %336, %495, %496, %497, %339, %498, %341, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.99 : Tensor = aten::_convolution(%input.97, %weight.405, %270, %398, %399, %400, %273, %401, %275, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.183 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.13)\n\t\t    %running_mean.183 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.13)\n\t\t    %bias.225 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.13)\n\t\t    %weight.407 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.13)\n\t\t-   %input.101 : Tensor = aten::batch_norm(%input.99, %weight.407, %bias.225, %running_mean.183, %running_var.183, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.101 : Tensor = aten::batch_norm(%input.99, %weight.407, %bias.225, %running_mean.183, %running_var.183, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.103 : Tensor = aten::hardtanh_(%input.101, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.103 : Tensor = aten::hardtanh_(%input.101, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.409 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.11)\n\t\t-   %507 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^ -                                ^^    ^^\n\t\t+   %410 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^^                                 ^ +   ^ +\n\t\t-   %508 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t-   %509 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^^^                                ^^    ^^\n\t\t+   %411 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^^^                                ^ +   ^ +\n\t\t-   %510 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %412 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %413 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t-   %input.105 : Tensor = aten::_convolution(%input.103, %weight.409, %336, %507, %508, %509, %339, %510, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.105 : Tensor = aten::_convolution(%input.103, %weight.409, %270, %410, %411, %412, %273, %413, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.185 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.11)\n\t\t    %running_mean.185 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.11)\n\t\t    %bias.227 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.11)\n\t\t    %weight.411 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.11)\n\t\t-   %x.19 : Tensor = aten::batch_norm(%input.105, %weight.411, %bias.227, %running_mean.185, %running_var.185, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.19 : Tensor = aten::batch_norm(%input.105, %weight.411, %bias.227, %running_mean.185, %running_var.185, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.107 : Tensor = aten::add_(%x.19, %input.91, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                       ^^\n\t\t+   %input.107 : Tensor = aten::add_(%x.19, %input.91, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                       ^ +\n\t\t-   %518 : int = prim::Constant[value=816](), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t+   %421 : int = prim::Constant[value=816](), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t+   %422 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %423 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %424 : Tensor = prim::Constant[value={0}](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %519 : int = prim::Constant[value=2](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t?     ^^^^^^^^                                                                                                                                                                                                                                                                ^^\n\t\t+   %425 : int = prim::Constant[value=2](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ++ ^^^^^^                                                                                                                                                                                                                                                                ^^\n\t\t-   %520 : int = prim::Constant[value=3](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %521 : Tensor = prim::Constant[value={-2}](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %522 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %523 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %524 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %525 : int = prim::Constant[value=288](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^^\n\t\t+   %426 : int = prim::Constant[value=288](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^^\n\t\t-   %526 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t-   %527 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^                                  ^\n\t\t+   %427 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^                                  ^\n\t\t+   %428 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t-   %528 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^ ^^^\n\t\t+   %429 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^ ^^^\n\t\t-   %529 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t+   %430 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t-   %530 : NoneType = prim::Constant(), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^ ^\n\t\t+   %431 : NoneType = prim::Constant(), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^ ^\n\t\t-   %531 : int = prim::Constant[value=1](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %532 : int = prim::Constant[value=0](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^                                ^\n\t\t+   %432 : int = prim::Constant[value=1](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^                                ^\n\t\t+   %433 : int = prim::Constant[value=0](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %533 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^\n\t\t+   %434 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^\n\t\t-   %534 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^\n\t\t+   %435 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ++ ^^\n\t\t-   %535 : int = prim::Constant[value=576](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t+   %436 : int = prim::Constant[value=576](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t    %_1.11 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"1\"](%layer3)\n\t\t    %_0.13 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"0\"](%layer3)\n\t\t    %_4.3 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"4\"](%_0.13)\n\t\t    %_3.3 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"3\"](%_0.13)\n\t\t    %_2.7 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"2\"](%_0.13)\n\t\t    %_1.7 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"1\"](%_0.13)\n\t\t    %_0.11 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_0.13)\n\t\t    %bn3.13 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.11)\n\t\t    %conv_pwl.13 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.11)\n\t\t    %se.15 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.11)\n\t\t    %act2.15 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.11)\n\t\t    %bn2.15 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.11)\n\t\t    %conv_dw.15 : __torch__.geffnet.conv2d_layers.Conv2dSameExport = prim::GetAttr[name=\"conv_dw\"](%_0.11)\n\t\t    %act1.15 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.11)\n\t\t    %bn1.15 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.11)\n\t\t    %conv_pw.15 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.11)\n\t\t    %weight.413 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.15)\n\t\t-   %553 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t-   %554 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^                                  ^     ^\n\t\t+   %454 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^                                  ^     ^\n\t\t-   %555 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?      -                                ^ ^   ^ ^\n\t\t+   %455 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    +                                  ^ ^   ^ ^\n\t\t-   %556 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^                                  ^     ^\n\t\t+   %456 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^                                  ^     ^\n\t\t+   %457 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t-   %input.109 : Tensor = aten::_convolution(%input.107, %weight.413, %530, %553, %554, %555, %533, %556, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.109 : Tensor = aten::_convolution(%input.107, %weight.413, %431, %454, %455, %456, %434, %457, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.187 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.15)\n\t\t    %running_mean.187 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.15)\n\t\t    %bias.229 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.15)\n\t\t    %weight.415 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.15)\n\t\t-   %input.111 : Tensor = aten::batch_norm(%input.109, %weight.415, %bias.229, %running_mean.187, %running_var.187, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.111 : Tensor = aten::batch_norm(%input.109, %weight.415, %bias.229, %running_mean.187, %running_var.187, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %x.21 : Tensor = aten::hardtanh_(%input.111, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                 ^^^   ^^^\n\t\t+   %x.21 : Tensor = aten::hardtanh_(%input.111, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                 ^^^   ^^^\n\t\t    %weight.417 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.15)\n\t\t+   %pad.7 : __torch__.torch.nn.modules.padding.ZeroPad2d = prim::GetAttr[name=\"pad\"](%conv_dw.15)\n\t\t-   %565 : int = aten::size(%x.21, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.13 : Tensor = prim::NumToTensor(%565), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %567 : int = aten::size(%x.21, %520), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.15 : Tensor = prim::NumToTensor(%567), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %569 : int = aten::size(%weight.417, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.13 : Tensor = prim::NumToTensor(%569), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %571 : int = aten::size(%weight.417, %520), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.15 : Tensor = prim::NumToTensor(%571), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %573 : Tensor = aten::floor_divide(%i.13, %521), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %574 : Tensor = aten::neg(%573), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %575 : Tensor = aten::sub(%574, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %576 : Tensor = aten::mul(%575, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %577 : Tensor = aten::sub(%k.13, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %578 : Tensor = aten::mul(%577, %522), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %579 : Tensor = aten::add(%576, %578, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %580 : Tensor = aten::add(%579, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_h.7 : Tensor = aten::sub(%580, %i.13, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %582 : Tensor = aten::floor_divide(%i.15, %521), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %583 : Tensor = aten::neg(%582), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %584 : Tensor = aten::sub(%583, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %585 : Tensor = aten::mul(%584, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %586 : Tensor = aten::sub(%k.15, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %587 : Tensor = aten::mul(%586, %522), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %588 : Tensor = aten::add(%585, %587, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %589 : Tensor = aten::add(%588, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_w.7 : Tensor = aten::sub(%589, %i.15, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %591 : Tensor = aten::floor_divide(%pad_w.7, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %592 : int = aten::Int(%591), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %593 : Tensor = aten::floor_divide(%pad_w.7, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %594 : Tensor = aten::sub(%pad_w.7, %593, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %595 : int = aten::Int(%594), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %596 : Tensor = aten::floor_divide(%pad_h.7, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %597 : int = aten::Int(%596), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    ^^                     ^^^\n\t\t+   %467 : int = aten::Int(%424), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad\n\t\t?    ^^                     ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %598 : Tensor = aten::floor_divide(%pad_h.7, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %599 : Tensor = aten::sub(%pad_h.7, %598, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %600 : int = aten::Int(%599), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?     ^^^^^^^^              ^^^\n\t\t+   %468 : int = aten::Int(%423), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad\n\t\t?    + ^^^^^^^              ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t+   %469 : int = aten::Int(%424), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad\n\t\t+   %470 : int = aten::Int(%423), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad\n\t\t-   %601 : int[] = prim::ListConstruct(%592, %595, %597, %600), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    ^^                                 ^ ^^^^^^^^^^^^ -----\n\t\t+   %471 : int[] = prim::ListConstruct(%467, %468, %469, %470), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad\n\t\t?    ^^                                 ^^^^^^^^^^^^^^ ^^^^                                                                                                                                         +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %x.23 : Tensor = aten::pad(%x.21, %601, %524, %526), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?                                      ^^    ^^^   ^^^\n\t\t+   %x.23 : Tensor = aten::pad(%x.21, %471, %422, %427), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?                                      ^^    ^^^   ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %603 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    ^^                                  --    --\n\t\t+   %473 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    ^^                                 ++    ++\n\t\t+   %474 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %604 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    --                                 ^     ^\n\t\t+   %475 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?     ++                                ^     ^\n\t\t-   %605 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?     --                                ^ ^   ^ ^\n\t\t+   %476 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    ++                                 ^ ^   ^ ^\n\t\t-   %606 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %input.113 : Tensor = aten::_convolution(%x.23, %weight.417, %530, %603, %604, %605, %533, %606, %525, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                  ^^^^^ ^^^^^ ^^^^^^^     --------------------------------------\n\t\t+   %input.113 : Tensor = aten::_convolution(%x.23, %weight.417, %431, %473, %474, %475, %434, %476, %426, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                 ++++++++++++++++++++ ^^^^^^^^^^^ ^^^^^ ^^^^^^^^^^^^^^^^^    ++\n\t\t    %running_var.189 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.15)\n\t\t    %running_mean.189 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.15)\n\t\t    %bias.231 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.15)\n\t\t    %weight.419 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.15)\n\t\t-   %input.115 : Tensor = aten::batch_norm(%input.113, %weight.419, %bias.231, %running_mean.189, %running_var.189, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.115 : Tensor = aten::batch_norm(%input.113, %weight.419, %bias.231, %running_mean.189, %running_var.189, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.117 : Tensor = aten::hardtanh_(%input.115, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.117 : Tensor = aten::hardtanh_(%input.115, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.421 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.13)\n\t\t-   %615 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t-   %616 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t-   %617 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t-   %618 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t?    ^^                                 ^     ^\n\t\t+   %485 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t?    ^ +                                ^     ^\n\t\t+   %486 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t+   %487 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t+   %488 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t-   %input.119 : Tensor = aten::_convolution(%input.117, %weight.421, %530, %615, %616, %617, %533, %618, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ^^^^^ ^    ^^^^^^^^^^^^ --------------------------------------\n\t\t+   %input.119 : Tensor = aten::_convolution(%input.117, %weight.421, %431, %485, %486, %487, %434, %488, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ++++++++ ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^\n\t\t    %running_var.191 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.13)\n\t\t    %running_mean.191 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.13)\n\t\t    %bias.233 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.13)\n\t\t    %weight.423 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.13)\n\t\t-   %input.121 : Tensor = aten::batch_norm(%input.119, %weight.423, %bias.233, %running_mean.191, %running_var.191, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.121 : Tensor = aten::batch_norm(%input.119, %weight.423, %bias.233, %running_mean.191, %running_var.191, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %bn3.15 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_1.7)\n\t\t    %conv_pwl.15 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_1.7)\n\t\t    %se.17 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_1.7)\n\t\t    %act2.17 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_1.7)\n\t\t    %bn2.17 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.7)\n\t\t    %conv_dw.17 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_1.7)\n\t\t    %act1.17 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_1.7)\n\t\t    %bn1.17 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.7)\n\t\t    %conv_pw.17 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_1.7)\n\t\t    %weight.425 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.17)\n\t\t-   %635 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t-   %636 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %505 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %637 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?     --                                ^ ^   ^ ^\n\t\t+   %506 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?    ++                                 ^ ^   ^ ^\n\t\t-   %638 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %507 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %input.123 : Tensor = aten::_convolution(%input.121, %weight.425, %530, %635, %636, %637, %533, %638, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %508 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t+   %input.123 : Tensor = aten::_convolution(%input.121, %weight.425, %431, %505, %506, %507, %434, %508, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.193 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.17)\n\t\t    %running_mean.193 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.17)\n\t\t    %bias.235 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.17)\n\t\t    %weight.427 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.17)\n\t\t-   %input.125 : Tensor = aten::batch_norm(%input.123, %weight.427, %bias.235, %running_mean.193, %running_var.193, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.125 : Tensor = aten::batch_norm(%input.123, %weight.427, %bias.235, %running_mean.193, %running_var.193, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.127 : Tensor = aten::hardtanh_(%input.125, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.127 : Tensor = aten::hardtanh_(%input.125, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.429 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.17)\n\t\t-   %647 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t-   %648 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t-   %649 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t-   %650 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t?    - ^                                ^     ^\n\t\t+   %517 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t?     ^^                                ^     ^\n\t\t-   %input.129 : Tensor = aten::_convolution(%input.127, %weight.429, %530, %647, %648, %649, %533, %650, %535, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %518 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t+   %519 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t+   %520 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t+   %input.129 : Tensor = aten::_convolution(%input.127, %weight.429, %431, %517, %518, %519, %434, %520, %436, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.195 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.17)\n\t\t    %running_mean.195 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.17)\n\t\t    %bias.237 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.17)\n\t\t    %weight.431 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.17)\n\t\t-   %input.131 : Tensor = aten::batch_norm(%input.129, %weight.431, %bias.237, %running_mean.195, %running_var.195, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.131 : Tensor = aten::batch_norm(%input.129, %weight.431, %bias.237, %running_mean.195, %running_var.195, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.133 : Tensor = aten::hardtanh_(%input.131, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.133 : Tensor = aten::hardtanh_(%input.131, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.433 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.15)\n\t\t-   %659 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t-   %660 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t-   %661 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t-   %662 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t?    ^^                                 ^     ^\n\t\t+   %529 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t?    ^ +                                ^     ^\n\t\t-   %input.135 : Tensor = aten::_convolution(%input.133, %weight.433, %530, %659, %660, %661, %533, %662, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %530 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t+   %531 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t+   %532 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t+   %input.135 : Tensor = aten::_convolution(%input.133, %weight.433, %431, %529, %530, %531, %434, %532, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.197 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.15)\n\t\t    %running_mean.197 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.15)\n\t\t    %bias.239 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.15)\n\t\t    %weight.435 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.15)\n\t\t-   %x.25 : Tensor = aten::batch_norm(%input.135, %weight.435, %bias.239, %running_mean.197, %running_var.197, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.25 : Tensor = aten::batch_norm(%input.135, %weight.435, %bias.239, %running_mean.197, %running_var.197, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.137 : Tensor = aten::add_(%x.25, %input.121, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.137 : Tensor = aten::add_(%x.25, %input.121, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.17 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_2.7)\n\t\t    %conv_pwl.17 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_2.7)\n\t\t    %se.19 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_2.7)\n\t\t    %act2.19 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_2.7)\n\t\t    %bn2.19 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_2.7)\n\t\t    %conv_dw.19 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_2.7)\n\t\t    %act1.19 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_2.7)\n\t\t    %bn1.19 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_2.7)\n\t\t    %conv_pw.19 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_2.7)\n\t\t    %weight.437 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.19)\n\t\t-   %680 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t-   %681 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %550 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %682 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %551 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %683 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %552 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %input.139 : Tensor = aten::_convolution(%input.137, %weight.437, %530, %680, %681, %682, %533, %683, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %553 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t+   %input.139 : Tensor = aten::_convolution(%input.137, %weight.437, %431, %550, %551, %552, %434, %553, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.199 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.19)\n\t\t    %running_mean.199 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.19)\n\t\t    %bias.241 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.19)\n\t\t    %weight.439 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.19)\n\t\t-   %input.141 : Tensor = aten::batch_norm(%input.139, %weight.439, %bias.241, %running_mean.199, %running_var.199, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.141 : Tensor = aten::batch_norm(%input.139, %weight.439, %bias.241, %running_mean.199, %running_var.199, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.143 : Tensor = aten::hardtanh_(%input.141, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.143 : Tensor = aten::hardtanh_(%input.141, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.441 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.19)\n\t\t-   %692 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t-   %693 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t-   %694 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t-   %695 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t?     ^^                                ^     ^\n\t\t+   %562 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t?    + ^                                ^     ^\n\t\t-   %input.145 : Tensor = aten::_convolution(%input.143, %weight.441, %530, %692, %693, %694, %533, %695, %535, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %563 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t+   %564 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t+   %565 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t+   %input.145 : Tensor = aten::_convolution(%input.143, %weight.441, %431, %562, %563, %564, %434, %565, %436, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.201 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.19)\n\t\t    %running_mean.201 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.19)\n\t\t    %bias.243 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.19)\n\t\t    %weight.443 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.19)\n\t\t-   %input.147 : Tensor = aten::batch_norm(%input.145, %weight.443, %bias.243, %running_mean.201, %running_var.201, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.147 : Tensor = aten::batch_norm(%input.145, %weight.443, %bias.243, %running_mean.201, %running_var.201, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.149 : Tensor = aten::hardtanh_(%input.147, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.149 : Tensor = aten::hardtanh_(%input.147, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.445 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.17)\n\t\t-   %704 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t-   %705 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?     ^^                                ^     ^\n\t\t+   %574 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?    + ^                                ^     ^\n\t\t-   %706 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?     ^^                                ^ ^   ^ ^\n\t\t+   %575 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?    + ^                                ^ ^   ^ ^\n\t\t-   %707 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?     ^^                                ^     ^\n\t\t+   %576 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?    + ^                                ^     ^\n\t\t-   %input.151 : Tensor = aten::_convolution(%input.149, %weight.445, %530, %704, %705, %706, %533, %707, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %577 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t+   %input.151 : Tensor = aten::_convolution(%input.149, %weight.445, %431, %574, %575, %576, %434, %577, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.203 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.17)\n\t\t    %running_mean.203 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.17)\n\t\t    %bias.245 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.17)\n\t\t    %weight.447 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.17)\n\t\t-   %x.27 : Tensor = aten::batch_norm(%input.151, %weight.447, %bias.245, %running_mean.203, %running_var.203, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.27 : Tensor = aten::batch_norm(%input.151, %weight.447, %bias.245, %running_mean.203, %running_var.203, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.153 : Tensor = aten::add_(%x.27, %input.137, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.153 : Tensor = aten::add_(%x.27, %input.137, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.19 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_3.3)\n\t\t    %conv_pwl.19 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_3.3)\n\t\t    %se.21 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_3.3)\n\t\t    %act2.21 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_3.3)\n\t\t    %bn2.21 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_3.3)\n\t\t    %conv_dw.21 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_3.3)\n\t\t    %act1.21 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_3.3)\n\t\t    %bn1.21 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_3.3)\n\t\t    %conv_pw.21 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_3.3)\n\t\t    %weight.449 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.21)\n\t\t-   %725 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?    --                                 ^ ^   ^ ^\n\t\t+   %595 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?     ++                                ^ ^   ^ ^\n\t\t+   %596 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t-   %726 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?     --                                ^     ^\n\t\t+   %597 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?    ++                                 ^     ^\n\t\t-   %727 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t-   %728 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t+   %598 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t-   %input.155 : Tensor = aten::_convolution(%input.153, %weight.449, %530, %725, %726, %727, %533, %728, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.155 : Tensor = aten::_convolution(%input.153, %weight.449, %431, %595, %596, %597, %434, %598, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.205 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.21)\n\t\t    %running_mean.205 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.21)\n\t\t    %bias.247 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.21)\n\t\t    %weight.451 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.21)\n\t\t-   %input.157 : Tensor = aten::batch_norm(%input.155, %weight.451, %bias.247, %running_mean.205, %running_var.205, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.157 : Tensor = aten::batch_norm(%input.155, %weight.451, %bias.247, %running_mean.205, %running_var.205, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.159 : Tensor = aten::hardtanh_(%input.157, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.159 : Tensor = aten::hardtanh_(%input.157, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.453 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.21)\n\t\t-   %737 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t-   %738 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t-   %739 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t-   %740 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t?     --                                ^     ^\n\t\t+   %607 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t?    ++                                 ^     ^\n\t\t+   %608 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t+   %609 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t+   %610 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t-   %input.161 : Tensor = aten::_convolution(%input.159, %weight.453, %530, %737, %738, %739, %533, %740, %535, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^ ^^^^^^^    ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.161 : Tensor = aten::_convolution(%input.159, %weight.453, %431, %607, %608, %609, %434, %610, %436, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^ ^^^^^    ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.207 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.21)\n\t\t    %running_mean.207 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.21)\n\t\t    %bias.249 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.21)\n\t\t    %weight.455 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.21)\n\t\t-   %input.163 : Tensor = aten::batch_norm(%input.161, %weight.455, %bias.249, %running_mean.207, %running_var.207, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.163 : Tensor = aten::batch_norm(%input.161, %weight.455, %bias.249, %running_mean.207, %running_var.207, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.165 : Tensor = aten::hardtanh_(%input.163, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.165 : Tensor = aten::hardtanh_(%input.163, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.457 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.19)\n\t\t-   %749 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t-   %750 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %619 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t-   %751 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %620 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %752 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^^                                 ^     ^\n\t\t+   %621 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^ +                                ^     ^\n\t\t+   %622 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t-   %input.167 : Tensor = aten::_convolution(%input.165, %weight.457, %530, %749, %750, %751, %533, %752, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.167 : Tensor = aten::_convolution(%input.165, %weight.457, %431, %619, %620, %621, %434, %622, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.209 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.19)\n\t\t    %running_mean.209 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.19)\n\t\t    %bias.251 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.19)\n\t\t    %weight.459 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.19)\n\t\t-   %x.29 : Tensor = aten::batch_norm(%input.167, %weight.459, %bias.251, %running_mean.209, %running_var.209, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.29 : Tensor = aten::batch_norm(%input.167, %weight.459, %bias.251, %running_mean.209, %running_var.209, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.169 : Tensor = aten::add_(%x.29, %input.153, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.169 : Tensor = aten::add_(%x.29, %input.153, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.21 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_4.3)\n\t\t    %conv_pwl.21 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_4.3)\n\t\t    %se.23 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_4.3)\n\t\t    %act2.23 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_4.3)\n\t\t    %bn2.23 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_4.3)\n\t\t    %conv_dw.23 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_4.3)\n\t\t    %act1.23 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_4.3)\n\t\t    %bn1.23 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_4.3)\n\t\t    %conv_pw.23 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_4.3)\n\t\t    %weight.461 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.23)\n\t\t-   %770 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t-   %771 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %640 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %772 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %641 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %773 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %642 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %input.171 : Tensor = aten::_convolution(%input.169, %weight.461, %530, %770, %771, %772, %533, %773, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %643 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t+   %input.171 : Tensor = aten::_convolution(%input.169, %weight.461, %431, %640, %641, %642, %434, %643, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.211 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.23)\n\t\t    %running_mean.211 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.23)\n\t\t    %bias.253 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.23)\n\t\t    %weight.463 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.23)\n\t\t-   %input.173 : Tensor = aten::batch_norm(%input.171, %weight.463, %bias.253, %running_mean.211, %running_var.211, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.173 : Tensor = aten::batch_norm(%input.171, %weight.463, %bias.253, %running_mean.211, %running_var.211, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.175 : Tensor = aten::hardtanh_(%input.173, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.175 : Tensor = aten::hardtanh_(%input.173, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.465 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.23)\n\t\t-   %782 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t-   %783 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t-   %784 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t-   %785 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t?    ^^                                 ^     ^\n\t\t+   %652 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t?    ^ +                                ^     ^\n\t\t-   %input.177 : Tensor = aten::_convolution(%input.175, %weight.465, %530, %782, %783, %784, %533, %785, %535, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %653 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t+   %654 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t+   %655 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t+   %input.177 : Tensor = aten::_convolution(%input.175, %weight.465, %431, %652, %653, %654, %434, %655, %436, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.213 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.23)\n\t\t    %running_mean.213 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.23)\n\t\t    %bias.255 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.23)\n\t\t    %weight.467 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.23)\n\t\t-   %input.179 : Tensor = aten::batch_norm(%input.177, %weight.467, %bias.255, %running_mean.213, %running_var.213, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.179 : Tensor = aten::batch_norm(%input.177, %weight.467, %bias.255, %running_mean.213, %running_var.213, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.181 : Tensor = aten::hardtanh_(%input.179, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.181 : Tensor = aten::hardtanh_(%input.179, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.469 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.21)\n\t\t-   %794 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t-   %795 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %664 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t-   %796 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?    --                                 ^ ^   ^ ^\n\t\t+   %665 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?     ++                                ^ ^   ^ ^\n\t\t-   %797 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %666 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t-   %input.183 : Tensor = aten::_convolution(%input.181, %weight.469, %530, %794, %795, %796, %533, %797, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %667 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t+   %input.183 : Tensor = aten::_convolution(%input.181, %weight.469, %431, %664, %665, %666, %434, %667, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.215 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.21)\n\t\t    %running_mean.215 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.21)\n\t\t    %bias.257 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.21)\n\t\t    %weight.471 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.21)\n\t\t-   %x.31 : Tensor = aten::batch_norm(%input.183, %weight.471, %bias.257, %running_mean.215, %running_var.215, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.31 : Tensor = aten::batch_norm(%input.183, %weight.471, %bias.257, %running_mean.215, %running_var.215, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.185 : Tensor = aten::add_(%x.31, %input.169, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.185 : Tensor = aten::add_(%x.31, %input.169, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %_4.5 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"4\"](%_1.11)\n\t\t    %_3.5 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"3\"](%_1.11)\n\t\t    %_2.9 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"2\"](%_1.11)\n\t\t    %_1.9 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"1\"](%_1.11)\n\t\t    %_0.15 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_1.11)\n\t\t    %bn3.23 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.15)\n\t\t    %conv_pwl.23 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.15)\n\t\t    %se.25 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.15)\n\t\t    %act2.25 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.15)\n\t\t    %bn2.25 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.15)\n\t\t    %conv_dw.25 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_0.15)\n\t\t    %act1.25 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.15)\n\t\t    %bn1.25 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.15)\n\t\t    %conv_pw.25 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.15)\n\t\t    %weight.473 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.25)\n\t\t-   %820 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t+   %690 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t+   %691 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t-   %821 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^ -                                ^     ^\n\t\t+   %692 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^^                                 ^     ^\n\t\t-   %822 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t-   %823 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t+   %693 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t-   %input.187 : Tensor = aten::_convolution(%input.185, %weight.473, %530, %820, %821, %822, %533, %823, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.187 : Tensor = aten::_convolution(%input.185, %weight.473, %431, %690, %691, %692, %434, %693, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.217 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.25)\n\t\t    %running_mean.217 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.25)\n\t\t    %bias.259 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.25)\n\t\t    %weight.475 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.25)\n\t\t-   %input.189 : Tensor = aten::batch_norm(%input.187, %weight.475, %bias.259, %running_mean.217, %running_var.217, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.189 : Tensor = aten::batch_norm(%input.187, %weight.475, %bias.259, %running_mean.217, %running_var.217, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.191 : Tensor = aten::hardtanh_(%input.189, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.191 : Tensor = aten::hardtanh_(%input.189, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.477 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.25)\n\t\t-   %832 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t-   %833 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t-   %834 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t-   %835 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t?    ^^^                                ^     ^\n\t\t+   %702 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t?    ^^^                                ^     ^\n\t\t+   %703 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t+   %704 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t+   %705 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t-   %input.193 : Tensor = aten::_convolution(%input.191, %weight.477, %530, %832, %833, %834, %533, %835, %535, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^  ------------------------------\n\t\t+   %input.193 : Tensor = aten::_convolution(%input.191, %weight.477, %431, %702, %703, %704, %434, %705, %436, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ++++++++++++++++++++++++++++++++ ^^^^^^^^^^^^^^^^^^^^^^^ ^^^^\n\t\t    %running_var.219 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.25)\n\t\t    %running_mean.219 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.25)\n\t\t    %bias.261 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.25)\n\t\t    %weight.479 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.25)\n\t\t-   %input.195 : Tensor = aten::batch_norm(%input.193, %weight.479, %bias.261, %running_mean.219, %running_var.219, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.195 : Tensor = aten::batch_norm(%input.193, %weight.479, %bias.261, %running_mean.219, %running_var.219, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.197 : Tensor = aten::hardtanh_(%input.195, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.197 : Tensor = aten::hardtanh_(%input.195, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.481 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.23)\n\t\t-   %844 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t-   %845 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?    ^ -                                ^     ^\n\t\t+   %714 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?    ^^                                 ^     ^\n\t\t-   %846 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %715 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %847 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?    --                                 ^     ^\n\t\t+   %716 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?     ++                                ^     ^\n\t\t-   %input.199 : Tensor = aten::_convolution(%input.197, %weight.481, %530, %844, %845, %846, %533, %847, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %717 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t+   %input.199 : Tensor = aten::_convolution(%input.197, %weight.481, %431, %714, %715, %716, %434, %717, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.221 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.23)\n\t\t    %running_mean.221 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.23)\n\t\t    %bias.263 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.23)\n\t\t    %weight.483 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.23)\n\t\t-   %input.201 : Tensor = aten::batch_norm(%input.199, %weight.483, %bias.263, %running_mean.221, %running_var.221, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.201 : Tensor = aten::batch_norm(%input.199, %weight.483, %bias.263, %running_mean.221, %running_var.221, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %bn3.25 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_1.9)\n\t\t    %conv_pwl.25 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_1.9)\n\t\t    %se.27 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_1.9)\n\t\t    %act2.27 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_1.9)\n\t\t    %bn2.27 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.9)\n\t\t    %conv_dw.27 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_1.9)\n\t\t    %act1.27 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_1.9)\n\t\t    %bn1.27 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.9)\n\t\t    %conv_pw.27 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_1.9)\n\t\t    %weight.485 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.27)\n\t\t-   %864 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t-   %865 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t-   %866 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t-   %867 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t?    --                                 ^     ^\n\t\t+   %734 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t?     ++                                ^     ^\n\t\t+   %735 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t+   %736 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t+   %737 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t-   %input.203 : Tensor = aten::_convolution(%input.201, %weight.485, %530, %864, %865, %866, %533, %867, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.203 : Tensor = aten::_convolution(%input.201, %weight.485, %431, %734, %735, %736, %434, %737, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.223 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.27)\n\t\t    %running_mean.223 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.27)\n\t\t    %bias.265 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.27)\n\t\t    %weight.487 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.27)\n\t\t-   %input.205 : Tensor = aten::batch_norm(%input.203, %weight.487, %bias.265, %running_mean.223, %running_var.223, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.205 : Tensor = aten::batch_norm(%input.203, %weight.487, %bias.265, %running_mean.223, %running_var.223, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.207 : Tensor = aten::hardtanh_(%input.205, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.207 : Tensor = aten::hardtanh_(%input.205, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.489 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.27)\n\t\t-   %876 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t-   %877 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t-   %878 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t-   %879 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t?    - ^                                ^     ^\n\t\t+   %746 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t?     ^^                                ^     ^\n\t\t+   %747 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t+   %748 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t+   %749 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t-   %input.209 : Tensor = aten::_convolution(%input.207, %weight.489, %530, %876, %877, %878, %533, %879, %518, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ^^^^^^^^^^^^^^^^^^^^^^^ --------------------------------------\n\t\t+   %input.209 : Tensor = aten::_convolution(%input.207, %weight.489, %431, %746, %747, %748, %434, %749, %421, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ^^^^^\n\t\t    %running_var.225 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.27)\n\t\t    %running_mean.225 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.27)\n\t\t    %bias.267 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.27)\n\t\t    %weight.491 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.27)\n\t\t-   %input.211 : Tensor = aten::batch_norm(%input.209, %weight.491, %bias.267, %running_mean.225, %running_var.225, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.211 : Tensor = aten::batch_norm(%input.209, %weight.491, %bias.267, %running_mean.225, %running_var.225, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.213 : Tensor = aten::hardtanh_(%input.211, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.213 : Tensor = aten::hardtanh_(%input.211, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.493 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.25)\n\t\t-   %888 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t-   %889 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?     --                                ^     ^\n\t\t+   %758 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?    ++                                 ^     ^\n\t\t-   %890 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?    ^ -                                ^ ^   ^ ^\n\t\t+   %759 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t-   %891 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %760 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %761 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t-   %input.215 : Tensor = aten::_convolution(%input.213, %weight.493, %530, %888, %889, %890, %533, %891, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.215 : Tensor = aten::_convolution(%input.213, %weight.493, %431, %758, %759, %760, %434, %761, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.227 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.25)\n\t\t    %running_mean.227 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.25)\n\t\t    %bias.269 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.25)\n\t\t    %weight.495 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.25)\n\t\t-   %x.33 : Tensor = aten::batch_norm(%input.215, %weight.495, %bias.269, %running_mean.227, %running_var.227, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                --------------------\n\t\t+   %x.33 : Tensor = aten::batch_norm(%input.215, %weight.495, %bias.269, %running_mean.227, %running_var.227, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                               ++++++++++++++++++++\n\t\t-   %input.217 : Tensor = aten::add_(%x.33, %input.201, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.217 : Tensor = aten::add_(%x.33, %input.201, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.27 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_2.9)\n\t\t    %conv_pwl.27 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_2.9)\n\t\t    %se.29 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_2.9)\n\t\t    %act2.29 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_2.9)\n\t\t    %bn2.29 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_2.9)\n\t\t    %conv_dw.29 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_2.9)\n\t\t    %act1.29 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_2.9)\n\t\t    %bn1.29 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_2.9)\n\t\t    %conv_pw.29 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_2.9)\n\t\t    %weight.497 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.29)\n\t\t-   %909 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t-   %910 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?     --                                ^     ^\n\t\t+   %779 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?    ++                                 ^     ^\n\t\t-   %911 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %780 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %912 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?    ^ -                                ^     ^\n\t\t+   %781 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?    ^^                                 ^     ^\n\t\t+   %782 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t-   %input.219 : Tensor = aten::_convolution(%input.217, %weight.497, %530, %909, %910, %911, %533, %912, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ^^^^^^^^^^^^^^^^^^^^^^^ --------------------------------------\n\t\t+   %input.219 : Tensor = aten::_convolution(%input.217, %weight.497, %431, %779, %780, %781, %434, %782, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ^^^^^\n\t\t    %running_var.229 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.29)\n\t\t    %running_mean.229 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.29)\n\t\t    %bias.271 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.29)\n\t\t    %weight.499 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.29)\n\t\t-   %input.221 : Tensor = aten::batch_norm(%input.219, %weight.499, %bias.271, %running_mean.229, %running_var.229, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.221 : Tensor = aten::batch_norm(%input.219, %weight.499, %bias.271, %running_mean.229, %running_var.229, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.223 : Tensor = aten::hardtanh_(%input.221, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.223 : Tensor = aten::hardtanh_(%input.221, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.501 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.29)\n\t\t-   %921 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t-   %922 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t-   %923 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t-   %924 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t?     ^^                                ^     ^\n\t\t+   %791 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t?    + ^                                ^     ^\n\t\t+   %792 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t+   %793 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t+   %794 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t-   %input.225 : Tensor = aten::_convolution(%input.223, %weight.501, %530, %921, %922, %923, %533, %924, %518, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^ ^^^^^  ^^^^ ^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.225 : Tensor = aten::_convolution(%input.223, %weight.501, %431, %791, %792, %793, %434, %794, %421, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^ ^^^^^  ^^^^ ^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.231 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.29)\n\t\t    %running_mean.231 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.29)\n\t\t    %bias.273 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.29)\n\t\t    %weight.503 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.29)\n\t\t-   %input.227 : Tensor = aten::batch_norm(%input.225, %weight.503, %bias.273, %running_mean.231, %running_var.231, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.227 : Tensor = aten::batch_norm(%input.225, %weight.503, %bias.273, %running_mean.231, %running_var.231, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.229 : Tensor = aten::hardtanh_(%input.227, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.229 : Tensor = aten::hardtanh_(%input.227, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.505 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.27)\n\t\t-   %933 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t-   %934 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^ -                                ^     ^\n\t\t+   %803 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^^                                 ^     ^\n\t\t-   %935 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %804 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %936 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %805 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %806 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t-   %input.231 : Tensor = aten::_convolution(%input.229, %weight.505, %530, %933, %934, %935, %533, %936, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.231 : Tensor = aten::_convolution(%input.229, %weight.505, %431, %803, %804, %805, %434, %806, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.233 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.27)\n\t\t    %running_mean.233 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.27)\n\t\t    %bias.275 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.27)\n\t\t    %weight.507 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.27)\n\t\t-   %x.35 : Tensor = aten::batch_norm(%input.231, %weight.507, %bias.275, %running_mean.233, %running_var.233, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                --------------------\n\t\t+   %x.35 : Tensor = aten::batch_norm(%input.231, %weight.507, %bias.275, %running_mean.233, %running_var.233, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                               ++++++++++++++++++++\n\t\t-   %input.233 : Tensor = aten::add_(%x.35, %input.217, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.233 : Tensor = aten::add_(%x.35, %input.217, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.29 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_3.5)\n\t\t    %conv_pwl.29 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_3.5)\n\t\t    %se.31 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_3.5)\n\t\t    %act2.31 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_3.5)\n\t\t    %bn2.31 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_3.5)\n\t\t    %conv_dw.31 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_3.5)\n\t\t    %act1.31 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_3.5)\n\t\t    %bn1.31 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_3.5)\n\t\t    %conv_pw.31 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_3.5)\n\t\t    %weight.509 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.31)\n\t\t-   %954 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t-   %955 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %824 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %956 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^ -                                ^ ^   ^ ^\n\t\t+   %825 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t-   %957 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %826 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %input.235 : Tensor = aten::_convolution(%input.233, %weight.509, %530, %954, %955, %956, %533, %957, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %827 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t+   %input.235 : Tensor = aten::_convolution(%input.233, %weight.509, %431, %824, %825, %826, %434, %827, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.235 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.31)\n\t\t    %running_mean.235 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.31)\n\t\t    %bias.277 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.31)\n\t\t    %weight.511 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.31)\n\t\t-   %input.237 : Tensor = aten::batch_norm(%input.235, %weight.511, %bias.277, %running_mean.235, %running_var.235, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ^^^^^^^^^^^^^     ^^^\n\t\t+   %input.237 : Tensor = aten::batch_norm(%input.235, %weight.511, %bias.277, %running_mean.235, %running_var.235, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ^^^^^^^     ^^^^^^^^^\n\t\t-   %input.239 : Tensor = aten::hardtanh_(%input.237, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.239 : Tensor = aten::hardtanh_(%input.237, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.513 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.31)\n\t\t-   %966 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t-   %967 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t-   %968 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t-   %969 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t?    ^ -                                ^     ^\n\t\t+   %836 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t?    ^^                                 ^     ^\n\t\t+   %837 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t+   %838 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t+   %839 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t-   %input.241 : Tensor = aten::_convolution(%input.239, %weight.513, %530, %966, %967, %968, %533, %969, %518, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ^^^^^^^^^^^^^^^^^^^^^^^ --------------------------------------\n\t\t+   %input.241 : Tensor = aten::_convolution(%input.239, %weight.513, %431, %836, %837, %838, %434, %839, %421, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ^^^^^\n\t\t    %running_var.237 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.31)\n\t\t    %running_mean.237 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.31)\n\t\t    %bias.279 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.31)\n\t\t    %weight.515 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.31)\n\t\t-   %input.243 : Tensor = aten::batch_norm(%input.241, %weight.515, %bias.279, %running_mean.237, %running_var.237, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.243 : Tensor = aten::batch_norm(%input.241, %weight.515, %bias.279, %running_mean.237, %running_var.237, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.245 : Tensor = aten::hardtanh_(%input.243, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.245 : Tensor = aten::hardtanh_(%input.243, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.517 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.29)\n\t\t-   %978 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t-   %979 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t-   %980 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t-   %981 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t?    - ^                                ^     ^\n\t\t+   %848 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t?     ^^                                ^     ^\n\t\t+   %849 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t+   %850 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t+   %851 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t-   %input.247 : Tensor = aten::_convolution(%input.245, %weight.517, %530, %978, %979, %980, %533, %981, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.247 : Tensor = aten::_convolution(%input.245, %weight.517, %431, %848, %849, %850, %434, %851, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.239 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.29)\n\t\t    %running_mean.239 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.29)\n\t\t    %bias.281 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.29)\n\t\t    %weight.519 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.29)\n\t\t-   %x.37 : Tensor = aten::batch_norm(%input.247, %weight.519, %bias.281, %running_mean.239, %running_var.239, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                --------------------\n\t\t+   %x.37 : Tensor = aten::batch_norm(%input.247, %weight.519, %bias.281, %running_mean.239, %running_var.239, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                               ++++++++++++++++++++\n\t\t-   %input.249 : Tensor = aten::add_(%x.37, %input.233, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.249 : Tensor = aten::add_(%x.37, %input.233, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.31 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_4.5)\n\t\t    %conv_pwl.31 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_4.5)\n\t\t    %se.33 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_4.5)\n\t\t    %act2.33 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_4.5)\n\t\t    %bn2.33 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_4.5)\n\t\t    %conv_dw.33 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_4.5)\n\t\t    %act1.33 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_4.5)\n\t\t    %bn1.33 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_4.5)\n\t\t    %conv_pw.33 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_4.5)\n\t\t    %weight.521 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.33)\n\t\t-   %999 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?     --                                ^ ^   ^ ^\n\t\t+   %869 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?    ++                                 ^ ^   ^ ^\n\t\t+   %870 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t-   %1000 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?     ---                                ^     ^\n\t\t+   %871 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?    ++                                 ^     ^\n\t\t-   %1001 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t-   %1002 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?    ^^^                                 ^ ^   ^ ^\n\t\t+   %872 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t-   %input.251 : Tensor = aten::_convolution(%input.249, %weight.521, %530, %999, %1000, %1001, %533, %1002, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.251 : Tensor = aten::_convolution(%input.249, %weight.521, %431, %869, %870, %871, %434, %872, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.241 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.33)\n\t\t    %running_mean.241 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.33)\n\t\t    %bias.283 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.33)\n\t\t    %weight.523 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.33)\n\t\t-   %input.253 : Tensor = aten::batch_norm(%input.251, %weight.523, %bias.283, %running_mean.241, %running_var.241, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.253 : Tensor = aten::batch_norm(%input.251, %weight.523, %bias.283, %running_mean.241, %running_var.241, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.255 : Tensor = aten::hardtanh_(%input.253, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.255 : Tensor = aten::hardtanh_(%input.253, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.525 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.33)\n\t\t-   %1011 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t-   %1012 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t-   %1013 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t-   %1014 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t?     ---                                ^     ^\n\t\t+   %881 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t?    ++                                 ^     ^\n\t\t+   %882 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t+   %883 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t+   %884 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t-   %input.257 : Tensor = aten::_convolution(%input.255, %weight.525, %530, %1011, %1012, %1013, %533, %1014, %518, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.257 : Tensor = aten::_convolution(%input.255, %weight.525, %431, %881, %882, %883, %434, %884, %421, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.243 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.33)\n\t\t    %running_mean.243 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.33)\n\t\t    %bias.285 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.33)\n\t\t    %weight.527 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.33)\n\t\t-   %input.259 : Tensor = aten::batch_norm(%input.257, %weight.527, %bias.285, %running_mean.243, %running_var.243, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ^^^^^^^^^^^^^     ^^^\n\t\t+   %input.259 : Tensor = aten::batch_norm(%input.257, %weight.527, %bias.285, %running_mean.243, %running_var.243, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ^^^^^^^     ^^^^^^^^^\n\t\t-   %input.261 : Tensor = aten::hardtanh_(%input.259, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.261 : Tensor = aten::hardtanh_(%input.259, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.529 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.31)\n\t\t-   %1023 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t-   %1024 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^^                                ^     ^\n\t\t+   %893 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t-   %1025 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^^                                ^ ^   ^ ^\n\t\t+   %894 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %1026 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^^                                ^     ^\n\t\t+   %895 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %896 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t-   %input.263 : Tensor = aten::_convolution(%input.261, %weight.529, %530, %1023, %1024, %1025, %533, %1026, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.263 : Tensor = aten::_convolution(%input.261, %weight.529, %431, %893, %894, %895, %434, %896, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.245 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.31)\n\t\t    %running_mean.245 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.31)\n\t\t    %bias.287 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.31)\n\t\t    %weight.531 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.31)\n\t\t-   %x.39 : Tensor = aten::batch_norm(%input.263, %weight.531, %bias.287, %running_mean.245, %running_var.245, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                --------------------\n\t\t+   %x.39 : Tensor = aten::batch_norm(%input.263, %weight.531, %bias.287, %running_mean.245, %running_var.245, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                               ++++++++++++++++++++\n\t\t-   %input.265 : Tensor = aten::add_(%x.39, %input.249, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.265 : Tensor = aten::add_(%x.39, %input.249, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t-   %1034 : int = prim::Constant[value=2](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %1035 : int = prim::Constant[value=3](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t+   %904 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %905 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %1036 : Tensor = prim::Constant[value={-2}](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t?    ^^^                                   ^^                                                                                                                                                                                          ^^^^^^^^^^^ ^^\n\t\t+   %906 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?    ^^                                   ^                                                                                                                                          +++++++++++++++++++++++++++++++++++++++++++                                                ^^^^^^^^^^^^^^^^^^^ ^\n\t\t-   %1037 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t?    ^^^    ^^^^^^                        ^^^                                                                                                                                                                                                                                      ^^\n\t\t+   %907 : int = prim::Constant[value=2](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^    ^^^                        ^                                                                                                                                                                                                                                      ^^^\n\t\t-   %1038 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1039 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %1040 : int = prim::Constant[value=816](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^^^\n\t\t+   %908 : int = prim::Constant[value=816](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^^\n\t\t-   %1041 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^^\n\t\t+   %909 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^\n\t\t-   %1042 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?      ^^^^\n\t\t+   %910 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    +  ^^\n\t\t-   %1043 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^^\n\t\t+   %911 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t-   %1044 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?     ^^^^^\n\t\t+   %912 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    + ^^^\n\t\t-   %1045 : NoneType = prim::Constant(), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?     ^^^\n\t\t+   %913 : NoneType = prim::Constant(), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    + ^\n\t\t-   %1046 : int = prim::Constant[value=1](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t+   %914 : int = prim::Constant[value=1](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    + ^^^^^^^\n\t\t-   %1047 : int = prim::Constant[value=0](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t+   %915 : int = prim::Constant[value=0](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    + ^^^^^^^\n\t\t-   %1048 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %916 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    + ^^^\n\t\t-   %1049 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %917 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    + ^^^\n\t\t-   %1050 : int = prim::Constant[value=1392](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^^\n\t\t+   %918 : int = prim::Constant[value=1392](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t    %_1.15 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"1\"](%layer4)\n\t\t    %_0.19 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"0\"](%layer4)\n\t\t    %_5.1 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"5\"](%_0.19)\n\t\t    %_4.7 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"4\"](%_0.19)\n\t\t    %_3.7 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"3\"](%_0.19)\n\t\t    %_2.11 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"2\"](%_0.19)\n\t\t    %_1.13 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"1\"](%_0.19)\n\t\t    %_0.17 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_0.19)\n\t\t    %bn3.33 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.17)\n\t\t    %conv_pwl.33 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.17)\n\t\t    %se.35 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.17)\n\t\t    %act2.35 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.17)\n\t\t    %bn2.35 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.17)\n\t\t    %conv_dw.35 : __torch__.geffnet.conv2d_layers.Conv2dSameExport = prim::GetAttr[name=\"conv_dw\"](%_0.17)\n\t\t    %act1.35 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.17)\n\t\t    %bn1.35 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.17)\n\t\t    %conv_pw.35 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.17)\n\t\t    %weight.533 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.35)\n\t\t-   %1069 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    ---                                  - -    - -\n\t\t+   %937 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?     ++                                +     +\n\t\t+   %938 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t-   %1070 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    ^^^^                                 - -    - -\n\t\t+   %939 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    ^^^                                +     +\n\t\t-   %1071 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    ^ --                                 ^^^    ^^^\n\t\t+   %940 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    ^^                                 + ^   + ^\n\t\t+   %input.267 : Tensor = aten::_convolution(%input.265, %weight.533, %913, %937, %938, %939, %916, %940, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1072 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t-   %input.267 : Tensor = aten::_convolution(%input.265, %weight.533, %1045, %1069, %1070, %1071, %1048, %1072, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.247 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.35)\n\t\t    %running_mean.247 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.35)\n\t\t    %bias.289 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.35)\n\t\t    %weight.535 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.35)\n\t\t-   %input.269 : Tensor = aten::batch_norm(%input.267, %weight.535, %bias.289, %running_mean.247, %running_var.247, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.269 : Tensor = aten::batch_norm(%input.267, %weight.535, %bias.289, %running_mean.247, %running_var.247, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %x.41 : Tensor = aten::hardtanh_(%input.269, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                 ^^^^   ^^^^\n\t\t+   %x.41 : Tensor = aten::hardtanh_(%input.269, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                 ^^^   ^^^\n\t\t    %weight.537 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.35)\n\t\t+   %pad : __torch__.torch.nn.modules.padding.ZeroPad2d = prim::GetAttr[name=\"pad\"](%conv_dw.35)\n\t\t-   %1081 : int = aten::size(%x.41, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.17 : Tensor = prim::NumToTensor(%1081), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1083 : int = aten::size(%x.41, %1035), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i : Tensor = prim::NumToTensor(%1083), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^^^^^^^^   ^^^^^^^^^^^^^^^^^  ^^^^\n\t\t+   %950 : int = aten::Int(%906), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad\n\t\t?    ^^^^^^^^^   ^^^^^^^^^  ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %1085 : int = aten::size(%weight.537, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.17 : Tensor = prim::NumToTensor(%1085), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1087 : int = aten::size(%weight.537, %1035), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k : Tensor = prim::NumToTensor(%1087), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1089 : Tensor = aten::floor_divide(%i.17, %1036), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1090 : Tensor = aten::neg(%1089), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1091 : Tensor = aten::sub(%1090, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1092 : Tensor = aten::mul(%1091, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1093 : Tensor = aten::sub(%k.17, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1094 : Tensor = aten::mul(%1093, %1037), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1095 : Tensor = aten::add(%1092, %1094, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1096 : Tensor = aten::add(%1095, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_h : Tensor = aten::sub(%1096, %i.17, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1098 : Tensor = aten::floor_divide(%i, %1036), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1099 : Tensor = aten::neg(%1098), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1100 : Tensor = aten::sub(%1099, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1101 : Tensor = aten::mul(%1100, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1102 : Tensor = aten::sub(%k, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1103 : Tensor = aten::mul(%1102, %1037), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1104 : Tensor = aten::add(%1101, %1103, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1105 : Tensor = aten::add(%1104, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_w : Tensor = aten::sub(%1105, %i, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1107 : Tensor = aten::floor_divide(%pad_w, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1108 : int = aten::Int(%1107), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?     ^^^^^^^^^              ^^^^\n\t\t+   %951 : int = aten::Int(%905), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad\n\t\t?    ++ ^^^^^^              ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %1109 : Tensor = aten::floor_divide(%pad_w, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1110 : Tensor = aten::sub(%pad_w, %1109, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %1111 : int = aten::Int(%1110), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^^^^^^^^              ^^^^\n\t\t+   %952 : int = aten::Int(%906), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad\n\t\t?    ^^^^^^^^^              ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %1112 : Tensor = aten::floor_divide(%pad_h, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1113 : int = aten::Int(%1112), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^                     ^^^^\n\t\t+   %953 : int = aten::Int(%905), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad\n\t\t?    ^^                     ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t+   %954 : int[] = prim::ListConstruct(%950, %951, %952, %953), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad\n\t\t+   %x.43 : Tensor = aten::pad(%x.41, %954, %904, %909), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %1114 : Tensor = aten::floor_divide(%pad_h, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1115 : Tensor = aten::sub(%pad_h, %1114, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %1116 : int = aten::Int(%1115), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1117 : int[] = prim::ListConstruct(%1108, %1111, %1113, %1116), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^^                                ^^ ^   ^^^^^^^^^^^^^^^^^^\n\t\t+   %956 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^                                ^ ^   ^^^\n\t\t-   %x.43 : Tensor = aten::pad(%x.41, %1117, %1039, %1041), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %957 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1119 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ---                                  --     --\n\t\t+   %958 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?     ++                                +     +\n\t\t-   %1120 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^^                                 ^^^    ^^^\n\t\t+   %959 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^                                + ^   + ^\n\t\t-   %1121 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1122 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %input.271 : Tensor = aten::_convolution(%x.43, %weight.537, %1045, %1119, %1120, %1121, %1048, %1122, %1040, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^\n\t\t+   %input.271 : Tensor = aten::_convolution(%x.43, %weight.537, %913, %956, %957, %958, %916, %959, %908, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                 ^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.249 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.35)\n\t\t    %running_mean.249 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.35)\n\t\t    %bias.291 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.35)\n\t\t    %weight.539 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.35)\n\t\t-   %input.273 : Tensor = aten::batch_norm(%input.271, %weight.539, %bias.291, %running_mean.249, %running_var.249, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.273 : Tensor = aten::batch_norm(%input.271, %weight.539, %bias.291, %running_mean.249, %running_var.249, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.275 : Tensor = aten::hardtanh_(%input.273, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.275 : Tensor = aten::hardtanh_(%input.273, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.541 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.33)\n\t\t-   %1131 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?    ^^^^                                 - -    - -\n\t\t+   %968 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?    ^^^                                +     +\n\t\t+   %969 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t-   %1132 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?    ^^^^                                 - -    - -\n\t\t+   %970 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?    ^^^                                +     +\n\t\t-   %1133 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?     ---                                 ^^^    ^^^\n\t\t+   %971 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?    ++                                 + ^   + ^\n\t\t+   %input.277 : Tensor = aten::_convolution(%input.275, %weight.541, %913, %968, %969, %970, %916, %971, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1134 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t-   %input.277 : Tensor = aten::_convolution(%input.275, %weight.541, %1045, %1131, %1132, %1133, %1048, %1134, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.251 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.33)\n\t\t    %running_mean.251 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.33)\n\t\t    %bias.293 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.33)\n\t\t    %weight.543 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.33)\n\t\t-   %input.279 : Tensor = aten::batch_norm(%input.277, %weight.543, %bias.293, %running_mean.251, %running_var.251, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.279 : Tensor = aten::batch_norm(%input.277, %weight.543, %bias.293, %running_mean.251, %running_var.251, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %bn3.35 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_1.13)\n\t\t    %conv_pwl.35 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_1.13)\n\t\t    %se.37 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_1.13)\n\t\t    %act2.37 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_1.13)\n\t\t    %bn2.37 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.13)\n\t\t    %conv_dw.37 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_1.13)\n\t\t    %act1.37 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_1.13)\n\t\t    %bn1.37 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.13)\n\t\t    %conv_pw.37 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_1.13)\n\t\t    %weight.545 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.37)\n\t\t-   %1151 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?    ^^^^                                 - -    - -\n\t\t+   %988 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?    ^^^                                +     +\n\t\t+   %989 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t-   %1152 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?    ^^^^                                 - -    - -\n\t\t+   %990 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?    ^^^                                +     +\n\t\t-   %1153 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?     ---                                 ^^^    ^^^\n\t\t+   %991 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?    ++                                 + ^   + ^\n\t\t-   %1154 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t-   %input.281 : Tensor = aten::_convolution(%input.279, %weight.545, %1045, %1151, %1152, %1153, %1048, %1154, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.281 : Tensor = aten::_convolution(%input.279, %weight.545, %913, %988, %989, %990, %916, %991, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^    ^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.253 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.37)\n\t\t    %running_mean.253 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.37)\n\t\t    %bias.295 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.37)\n\t\t    %weight.547 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.37)\n\t\t-   %input.283 : Tensor = aten::batch_norm(%input.281, %weight.547, %bias.295, %running_mean.253, %running_var.253, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.283 : Tensor = aten::batch_norm(%input.281, %weight.547, %bias.295, %running_mean.253, %running_var.253, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.285 : Tensor = aten::hardtanh_(%input.283, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.285 : Tensor = aten::hardtanh_(%input.283, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.549 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.37)\n\t\t-   %1163 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1000 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t?     ^^^                                +     +\n\t\t-   %1164 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t-   %1165 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t-   %1166 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t?      --                                ^ -    ^ -\n\t\t+   %1001 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t?     ++                                 ^     ^\n\t\t+   %1002 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t+   %1003 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t-   %input.287 : Tensor = aten::_convolution(%input.285, %weight.549, %1045, %1163, %1164, %1165, %1048, %1166, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^      ^  ^^^^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.287 : Tensor = aten::_convolution(%input.285, %weight.549, %913, %1000, %1001, %1002, %916, %1003, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^  ++++++    ^^^^^^^  ^^^^  ^^^^^^^^^^^^\n\t\t    %running_var.255 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.37)\n\t\t    %running_mean.255 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.37)\n\t\t    %bias.297 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.37)\n\t\t    %weight.551 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.37)\n\t\t-   %input.289 : Tensor = aten::batch_norm(%input.287, %weight.551, %bias.297, %running_mean.255, %running_var.255, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.289 : Tensor = aten::batch_norm(%input.287, %weight.551, %bias.297, %running_mean.255, %running_var.255, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.291 : Tensor = aten::hardtanh_(%input.289, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.291 : Tensor = aten::hardtanh_(%input.289, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.553 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.35)\n\t\t-   %1175 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?      ^^                                 - -    - -\n\t\t+   %1012 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?     + ^                                +     +\n\t\t+   %1013 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t-   %1176 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?      ^^                                 - -    - -\n\t\t+   %1014 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?     + ^                                +     +\n\t\t-   %1177 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?      ^^                                 ^^^    ^^^\n\t\t+   %1015 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?     + ^                                + ^   + ^\n\t\t-   %1178 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t-   %input.293 : Tensor = aten::_convolution(%input.291, %weight.553, %1045, %1175, %1176, %1177, %1048, %1178, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^    ^  ^^^^^  ---------------------------------------------------------\n\t\t+   %input.293 : Tensor = aten::_convolution(%input.291, %weight.553, %913, %1012, %1013, %1014, %916, %1015, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^  ^^^^\n\t\t    %running_var.257 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.35)\n\t\t    %running_mean.257 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.35)\n\t\t    %bias.299 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.35)\n\t\t    %weight.555 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.35)\n\t\t-   %x.45 : Tensor = aten::batch_norm(%input.293, %weight.555, %bias.299, %running_mean.257, %running_var.257, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.45 : Tensor = aten::batch_norm(%input.293, %weight.555, %bias.299, %running_mean.257, %running_var.257, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.295 : Tensor = aten::add_(%x.45, %input.279, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                         ^^^\n\t\t+   %input.295 : Tensor = aten::add_(%x.45, %input.279, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        + ^\n\t\t    %bn3.37 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_2.11)\n\t\t    %conv_pwl.37 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_2.11)\n\t\t    %se.39 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_2.11)\n\t\t    %act2.39 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_2.11)\n\t\t    %bn2.39 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_2.11)\n\t\t    %conv_dw.39 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_2.11)\n\t\t    %act1.39 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_2.11)\n\t\t    %bn1.39 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_2.11)\n\t\t    %conv_pw.39 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_2.11)\n\t\t    %weight.557 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.39)\n\t\t-   %1196 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1033 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                +     +\n\t\t+   %1034 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t-   %1197 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1035 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                +     +\n\t\t-   %1198 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1036 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                + ^   + ^\n\t\t+   %input.297 : Tensor = aten::_convolution(%input.295, %weight.557, %913, %1033, %1034, %1035, %916, %1036, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1199 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t-   %input.297 : Tensor = aten::_convolution(%input.295, %weight.557, %1045, %1196, %1197, %1198, %1048, %1199, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.259 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.39)\n\t\t    %running_mean.259 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.39)\n\t\t    %bias.301 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.39)\n\t\t    %weight.559 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.39)\n\t\t-   %input.299 : Tensor = aten::batch_norm(%input.297, %weight.559, %bias.301, %running_mean.259, %running_var.259, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.299 : Tensor = aten::batch_norm(%input.297, %weight.559, %bias.301, %running_mean.259, %running_var.259, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.301 : Tensor = aten::hardtanh_(%input.299, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.301 : Tensor = aten::hardtanh_(%input.299, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.561 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.39)\n\t\t-   %1208 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?     - ^                                 - -    - -\n\t\t+   %1045 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?      ^^                                +     +\n\t\t+   %1046 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t-   %1209 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?     - ^                                 --     --\n\t\t+   %1047 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?      ^^                                +     +\n\t\t-   %1210 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?     --                                  ^^^    ^^^\n\t\t+   %1048 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?      ++                                + ^   + ^\n\t\t+   %input.303 : Tensor = aten::_convolution(%input.301, %weight.561, %913, %1045, %1046, %1047, %916, %1048, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1211 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t-   %input.303 : Tensor = aten::_convolution(%input.301, %weight.561, %1045, %1208, %1209, %1210, %1048, %1211, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.261 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.39)\n\t\t    %running_mean.261 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.39)\n\t\t    %bias.303 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.39)\n\t\t    %weight.563 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.39)\n\t\t-   %input.305 : Tensor = aten::batch_norm(%input.303, %weight.563, %bias.303, %running_mean.261, %running_var.261, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.305 : Tensor = aten::batch_norm(%input.303, %weight.563, %bias.303, %running_mean.261, %running_var.261, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.307 : Tensor = aten::hardtanh_(%input.305, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.307 : Tensor = aten::hardtanh_(%input.305, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.565 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.37)\n\t\t-   %1220 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?     --                                  - -    - -\n\t\t+   %1057 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?      ++                                +     +\n\t\t+   %1058 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t-   %1221 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1059 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?     ^^^                                +     +\n\t\t-   %1222 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1060 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?     ^^^                                + ^   + ^\n\t\t+   %input.309 : Tensor = aten::_convolution(%input.307, %weight.565, %913, %1057, %1058, %1059, %916, %1060, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1223 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t-   %input.309 : Tensor = aten::_convolution(%input.307, %weight.565, %1045, %1220, %1221, %1222, %1048, %1223, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.263 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.37)\n\t\t    %running_mean.263 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.37)\n\t\t    %bias.305 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.37)\n\t\t    %weight.567 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.37)\n\t\t-   %x.47 : Tensor = aten::batch_norm(%input.309, %weight.567, %bias.305, %running_mean.263, %running_var.263, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.47 : Tensor = aten::batch_norm(%input.309, %weight.567, %bias.305, %running_mean.263, %running_var.263, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.311 : Tensor = aten::add_(%x.47, %input.295, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                         ^^^\n\t\t+   %input.311 : Tensor = aten::add_(%x.47, %input.295, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        + ^\n\t\t    %bn3.39 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_3.7)\n\t\t    %conv_pwl.39 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_3.7)\n\t\t    %se.41 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_3.7)\n\t\t    %act2.41 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_3.7)\n\t\t    %bn2.41 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_3.7)\n\t\t    %conv_dw.41 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_3.7)\n\t\t    %act1.41 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_3.7)\n\t\t    %bn1.41 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_3.7)\n\t\t    %conv_pw.41 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_3.7)\n\t\t    %weight.569 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.41)\n\t\t-   %1241 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1078 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                +     +\n\t\t+   %1079 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t-   %1242 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1080 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                +     +\n\t\t-   %1243 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1081 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                + ^   + ^\n\t\t+   %input.313 : Tensor = aten::_convolution(%input.311, %weight.569, %913, %1078, %1079, %1080, %916, %1081, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1244 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t-   %input.313 : Tensor = aten::_convolution(%input.311, %weight.569, %1045, %1241, %1242, %1243, %1048, %1244, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.265 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.41)\n\t\t    %running_mean.265 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.41)\n\t\t    %bias.307 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.41)\n\t\t    %weight.571 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.41)\n\t\t-   %input.315 : Tensor = aten::batch_norm(%input.313, %weight.571, %bias.307, %running_mean.265, %running_var.265, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.315 : Tensor = aten::batch_norm(%input.313, %weight.571, %bias.307, %running_mean.265, %running_var.265, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.317 : Tensor = aten::hardtanh_(%input.315, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.317 : Tensor = aten::hardtanh_(%input.315, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.573 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.41)\n\t\t+   %1090 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t+   %1091 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t-   %1253 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t?      --                                 - -    - -\n\t\t+   %1092 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t?     ++                                 +     +\n\t\t-   %1254 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1093 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t?     ^^^                                + ^   + ^\n\t\t+   %input.319 : Tensor = aten::_convolution(%input.317, %weight.573, %913, %1090, %1091, %1092, %916, %1093, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1255 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t-   %1256 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t-   %input.319 : Tensor = aten::_convolution(%input.317, %weight.573, %1045, %1253, %1254, %1255, %1048, %1256, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.267 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.41)\n\t\t    %running_mean.267 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.41)\n\t\t    %bias.309 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.41)\n\t\t    %weight.575 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.41)\n\t\t-   %input.321 : Tensor = aten::batch_norm(%input.319, %weight.575, %bias.309, %running_mean.267, %running_var.267, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.321 : Tensor = aten::batch_norm(%input.319, %weight.575, %bias.309, %running_mean.267, %running_var.267, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.323 : Tensor = aten::hardtanh_(%input.321, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.323 : Tensor = aten::hardtanh_(%input.321, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.577 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.39)\n\t\t-   %1265 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?      --                                 - -    - -\n\t\t+   %1102 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?     ++                                 +     +\n\t\t+   %1103 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t-   %1266 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1104 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?     ^^^                                +     +\n\t\t-   %1267 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1105 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?     ^^^                                + ^   + ^\n\t\t-   %1268 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t-   %input.325 : Tensor = aten::_convolution(%input.323, %weight.577, %1045, %1265, %1266, %1267, %1048, %1268, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^    ^^ ^^^^^^ ^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.325 : Tensor = aten::_convolution(%input.323, %weight.577, %913, %1102, %1103, %1104, %916, %1105, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^ ^^^^^ ^^^^^    ^^^\n\t\t    %running_var.269 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.39)\n\t\t    %running_mean.269 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.39)\n\t\t    %bias.311 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.39)\n\t\t    %weight.579 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.39)\n\t\t-   %x.49 : Tensor = aten::batch_norm(%input.325, %weight.579, %bias.311, %running_mean.269, %running_var.269, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.49 : Tensor = aten::batch_norm(%input.325, %weight.579, %bias.311, %running_mean.269, %running_var.269, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.327 : Tensor = aten::add_(%x.49, %input.311, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                         ^^^\n\t\t+   %input.327 : Tensor = aten::add_(%x.49, %input.311, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        + ^\n\t\t    %bn3.41 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_4.7)\n\t\t    %conv_pwl.41 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_4.7)\n\t\t    %se.43 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_4.7)\n\t\t    %act2.43 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_4.7)\n\t\t    %bn2.43 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_4.7)\n\t\t    %conv_dw.43 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_4.7)\n\t\t    %act1.43 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_4.7)\n\t\t    %bn1.43 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_4.7)\n\t\t    %conv_pw.43 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_4.7)\n\t\t    %weight.581 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.43)\n\t\t-   %1286 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?      ^^                                 - -    - -\n\t\t+   %1123 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?     + ^                                +     +\n\t\t+   %1124 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t-   %1287 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?      ^^                                 - -    - -\n\t\t+   %1125 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?     + ^                                +     +\n\t\t-   %1288 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?      ^^                                 ^^^    ^^^\n\t\t+   %1126 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?     + ^                                + ^   + ^\n\t\t+   %input.329 : Tensor = aten::_convolution(%input.327, %weight.581, %913, %1123, %1124, %1125, %916, %1126, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1289 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t-   %input.329 : Tensor = aten::_convolution(%input.327, %weight.581, %1045, %1286, %1287, %1288, %1048, %1289, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.271 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.43)\n\t\t    %running_mean.271 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.43)\n\t\t    %bias.313 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.43)\n\t\t    %weight.583 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.43)\n\t\t-   %input.331 : Tensor = aten::batch_norm(%input.329, %weight.583, %bias.313, %running_mean.271, %running_var.271, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.331 : Tensor = aten::batch_norm(%input.329, %weight.583, %bias.313, %running_mean.271, %running_var.271, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.333 : Tensor = aten::hardtanh_(%input.331, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.333 : Tensor = aten::hardtanh_(%input.331, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.585 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.43)\n\t\t-   %1298 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t-   %1299 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t-   %1300 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t?      ^^                                 - -    - -\n\t\t+   %1135 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t?     + ^                                +     +\n\t\t-   %1301 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t?      ^^                                ^ -    ^ -\n\t\t+   %1136 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t?     + ^                                ^     ^\n\t\t-   %input.335 : Tensor = aten::_convolution(%input.333, %weight.585, %1045, %1298, %1299, %1300, %1048, %1301, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %1137 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t+   %1138 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t+   %input.335 : Tensor = aten::_convolution(%input.333, %weight.585, %913, %1135, %1136, %1137, %916, %1138, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.273 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.43)\n\t\t    %running_mean.273 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.43)\n\t\t    %bias.315 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.43)\n\t\t    %weight.587 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.43)\n\t\t-   %input.337 : Tensor = aten::batch_norm(%input.335, %weight.587, %bias.315, %running_mean.273, %running_var.273, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.337 : Tensor = aten::batch_norm(%input.335, %weight.587, %bias.315, %running_mean.273, %running_var.273, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.339 : Tensor = aten::hardtanh_(%input.337, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.339 : Tensor = aten::hardtanh_(%input.337, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.589 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.41)\n\t\t-   %1310 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?     - ^                                 - -    - -\n\t\t+   %1147 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?      ^^                                +     +\n\t\t+   %1148 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t-   %1311 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?     - ^                                 - -    - -\n\t\t+   %1149 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?      ^^                                +     +\n\t\t-   %1312 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?     - ^                                 ^^^    ^^^\n\t\t+   %1150 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?      ^^                                + ^   + ^\n\t\t-   %1313 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t-   %input.341 : Tensor = aten::_convolution(%input.339, %weight.589, %1045, %1310, %1311, %1312, %1048, %1313, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.341 : Tensor = aten::_convolution(%input.339, %weight.589, %913, %1147, %1148, %1149, %916, %1150, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^    ^^^^^^^^^^^^^^^\n\t\t    %running_var.275 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.41)\n\t\t    %running_mean.275 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.41)\n\t\t    %bias.317 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.41)\n\t\t    %weight.591 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.41)\n\t\t-   %x.51 : Tensor = aten::batch_norm(%input.341, %weight.591, %bias.317, %running_mean.275, %running_var.275, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.51 : Tensor = aten::batch_norm(%input.341, %weight.591, %bias.317, %running_mean.275, %running_var.275, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.343 : Tensor = aten::add_(%x.51, %input.327, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                         ^^^\n\t\t+   %input.343 : Tensor = aten::add_(%x.51, %input.327, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        + ^\n\t\t    %bn3.43 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_5.1)\n\t\t    %conv_pwl.43 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_5.1)\n\t\t    %se.45 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_5.1)\n\t\t    %act2.45 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_5.1)\n\t\t    %bn2.45 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_5.1)\n\t\t    %conv_dw.45 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_5.1)\n\t\t    %act1.45 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_5.1)\n\t\t    %bn1.45 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_5.1)\n\t\t    %conv_pw.45 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_5.1)\n\t\t    %weight.593 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.45)\n\t\t-   %1331 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?     --                                  - -    - -\n\t\t+   %1168 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?      ++                                +     +\n\t\t+   %1169 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t-   %1332 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1170 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?     ^^^                                +     +\n\t\t-   %1333 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1171 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?     ^^^                                + ^   + ^\n\t\t+   %input.345 : Tensor = aten::_convolution(%input.343, %weight.593, %913, %1168, %1169, %1170, %916, %1171, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1334 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t-   %input.345 : Tensor = aten::_convolution(%input.343, %weight.593, %1045, %1331, %1332, %1333, %1048, %1334, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.277 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.45)\n\t\t    %running_mean.277 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.45)\n\t\t    %bias.319 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.45)\n\t\t    %weight.595 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.45)\n\t\t-   %input.347 : Tensor = aten::batch_norm(%input.345, %weight.595, %bias.319, %running_mean.277, %running_var.277, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.347 : Tensor = aten::batch_norm(%input.345, %weight.595, %bias.319, %running_mean.277, %running_var.277, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.349 : Tensor = aten::hardtanh_(%input.347, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.349 : Tensor = aten::hardtanh_(%input.347, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.597 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.45)\n\t\t-   %1343 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1180 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t?     ^^^                                +     +\n\t\t-   %1344 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t-   %1345 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t-   %1346 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t?     ^^^                                ^ -    ^ -\n\t\t+   %1181 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t?     ^^^                                ^     ^\n\t\t+   %1182 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t+   %1183 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t-   %input.351 : Tensor = aten::_convolution(%input.349, %weight.597, %1045, %1343, %1344, %1345, %1048, %1346, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.351 : Tensor = aten::_convolution(%input.349, %weight.597, %913, %1180, %1181, %1182, %916, %1183, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.279 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.45)\n\t\t    %running_mean.279 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.45)\n\t\t    %bias.321 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.45)\n\t\t    %weight.599 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.45)\n\t\t-   %input.353 : Tensor = aten::batch_norm(%input.351, %weight.599, %bias.321, %running_mean.279, %running_var.279, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.353 : Tensor = aten::batch_norm(%input.351, %weight.599, %bias.321, %running_mean.279, %running_var.279, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.355 : Tensor = aten::hardtanh_(%input.353, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.355 : Tensor = aten::hardtanh_(%input.353, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.601 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.43)\n\t\t-   %1355 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1192 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^^^                                +     +\n\t\t+   %1193 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t-   %1356 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1194 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^^^                                +     +\n\t\t-   %1357 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^ -                                 ^^^    ^^^\n\t\t+   %1195 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^^                                 + ^   + ^\n\t\t+   %input.357 : Tensor = aten::_convolution(%input.355, %weight.601, %913, %1192, %1193, %1194, %916, %1195, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1358 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t-   %input.357 : Tensor = aten::_convolution(%input.355, %weight.601, %1045, %1355, %1356, %1357, %1048, %1358, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.281 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.43)\n\t\t    %running_mean.281 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.43)\n\t\t    %bias.323 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.43)\n\t\t    %weight.603 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.43)\n\t\t-   %x.53 : Tensor = aten::batch_norm(%input.357, %weight.603, %bias.323, %running_mean.281, %running_var.281, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.53 : Tensor = aten::batch_norm(%input.357, %weight.603, %bias.323, %running_mean.281, %running_var.281, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.359 : Tensor = aten::add_(%x.53, %input.343, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                         ^^^\n\t\t+   %input.359 : Tensor = aten::add_(%x.53, %input.343, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        + ^\n\t\t    %_0.21 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_1.15)\n\t\t    %bn3 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.21)\n\t\t    %conv_pwl : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.21)\n\t\t    %se : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.21)\n\t\t    %act2 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.21)\n\t\t    %bn2 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.21)\n\t\t    %conv_dw : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_0.21)\n\t\t    %act1 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.21)\n\t\t    %bn1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.21)\n\t\t    %conv_pw : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.21)\n\t\t    %weight.605 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw)\n\t\t-   %1377 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1214 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^^^                                +     +\n\t\t+   %1215 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t-   %1378 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1216 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^^^                                +     +\n\t\t-   %1379 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^ -                                 ^^^    ^^^\n\t\t+   %1217 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^^                                 + ^   + ^\n\t\t+   %input.361 : Tensor = aten::_convolution(%input.359, %weight.605, %913, %1214, %1215, %1216, %916, %1217, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1380 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t-   %input.361 : Tensor = aten::_convolution(%input.359, %weight.605, %1045, %1377, %1378, %1379, %1048, %1380, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.283 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1)\n\t\t    %running_mean.283 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1)\n\t\t    %bias.325 : Tensor = prim::GetAttr[name=\"bias\"](%bn1)\n\t\t    %weight.607 : Tensor = prim::GetAttr[name=\"weight\"](%bn1)\n\t\t-   %input.363 : Tensor = aten::batch_norm(%input.361, %weight.607, %bias.325, %running_mean.283, %running_var.283, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.363 : Tensor = aten::batch_norm(%input.361, %weight.607, %bias.325, %running_mean.283, %running_var.283, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.365 : Tensor = aten::hardtanh_(%input.363, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.365 : Tensor = aten::hardtanh_(%input.363, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.609 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw)\n\t\t-   %1389 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t-   %1390 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t-   %1391 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t-   %1392 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t?     --                                  - -    - -\n\t\t+   %1226 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t?      ++                                +     +\n\t\t-   %input.367 : Tensor = aten::_convolution(%input.365, %weight.609, %1045, %1389, %1390, %1391, %1048, %1392, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %1227 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t+   %1228 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t+   %1229 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t+   %input.367 : Tensor = aten::_convolution(%input.365, %weight.609, %913, %1226, %1227, %1228, %916, %1229, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.285 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2)\n\t\t    %running_mean.285 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2)\n\t\t    %bias.327 : Tensor = prim::GetAttr[name=\"bias\"](%bn2)\n\t\t    %weight.611 : Tensor = prim::GetAttr[name=\"weight\"](%bn2)\n\t\t-   %input.369 : Tensor = aten::batch_norm(%input.367, %weight.611, %bias.327, %running_mean.285, %running_var.285, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.369 : Tensor = aten::batch_norm(%input.367, %weight.611, %bias.327, %running_mean.285, %running_var.285, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.371 : Tensor = aten::hardtanh_(%input.369, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.371 : Tensor = aten::hardtanh_(%input.369, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.613 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl)\n\t\t+   %1238 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t+   %1239 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t-   %1401 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t?       -                                 - -    - -\n\t\t+   %1240 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t?     +                                  +     +\n\t\t-   %1402 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t?      ^^                                 ^^^    ^^^\n\t\t+   %1241 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t?     + ^                                + ^   + ^\n\t\t+   %input.373 : Tensor = aten::_convolution(%input.371, %weight.613, %913, %1238, %1239, %1240, %916, %1241, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1403 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t-   %1404 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t-   %input.373 : Tensor = aten::_convolution(%input.371, %weight.613, %1045, %1401, %1402, %1403, %1048, %1404, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var : Tensor = prim::GetAttr[name=\"running_var\"](%bn3)\n\t\t    %running_mean : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3)\n\t\t    %bias.329 : Tensor = prim::GetAttr[name=\"bias\"](%bn3)\n\t\t    %weight.615 : Tensor = prim::GetAttr[name=\"weight\"](%bn3)\n\t\t-   %input.375 : Tensor = aten::batch_norm(%input.373, %weight.615, %bias.329, %running_mean, %running_var, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.375 : Tensor = aten::batch_norm(%input.373, %weight.615, %bias.329, %running_mean, %running_var, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %1411 : bool = prim::Constant[value=1](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t+   %1248 : bool = prim::Constant[value=1](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     + ^\n\t\t-   %1412 : int = prim::Constant[value=0](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t+   %1249 : int = prim::Constant[value=0](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     + ^\n\t\t-   %1413 : bool = prim::Constant[value=0](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1250 : bool = prim::Constant[value=0](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1414 : int = prim::Constant[value=1](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^ -\n\t\t+   %1251 : int = prim::Constant[value=1](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^\n\t\t-   %1415 : NoneType = prim::Constant(), scope: __module.scratch.layer1_rn\n\t\t?     ^^\n\t\t+   %1252 : NoneType = prim::Constant(), scope: __module.scratch.layer1_rn\n\t\t?     ^ +\n\t\t    %weight.617 : Tensor = prim::GetAttr[name=\"weight\"](%layer1_rn)\n\t\t-   %1417 : int[] = prim::ListConstruct(%1414, %1414), scope: __module.scratch.layer1_rn\n\t\t?      --                                 ^ -    ^ -\n\t\t+   %1254 : int[] = prim::ListConstruct(%1251, %1251), scope: __module.scratch.layer1_rn\n\t\t?     ++                                  ^^     ^^\n\t\t-   %1418 : int[] = prim::ListConstruct(%1414, %1414), scope: __module.scratch.layer1_rn\n\t\t?     ^^^                                 ^ -    ^ -\n\t\t+   %1255 : int[] = prim::ListConstruct(%1251, %1251), scope: __module.scratch.layer1_rn\n\t\t?     ^^^                                 ^^     ^^\n\t\t-   %1419 : int[] = prim::ListConstruct(%1414, %1414), scope: __module.scratch.layer1_rn\n\t\t?     ^^^                                 ^ -    ^ -\n\t\t+   %1256 : int[] = prim::ListConstruct(%1251, %1251), scope: __module.scratch.layer1_rn\n\t\t?     ^^^                                 ^^     ^^\n\t\t-   %1420 : int[] = prim::ListConstruct(%1412, %1412), scope: __module.scratch.layer1_rn\n\t\t?     - ^                                    ---- ^^\n\t\t+   %1257 : int[] = prim::ListConstruct(%1249, %1249), scope: __module.scratch.layer1_rn\n\t\t?      ^^                                 + ++++   ^\n\t\t-   %input.429 : Tensor = aten::_convolution(%input.61, %weight.617, %1415, %1417, %1418, %1419, %1413, %1420, %1414, %1413, %1413, %1411, %1411), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.429 : Tensor = aten::_convolution(%input.61, %weight.617, %1252, %1254, %1255, %1256, %1250, %1257, %1251, %1250, %1250, %1248, %1248), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1422 : bool = prim::Constant[value=1](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     - ^\n\t\t+   %1259 : bool = prim::Constant[value=1](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t-   %1423 : int = prim::Constant[value=0](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     - ^\n\t\t+   %1260 : int = prim::Constant[value=0](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t-   %1424 : bool = prim::Constant[value=0](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     - ^\n\t\t+   %1261 : bool = prim::Constant[value=0](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t-   %1425 : int = prim::Constant[value=1](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     - ^\n\t\t+   %1262 : int = prim::Constant[value=1](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t-   %1426 : NoneType = prim::Constant(), scope: __module.scratch.layer2_rn\n\t\t?     -\n\t\t+   %1263 : NoneType = prim::Constant(), scope: __module.scratch.layer2_rn\n\t\t?       +\n\t\t    %weight.619 : Tensor = prim::GetAttr[name=\"weight\"](%layer2_rn)\n\t\t+   %1265 : int[] = prim::ListConstruct(%1262, %1262), scope: __module.scratch.layer2_rn\n\t\t+   %1266 : int[] = prim::ListConstruct(%1262, %1262), scope: __module.scratch.layer2_rn\n\t\t+   %1267 : int[] = prim::ListConstruct(%1262, %1262), scope: __module.scratch.layer2_rn\n\t\t-   %1428 : int[] = prim::ListConstruct(%1425, %1425), scope: __module.scratch.layer2_rn\n\t\t?     -                                   - ^    - ^\n\t\t+   %1268 : int[] = prim::ListConstruct(%1260, %1260), scope: __module.scratch.layer2_rn\n\t\t?      +                                   ^^     ^^\n\t\t+   %input.409 : Tensor = aten::_convolution(%input.107, %weight.619, %1263, %1265, %1266, %1267, %1261, %1268, %1262, %1261, %1261, %1259, %1259), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1429 : int[] = prim::ListConstruct(%1425, %1425), scope: __module.scratch.layer2_rn\n\t\t-   %1430 : int[] = prim::ListConstruct(%1425, %1425), scope: __module.scratch.layer2_rn\n\t\t-   %1431 : int[] = prim::ListConstruct(%1423, %1423), scope: __module.scratch.layer2_rn\n\t\t-   %input.409 : Tensor = aten::_convolution(%input.107, %weight.619, %1426, %1428, %1429, %1430, %1424, %1431, %1425, %1424, %1424, %1422, %1422), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1433 : bool = prim::Constant[value=1](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1270 : bool = prim::Constant[value=1](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1434 : int = prim::Constant[value=0](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1271 : int = prim::Constant[value=0](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1435 : bool = prim::Constant[value=0](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1272 : bool = prim::Constant[value=0](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1436 : int = prim::Constant[value=1](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^ -\n\t\t+   %1273 : int = prim::Constant[value=1](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^\n\t\t-   %1437 : NoneType = prim::Constant(), scope: __module.scratch.layer3_rn\n\t\t?      --\n\t\t+   %1274 : NoneType = prim::Constant(), scope: __module.scratch.layer3_rn\n\t\t?     ++\n\t\t    %weight.621 : Tensor = prim::GetAttr[name=\"weight\"](%layer3_rn)\n\t\t-   %1439 : int[] = prim::ListConstruct(%1436, %1436), scope: __module.scratch.layer3_rn\n\t\t-   %1440 : int[] = prim::ListConstruct(%1436, %1436), scope: __module.scratch.layer3_rn\n\t\t-   %1441 : int[] = prim::ListConstruct(%1436, %1436), scope: __module.scratch.layer3_rn\n\t\t-   %1442 : int[] = prim::ListConstruct(%1434, %1434), scope: __module.scratch.layer3_rn\n\t\t?     --                                  ^ -    ^ -\n\t\t+   %1276 : int[] = prim::ListConstruct(%1273, %1273), scope: __module.scratch.layer3_rn\n\t\t?      ++                                 ^^     ^^\n\t\t+   %1277 : int[] = prim::ListConstruct(%1273, %1273), scope: __module.scratch.layer3_rn\n\t\t+   %1278 : int[] = prim::ListConstruct(%1273, %1273), scope: __module.scratch.layer3_rn\n\t\t+   %1279 : int[] = prim::ListConstruct(%1271, %1271), scope: __module.scratch.layer3_rn\n\t\t-   %input.389 : Tensor = aten::_convolution(%input.265, %weight.621, %1437, %1439, %1440, %1441, %1435, %1442, %1436, %1435, %1435, %1433, %1433), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                        ^^^^^^^^     ^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.389 : Tensor = aten::_convolution(%input.265, %weight.621, %1274, %1276, %1277, %1278, %1272, %1279, %1273, %1272, %1272, %1270, %1270), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ++ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^     ^^^\n\t\t-   %1444 : bool = prim::Constant[value=1](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1281 : bool = prim::Constant[value=1](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1445 : int = prim::Constant[value=0](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1282 : int = prim::Constant[value=0](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1446 : bool = prim::Constant[value=0](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1283 : bool = prim::Constant[value=0](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1447 : int = prim::Constant[value=1](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      --\n\t\t+   %1284 : int = prim::Constant[value=1](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ++\n\t\t-   %1448 : NoneType = prim::Constant(), scope: __module.scratch.layer4_rn\n\t\t?     ^^\n\t\t+   %1285 : NoneType = prim::Constant(), scope: __module.scratch.layer4_rn\n\t\t?     ^ +\n\t\t    %weight.623 : Tensor = prim::GetAttr[name=\"weight\"](%layer4_rn)\n\t\t-   %1450 : int[] = prim::ListConstruct(%1447, %1447), scope: __module.scratch.layer4_rn\n\t\t-   %1451 : int[] = prim::ListConstruct(%1447, %1447), scope: __module.scratch.layer4_rn\n\t\t-   %1452 : int[] = prim::ListConstruct(%1447, %1447), scope: __module.scratch.layer4_rn\n\t\t?     --                                   --     --\n\t\t+   %1287 : int[] = prim::ListConstruct(%1284, %1284), scope: __module.scratch.layer4_rn\n\t\t?      ++                                 ++     ++\n\t\t-   %1453 : int[] = prim::ListConstruct(%1445, %1445), scope: __module.scratch.layer4_rn\n\t\t?     ^^^                                  --     --\n\t\t+   %1288 : int[] = prim::ListConstruct(%1284, %1284), scope: __module.scratch.layer4_rn\n\t\t?     ^^^                                 ++     ++\n\t\t-   %input.377 : Tensor = aten::_convolution(%input.375, %weight.623, %1448, %1450, %1451, %1452, %1446, %1453, %1447, %1446, %1446, %1444, %1444), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %1289 : int[] = prim::ListConstruct(%1284, %1284), scope: __module.scratch.layer4_rn\n\t\t+   %1290 : int[] = prim::ListConstruct(%1282, %1282), scope: __module.scratch.layer4_rn\n\t\t+   %input.377 : Tensor = aten::_convolution(%input.375, %weight.623, %1285, %1287, %1288, %1289, %1283, %1290, %1284, %1283, %1283, %1281, %1281), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1455 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet4 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t+   %1292 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet4 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t-   %1456 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %1293 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t-   %1457 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t+   %1294 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t-   %1458 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^ ^^^\n\t\t+   %1295 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^ ^^\n\t\t-   %1459 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^ ^^^^^^\n\t\t+   %1296 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^ ^^^^^^^\n\t\t-   %1460 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t+   %1297 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t    %out_conv.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"out_conv\"](%refinenet4)\n\t\t    %resConfUnit2.1 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit2\"](%refinenet4)\n\t\t    %skip_add.1 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit2.1)\n\t\t    %activation_post_process.1 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.1)\n\t\t    %conv2.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit2.1)\n\t\t    %conv1.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit2.1)\n\t\t    %input.379 : Tensor = aten::relu(%input.377), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.331 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.1)\n\t\t    %weight.625 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.1)\n\t\t-   %1470 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t?     ^ -                                 ^^     ^^\n\t\t+   %1307 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t?     ^^                                  ^ +    ^ +\n\t\t+   %1308 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t+   %1309 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t-   %1471 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t?     ^^                                   --     --\n\t\t+   %1310 : int[] = prim::ListConstruct(%1294, %1294), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t?     ^ +                                 ++     ++\n\t\t+   %input.381 : Tensor = aten::_convolution(%input.379, %weight.625, %bias.331, %1307, %1308, %1309, %1295, %1310, %1296, %1295, %1295, %1293, %1293), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1472 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t-   %1473 : int[] = prim::ListConstruct(%1457, %1457), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t-   %input.381 : Tensor = aten::_convolution(%input.379, %weight.625, %bias.331, %1470, %1471, %1472, %1458, %1473, %1459, %1458, %1458, %1456, %1456), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %input.383 : Tensor = aten::relu(%input.381), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.333 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.1)\n\t\t    %weight.627 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.1)\n\t\t+   %1315 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t+   %1316 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t-   %1478 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t?     ^ -                                 ^^     ^^\n\t\t+   %1317 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t?     ^^                                  ^ +    ^ +\n\t\t-   %1479 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t-   %1480 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t?     ^ -                                  --     --\n\t\t+   %1318 : int[] = prim::ListConstruct(%1294, %1294), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t?     ^^                                  ++     ++\n\t\t+   %x.55 : Tensor = aten::_convolution(%input.383, %weight.627, %bias.333, %1315, %1316, %1317, %1295, %1318, %1296, %1295, %1295, %1293, %1293), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1481 : int[] = prim::ListConstruct(%1457, %1457), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t-   %x.55 : Tensor = aten::_convolution(%input.383, %weight.627, %bias.333, %1478, %1479, %1480, %1458, %1481, %1459, %1458, %1458, %1456, %1456), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %input.385 : Tensor = aten::add(%x.55, %input.377, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                        ^^\n\t\t+   %input.385 : Tensor = aten::add(%x.55, %input.377, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                        ^ +\n\t\t-   %1484 : float[] = prim::ListConstruct(%1455, %1455), scope: __module.scratch.refinenet4\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t+   %1321 : float[] = prim::ListConstruct(%1292, %1292), scope: __module.scratch.refinenet4\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t-   %input.387 : Tensor = aten::upsample_bilinear2d(%input.385, %1460, %1456, %1484), scope: __module.scratch.refinenet4 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^^^\n\t\t+   %input.387 : Tensor = aten::upsample_bilinear2d(%input.385, %1297, %1293, %1321), scope: __module.scratch.refinenet4 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^^^\n\t\t    %bias.335 : Tensor = prim::GetAttr[name=\"bias\"](%out_conv.1)\n\t\t    %weight.629 : Tensor = prim::GetAttr[name=\"weight\"](%out_conv.1)\n\t\t+   %1325 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t+   %1326 : int[] = prim::ListConstruct(%1294, %1294), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t+   %1327 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t-   %1488 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t?     ^ -                                  --     --\n\t\t+   %1328 : int[] = prim::ListConstruct(%1294, %1294), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t?     ^^                                  ++     ++\n\t\t+   %x.59 : Tensor = aten::_convolution(%input.387, %weight.629, %bias.335, %1325, %1326, %1327, %1295, %1328, %1296, %1295, %1295, %1293, %1293), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1489 : int[] = prim::ListConstruct(%1457, %1457), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t-   %1490 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t-   %1491 : int[] = prim::ListConstruct(%1457, %1457), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t-   %x.59 : Tensor = aten::_convolution(%input.387, %weight.629, %bias.335, %1488, %1489, %1490, %1458, %1491, %1459, %1458, %1458, %1456, %1456), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1493 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     --\n\t\t+   %1330 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?      ++\n\t\t-   %1494 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %1331 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t-   %1495 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t+   %1332 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t-   %1496 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %1333 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t-   %1497 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^^^^^^^\n\t\t+   %1334 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ++ ^^^^^^\n\t\t-   %1498 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t+   %1335 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t    %out_conv.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"out_conv\"](%refinenet3)\n\t\t    %resConfUnit2.3 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit2\"](%refinenet3)\n\t\t    %skip_add.5 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%refinenet3)\n\t\t    %activation_post_process.5 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.5)\n\t\t    %resConfUnit1.1 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit1\"](%refinenet3)\n\t\t    %skip_add.3 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit1.1)\n\t\t    %activation_post_process.3 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.3)\n\t\t    %conv2.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit1.1)\n\t\t    %conv1.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit1.1)\n\t\t    %input.391 : Tensor = aten::relu(%input.389), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.337 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.3)\n\t\t    %weight.631 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.3)\n\t\t-   %1511 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t-   %1512 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t-   %1513 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t?     --                                   --     --\n\t\t+   %1348 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t?      ++                                 ++     ++\n\t\t-   %1514 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t?     ^^                                   --     --\n\t\t+   %1349 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t?     ^ +                                 ++     ++\n\t\t+   %1350 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t+   %1351 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t-   %input.393 : Tensor = aten::_convolution(%input.391, %weight.631, %bias.337, %1511, %1512, %1513, %1496, %1514, %1497, %1496, %1496, %1494, %1494), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^  ^^^^^ ^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.393 : Tensor = aten::_convolution(%input.391, %weight.631, %bias.337, %1348, %1349, %1350, %1333, %1351, %1334, %1333, %1333, %1331, %1331), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^  ^^^^^ ^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %input.395 : Tensor = aten::relu(%input.393), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.339 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.3)\n\t\t    %weight.633 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.3)\n\t\t-   %1519 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?      ^^                                  --     --\n\t\t+   %1356 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?     + ^                                 ++     ++\n\t\t-   %1520 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?      ^^                                  --     --\n\t\t+   %1357 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?     + ^                                 ++     ++\n\t\t-   %1521 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?      ^^                                  --     --\n\t\t+   %1358 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?     + ^                                 ++     ++\n\t\t-   %1522 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?      ^^                                 ^^^    ^^^\n\t\t+   %1359 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?     + ^                                 ^^^    ^^^\n\t\t-   %x.57 : Tensor = aten::_convolution(%input.395, %weight.633, %bias.339, %1519, %1520, %1521, %1496, %1522, %1497, %1496, %1496, %1494, %1494), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^     ^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.57 : Tensor = aten::_convolution(%input.395, %weight.633, %bias.339, %1356, %1357, %1358, %1333, %1359, %1334, %1333, %1333, %1331, %1331), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %y.1 : Tensor = aten::add(%x.57, %input.389, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                   --\n\t\t+   %y.1 : Tensor = aten::add(%x.57, %input.389, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ++\n\t\t-   %input.397 : Tensor = aten::add(%x.59, %y.1, %1497), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                   --\n\t\t+   %input.397 : Tensor = aten::add(%x.59, %y.1, %1334), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ++\n\t\t    %skip_add.7 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit2.3)\n\t\t    %activation_post_process.7 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.7)\n\t\t    %conv2.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit2.3)\n\t\t    %conv1.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit2.3)\n\t\t    %input.399 : Tensor = aten::relu(%input.397), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.341 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.5)\n\t\t    %weight.635 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.5)\n\t\t-   %1533 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?     - ^                                  --     --\n\t\t+   %1370 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?      ^^                                 ++     ++\n\t\t-   %1534 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?     - ^                                  --     --\n\t\t+   %1371 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?      ^^                                 ++     ++\n\t\t-   %1535 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?     - ^                                  --     --\n\t\t+   %1372 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?      ^^                                 ++     ++\n\t\t-   %1536 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?     - ^                                 ^^^    ^^^\n\t\t+   %1373 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?      ^^                                 ^^^    ^^^\n\t\t-   %input.401 : Tensor = aten::_convolution(%input.399, %weight.635, %bias.341, %1533, %1534, %1535, %1496, %1536, %1497, %1496, %1496, %1494, %1494), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.401 : Tensor = aten::_convolution(%input.399, %weight.635, %bias.341, %1370, %1371, %1372, %1333, %1373, %1334, %1333, %1333, %1331, %1331), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %input.403 : Tensor = aten::relu(%input.401), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.343 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.5)\n\t\t    %weight.637 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.5)\n\t\t-   %1541 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t-   %1542 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t-   %1543 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t?     --                                   --     --\n\t\t+   %1378 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t?      ++                                 ++     ++\n\t\t-   %1544 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t?     ^^^                                  --     --\n\t\t+   %1379 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t?     ^^^                                 ++     ++\n\t\t+   %1380 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t+   %1381 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t-   %x.61 : Tensor = aten::_convolution(%input.403, %weight.637, %bias.343, %1541, %1542, %1543, %1496, %1544, %1497, %1496, %1496, %1494, %1494), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.61 : Tensor = aten::_convolution(%input.403, %weight.637, %bias.343, %1378, %1379, %1380, %1333, %1381, %1334, %1333, %1333, %1331, %1331), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %input.405 : Tensor = aten::add(%x.61, %input.397, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                         --\n\t\t+   %input.405 : Tensor = aten::add(%x.61, %input.397, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                        ++\n\t\t-   %1547 : float[] = prim::ListConstruct(%1493, %1493), scope: __module.scratch.refinenet3\n\t\t?     ^ -                                   --     --\n\t\t+   %1384 : float[] = prim::ListConstruct(%1330, %1330), scope: __module.scratch.refinenet3\n\t\t?     ^^                                     ++     ++\n\t\t-   %input.407 : Tensor = aten::upsample_bilinear2d(%input.405, %1498, %1494, %1547), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^ -\n\t\t+   %input.407 : Tensor = aten::upsample_bilinear2d(%input.405, %1335, %1331, %1384), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^^\n\t\t    %bias.345 : Tensor = prim::GetAttr[name=\"bias\"](%out_conv.3)\n\t\t    %weight.639 : Tensor = prim::GetAttr[name=\"weight\"](%out_conv.3)\n\t\t-   %1551 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t-   %1552 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t-   %1553 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t?     --                                   --     --\n\t\t+   %1388 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t?      ++                                 ++     ++\n\t\t+   %1389 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t-   %1554 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t?     ^^^                                  --     --\n\t\t+   %1390 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t?     ^^^                                 ++     ++\n\t\t+   %1391 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t-   %x.65 : Tensor = aten::_convolution(%input.407, %weight.639, %bias.345, %1551, %1552, %1553, %1496, %1554, %1497, %1496, %1496, %1494, %1494), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.65 : Tensor = aten::_convolution(%input.407, %weight.639, %bias.345, %1388, %1389, %1390, %1333, %1391, %1334, %1333, %1333, %1331, %1331), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1556 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t+   %1393 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t-   %1557 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %1394 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t-   %1558 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^^^^^^^\n\t\t+   %1395 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ++ ^^^^^^\n\t\t-   %1559 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^ ^^\n\t\t+   %1396 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^ ^^^\n\t\t-   %1560 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t+   %1397 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t-   %1561 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t+   %1398 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t    %out_conv.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"out_conv\"](%refinenet2)\n\t\t    %resConfUnit2.5 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit2\"](%refinenet2)\n\t\t    %skip_add.11 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%refinenet2)\n\t\t    %activation_post_process.11 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.11)\n\t\t    %resConfUnit1.3 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit1\"](%refinenet2)\n\t\t    %skip_add.9 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit1.3)\n\t\t    %activation_post_process.9 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.9)\n\t\t    %conv2.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit1.3)\n\t\t    %conv1.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit1.3)\n\t\t    %input.411 : Tensor = aten::relu(%input.409), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.347 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.7)\n\t\t    %weight.641 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.7)\n\t\t+   %1411 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t+   %1412 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t+   %1413 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t-   %1574 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t?     --                                   --     --\n\t\t+   %1414 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t?      ++                                 ++     ++\n\t\t-   %1575 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t-   %1576 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t-   %1577 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t-   %input.413 : Tensor = aten::_convolution(%input.411, %weight.641, %bias.347, %1574, %1575, %1576, %1559, %1577, %1560, %1559, %1559, %1557, %1557), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.413 : Tensor = aten::_convolution(%input.411, %weight.641, %bias.347, %1411, %1412, %1413, %1396, %1414, %1397, %1396, %1396, %1394, %1394), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %input.415 : Tensor = aten::relu(%input.413), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.349 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.7)\n\t\t    %weight.643 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.7)\n\t\t+   %1419 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t+   %1420 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t+   %1421 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t-   %1582 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t?     ^^                                   --     --\n\t\t+   %1422 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t?     ^ +                                 ++     ++\n\t\t-   %1583 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t-   %1584 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t-   %1585 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t-   %x.63 : Tensor = aten::_convolution(%input.415, %weight.643, %bias.349, %1582, %1583, %1584, %1559, %1585, %1560, %1559, %1559, %1557, %1557), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^     ^^^\n\t\t+   %x.63 : Tensor = aten::_convolution(%input.415, %weight.643, %bias.349, %1419, %1420, %1421, %1396, %1422, %1397, %1396, %1396, %1394, %1394), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %y.3 : Tensor = aten::add(%x.63, %input.409, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ^^^\n\t\t+   %y.3 : Tensor = aten::add(%x.63, %input.409, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ^^^\n\t\t-   %input.417 : Tensor = aten::add(%x.65, %y.3, %1560), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ^^^\n\t\t+   %input.417 : Tensor = aten::add(%x.65, %y.3, %1397), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ^^^\n\t\t    %skip_add.13 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit2.5)\n\t\t    %activation_post_process.13 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.13)\n\t\t    %conv2.9 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit2.5)\n\t\t    %conv1.9 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit2.5)\n\t\t    %input.419 : Tensor = aten::relu(%input.417), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.351 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.9)\n\t\t    %weight.645 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.9)\n\t\t+   %1433 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t+   %1434 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t+   %1435 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t-   %1596 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t?     ^^                                   --     --\n\t\t+   %1436 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t?     ^^                                  ++     ++\n\t\t-   %1597 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t-   %1598 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t-   %1599 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t-   %input.421 : Tensor = aten::_convolution(%input.419, %weight.645, %bias.351, %1596, %1597, %1598, %1559, %1599, %1560, %1559, %1559, %1557, %1557), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                   ^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.421 : Tensor = aten::_convolution(%input.419, %weight.645, %bias.351, %1433, %1434, %1435, %1396, %1436, %1397, %1396, %1396, %1394, %1394), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ++++++++++++++++ ^^^^^^^^^^^^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %input.423 : Tensor = aten::relu(%input.421), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.353 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.9)\n\t\t    %weight.647 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.9)\n\t\t+   %1441 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t+   %1442 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t+   %1443 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t-   %1604 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t?     --                                   --     --\n\t\t+   %1444 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t?      ++                                 ++     ++\n\t\t-   %1605 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t-   %1606 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t-   %1607 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t-   %x.67 : Tensor = aten::_convolution(%input.423, %weight.647, %bias.353, %1604, %1605, %1606, %1559, %1607, %1560, %1559, %1559, %1557, %1557), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.67 : Tensor = aten::_convolution(%input.423, %weight.647, %bias.353, %1441, %1442, %1443, %1396, %1444, %1397, %1396, %1396, %1394, %1394), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %input.425 : Tensor = aten::add(%x.67, %input.417, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                        ^^^\n\t\t+   %input.425 : Tensor = aten::add(%x.67, %input.417, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                        ^^^\n\t\t-   %1610 : float[] = prim::ListConstruct(%1556, %1556), scope: __module.scratch.refinenet2\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t+   %1447 : float[] = prim::ListConstruct(%1393, %1393), scope: __module.scratch.refinenet2\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t-   %input.427 : Tensor = aten::upsample_bilinear2d(%input.425, %1561, %1557, %1610), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^^^\n\t\t+   %input.427 : Tensor = aten::upsample_bilinear2d(%input.425, %1398, %1394, %1447), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^^^\n\t\t    %bias.355 : Tensor = prim::GetAttr[name=\"bias\"](%out_conv.5)\n\t\t    %weight.649 : Tensor = prim::GetAttr[name=\"weight\"](%out_conv.5)\n\t\t+   %1451 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t-   %1614 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t?     --                                   --     --\n\t\t+   %1452 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t?      ++                                 ++     ++\n\t\t+   %1453 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t-   %1615 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t?     ^^                                   --     --\n\t\t+   %1454 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t?     ^ +                                 ++     ++\n\t\t-   %1616 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t-   %1617 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t-   %x.71 : Tensor = aten::_convolution(%input.427, %weight.649, %bias.355, %1614, %1615, %1616, %1559, %1617, %1560, %1559, %1559, %1557, %1557), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.71 : Tensor = aten::_convolution(%input.427, %weight.649, %bias.355, %1451, %1452, %1453, %1396, %1454, %1397, %1396, %1396, %1394, %1394), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1619 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?      --\n\t\t+   %1456 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ++\n\t\t+   %1457 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %1458 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %1459 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1620 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      -    ^^^^\n\t\t+   %1460 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     +     ^^^\n\t\t-   %1621 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1622 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1623 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1624 : NoneType = prim::Constant()\n\t\t?      ^^\n\t\t+   %1461 : NoneType = prim::Constant()\n\t\t?     + ^\n\t\t    %out_conv : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"out_conv\"](%refinenet1)\n\t\t    %resConfUnit2 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit2\"](%refinenet1)\n\t\t    %skip_add.17 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%refinenet1)\n\t\t    %activation_post_process.17 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.17)\n\t\t    %resConfUnit1 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit1\"](%refinenet1)\n\t\t    %skip_add.15 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit1)\n\t\t    %activation_post_process.15 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.15)\n\t\t    %conv2.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit1)\n\t\t    %conv1.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit1)\n\t\t    %input.431 : Tensor = aten::relu(%input.429), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.357 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.11)\n\t\t    %weight.651 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.11)\n\t\t-   %1637 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t?     ^^                                   ^^     ^^\n\t\t+   %1474 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t?     ^ +                                 + ^    + ^\n\t\t-   %1638 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t-   %1639 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t-   %1640 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t?     - ^                                  ^^     ^^\n\t\t+   %1475 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t?      ^^                                 + ^    + ^\n\t\t+   %1476 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t+   %1477 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t-   %input.433 : Tensor = aten::_convolution(%input.431, %weight.651, %bias.357, %1637, %1638, %1639, %1622, %1640, %1623, %1622, %1622, %1620, %1620), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                   ^^^^^^ ^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.433 : Tensor = aten::_convolution(%input.431, %weight.651, %bias.357, %1474, %1475, %1476, %1459, %1477, %1460, %1459, %1459, %1457, %1457), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ++++++++++++++++ ^^^^^^^^^^^^^^^^^^^ ^^^^^^^     ^^^^^^^^^^^^^^^^^\n\t\t    %input.435 : Tensor = aten::relu(%input.433), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.359 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.11)\n\t\t    %weight.653 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.11)\n\t\t-   %1645 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t-   %1646 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t-   %1647 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t-   %1648 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t?     -                                    ^^     ^^\n\t\t+   %1482 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t?       +                                 + ^    + ^\n\t\t+   %1483 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t+   %1484 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t+   %1485 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t-   %x.69 : Tensor = aten::_convolution(%input.435, %weight.653, %bias.359, %1645, %1646, %1647, %1622, %1648, %1623, %1622, %1622, %1620, %1620), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.69 : Tensor = aten::_convolution(%input.435, %weight.653, %bias.359, %1482, %1483, %1484, %1459, %1485, %1460, %1459, %1459, %1457, %1457), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ++++++++++++++++++++++++++++++++++++ ^^^^^^^^^^^^^^^^^^^^^     ^^^\n\t\t-   %y : Tensor = aten::add(%x.69, %input.429, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                 ^^\n\t\t+   %y : Tensor = aten::add(%x.69, %input.429, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                + ^\n\t\t-   %input.437 : Tensor = aten::add(%x.71, %y, %1623), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                 ^^\n\t\t+   %input.437 : Tensor = aten::add(%x.71, %y, %1460), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                + ^\n\t\t    %skip_add : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit2)\n\t\t    %activation_post_process : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add)\n\t\t    %conv2 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit2)\n\t\t    %conv1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit2)\n\t\t    %input.439 : Tensor = aten::relu(%input.437), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.361 : Tensor = prim::GetAttr[name=\"bias\"](%conv1)\n\t\t    %weight.655 : Tensor = prim::GetAttr[name=\"weight\"](%conv1)\n\t\t-   %1659 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?      --                                  ^^     ^^\n\t\t+   %1496 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ++                                  + ^    + ^\n\t\t-   %1660 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                  ^^     ^^\n\t\t+   %1497 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                 + ^    + ^\n\t\t-   %1661 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                  ^^     ^^\n\t\t+   %1498 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                 + ^    + ^\n\t\t-   %1662 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1499 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t-   %input.441 : Tensor = aten::_convolution(%input.439, %weight.655, %bias.361, %1659, %1660, %1661, %1622, %1662, %1623, %1622, %1622, %1620, %1620), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.441 : Tensor = aten::_convolution(%input.439, %weight.655, %bias.361, %1496, %1497, %1498, %1459, %1499, %1460, %1459, %1459, %1457, %1457), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %input.443 : Tensor = aten::relu(%input.441), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.363 : Tensor = prim::GetAttr[name=\"bias\"](%conv2)\n\t\t    %weight.657 : Tensor = prim::GetAttr[name=\"weight\"](%conv2)\n\t\t-   %1667 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t-   %1668 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t-   %1669 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t-   %1670 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t?     ^^                                   ^^     ^^\n\t\t+   %1504 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t?     ^ +                                 + ^    + ^\n\t\t+   %1505 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t+   %1506 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t+   %1507 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t-   %x : Tensor = aten::_convolution(%input.443, %weight.657, %bias.363, %1667, %1668, %1669, %1622, %1670, %1623, %1622, %1622, %1620, %1620), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                          ^^     ^^^^^^^^^     ^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x : Tensor = aten::_convolution(%input.443, %weight.657, %bias.363, %1504, %1505, %1506, %1459, %1507, %1460, %1459, %1459, %1457, %1457), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^     ^^^^^^^^^ ^^^^^^^\n\t\t-   %input.445 : Tensor = aten::add(%x, %input.437, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                      ^^\n\t\t+   %input.445 : Tensor = aten::add(%x, %input.437, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                     + ^\n\t\t-   %1673 : float[] = prim::ListConstruct(%1619, %1619), scope: __module.scratch.refinenet1\n\t\t?     ^^^                                    --     --\n\t\t+   %1510 : float[] = prim::ListConstruct(%1456, %1456), scope: __module.scratch.refinenet1\n\t\t?     ^^^                                   ++     ++\n\t\t-   %input.447 : Tensor = aten::upsample_bilinear2d(%input.445, %1624, %1620, %1673), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                  ^^    ^^^    ^^^\n\t\t+   %input.447 : Tensor = aten::upsample_bilinear2d(%input.445, %1461, %1457, %1510), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 + ^    ^^^    ^^^\n\t\t    %bias.365 : Tensor = prim::GetAttr[name=\"bias\"](%out_conv)\n\t\t    %weight.659 : Tensor = prim::GetAttr[name=\"weight\"](%out_conv)\n\t\t+   %1514 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t+   %1515 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t-   %1677 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t?      --                                  ^^     ^^\n\t\t+   %1516 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t?     ++                                  + ^    + ^\n\t\t-   %1678 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t?     ^ -                                 ^^^    ^^^\n\t\t+   %1517 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t?     ^^                                  ^^^    ^^^\n\t\t-   %1679 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t-   %1680 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t-   %input.449 : Tensor = aten::_convolution(%input.447, %weight.659, %bias.365, %1677, %1678, %1679, %1622, %1680, %1623, %1622, %1622, %1620, %1620), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.449 : Tensor = aten::_convolution(%input.447, %weight.659, %bias.365, %1514, %1515, %1516, %1459, %1517, %1460, %1459, %1459, %1457, %1457), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1682 : NoneType = prim::Constant(), scope: __module.scratch.output_conv/__module.scratch.output_conv.1\n\t\t?     ^^^\n\t\t+   %1519 : NoneType = prim::Constant(), scope: __module.scratch.output_conv/__module.scratch.output_conv.1\n\t\t?     ^^^\n\t\t-   %1683 : float = prim::Constant[value=2.](), scope: __module.scratch.output_conv/__module.scratch.output_conv.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t+   %1520 : float = prim::Constant[value=2.](), scope: __module.scratch.output_conv/__module.scratch.output_conv.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t-   %1684 : int = prim::Constant[value=1](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1521 : int = prim::Constant[value=1](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1685 : bool = prim::Constant[value=0](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     --\n\t\t+   %1522 : bool = prim::Constant[value=0](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ++\n\t\t-   %1686 : int = prim::Constant[value=0](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1523 : int = prim::Constant[value=0](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1687 : bool = prim::Constant[value=1](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1524 : bool = prim::Constant[value=1](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t    %_6 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"6\"](%output_conv)\n\t\t    %_5 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name=\"5\"](%output_conv)\n\t\t    %_4 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"4\"](%output_conv)\n\t\t    %_3 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name=\"3\"](%output_conv)\n\t\t    %_2 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"2\"](%output_conv)\n\t\t    %_1 : __torch__.midas.blocks.Interpolate = prim::GetAttr[name=\"1\"](%output_conv)\n\t\t    %_0 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"0\"](%output_conv)\n\t\t    %bias.367 : Tensor = prim::GetAttr[name=\"bias\"](%_0)\n\t\t    %weight.661 : Tensor = prim::GetAttr[name=\"weight\"](%_0)\n\t\t+   %1534 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t+   %1535 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t-   %1697 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t?      --                                 ^^^    ^^^\n\t\t+   %1536 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t?     ++                                  ^^^    ^^^\n\t\t-   %1698 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t-   %1699 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t-   %1700 : int[] = prim::ListConstruct(%1686, %1686), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t?      --                                 ^^^    ^^^\n\t\t+   %1537 : int[] = prim::ListConstruct(%1523, %1523), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t?     ++                                  ^^^    ^^^\n\t\t-   %input.451 : Tensor = aten::_convolution(%input.449, %weight.661, %bias.367, %1697, %1698, %1699, %1685, %1700, %1684, %1685, %1685, %1687, %1687), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.451 : Tensor = aten::_convolution(%input.449, %weight.661, %bias.367, %1534, %1535, %1536, %1522, %1537, %1521, %1522, %1522, %1524, %1524), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1702 : float[] = prim::ListConstruct(%1683, %1683), scope: __module.scratch.output_conv/__module.scratch.output_conv.1\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t+   %1539 : float[] = prim::ListConstruct(%1520, %1520), scope: __module.scratch.output_conv/__module.scratch.output_conv.1\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t-   %input.453 : Tensor = aten::upsample_bilinear2d(%input.451, %1682, %1685, %1702), scope: __module.scratch.output_conv/__module.scratch.output_conv.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^ -------------\n\t\t+   %input.453 : Tensor = aten::upsample_bilinear2d(%input.451, %1519, %1522, %1539), scope: __module.scratch.output_conv/__module.scratch.output_conv.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^^^^^^  +++++++\n\t\t    %bias.369 : Tensor = prim::GetAttr[name=\"bias\"](%_2)\n\t\t    %weight.663 : Tensor = prim::GetAttr[name=\"weight\"](%_2)\n\t\t+   %1543 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t+   %1544 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t+   %1545 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t-   %1706 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t?     ^^                                  ^^^    ^^^\n\t\t+   %1546 : int[] = prim::ListConstruct(%1523, %1523), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t?     ^^                                  ^^^    ^^^\n\t\t-   %1707 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t-   %1708 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t-   %1709 : int[] = prim::ListConstruct(%1686, %1686), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t-   %input.455 : Tensor = aten::_convolution(%input.453, %weight.663, %bias.369, %1706, %1707, %1708, %1685, %1709, %1684, %1685, %1685, %1687, %1687), scope: __module.scratch.output_conv/__module.scratch.output_conv.2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.455 : Tensor = aten::_convolution(%input.453, %weight.663, %bias.369, %1543, %1544, %1545, %1522, %1546, %1521, %1522, %1522, %1524, %1524), scope: __module.scratch.output_conv/__module.scratch.output_conv.2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %input.457 : Tensor = aten::relu(%input.455), scope: __module.scratch.output_conv/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias : Tensor = prim::GetAttr[name=\"bias\"](%_4)\n\t\t    %weight : Tensor = prim::GetAttr[name=\"weight\"](%_4)\n\t\t-   %1714 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^ -                                 ^^^    ^^^\n\t\t+   %1551 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^^                                  ^^^    ^^^\n\t\t-   %1715 : int[] = prim::ListConstruct(%1686, %1686), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     --                                  ^^^    ^^^\n\t\t+   %1552 : int[] = prim::ListConstruct(%1523, %1523), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?      ++                                 ^^^    ^^^\n\t\t-   %1716 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1553 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t-   %1717 : int[] = prim::ListConstruct(%1686, %1686), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1554 : int[] = prim::ListConstruct(%1523, %1523), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t-   %input : Tensor = aten::_convolution(%input.457, %weight, %bias, %1714, %1715, %1716, %1685, %1717, %1684, %1685, %1685, %1687, %1687), scope: __module.scratch.output_conv/__module.scratch.output_conv.4 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input : Tensor = aten::_convolution(%input.457, %weight, %bias, %1551, %1552, %1553, %1522, %1554, %1521, %1522, %1522, %1524, %1524), scope: __module.scratch.output_conv/__module.scratch.output_conv.4 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %out : Tensor = aten::relu_(%input), scope: __module.scratch.output_conv/__module.scratch.output_conv.5 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1471:0\n\t\t    %44 : int = prim::Constant[value=1]() # /root/.cache/torch/hub/intel-isl_MiDaS_master/midas/midas_net_custom.py:105:0\n\t\t    %45 : Tensor = aten::squeeze(%out, %44) # /root/.cache/torch/hub/intel-isl_MiDaS_master/midas/midas_net_custom.py:105:0\n\t\t    return (%45)\n\tFirst diverging operator:\n\tNode diff:\n\t\t- %scratch : __torch__.torch.nn.modules.module.___torch_mangle_983.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t?                                                              ^^\n\t\t+ %scratch : __torch__.torch.nn.modules.module.___torch_mangle_1320.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t?                                                              ^ ++\nERROR: Tensor-valued Constant nodes differed in value across invocations. This often indicates that the tracer has encountered untraceable code.\n\tNode:\n\t\t%54 : Tensor = prim::Constant[value={-2}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\tSource Location:\n\t\t/usr/local/lib/python3.8/dist-packages/torch/_tensor.py(974): __floordiv__\n\t\t/usr/local/lib/python3.8/dist-packages/torch/_tensor.py(40): wrapped\n\t\t/root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py(47): _calc_same_pad\n\t\t/root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py(53): _same_pad_arg\n\t\t/root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py(106): forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1501): _slow_forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1520): _call_impl\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1511): _wrapped_call_impl\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py(217): forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1501): _slow_forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1520): _call_impl\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1511): _wrapped_call_impl\n\t\t/root/.cache/torch/hub/intel-isl_MiDaS_master/midas/midas_net_custom.py(87): forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1501): _slow_forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1520): _call_impl\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1511): _wrapped_call_impl\n\t\t/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py(1074): trace_module\n\t\t/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py(806): trace\n\t\t/tmp/ipykernel_120010/1151187925.py(3): <module>\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3508): run_code\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3448): run_ast_nodes\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3269): run_cell_async\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3064): _run_cell\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3009): run_cell\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py(549): run_cell\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(446): do_execute\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(775): execute_request\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(359): execute_request\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(437): dispatch_shell\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(531): process_one\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(542): dispatch_queue\n\t\t/usr/lib/python3.8/asyncio/events.py(81): _run\n\t\t/usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n\t\t/usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n\t\t/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py(205): start\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py(739): start\n\t\t/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py(1075): launch_instance\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py(17): <module>\n\t\t/usr/lib/python3.8/runpy.py(87): _run_code\n\t\t/usr/lib/python3.8/runpy.py(194): _run_module_as_main\n\tComparison exception: \tScalars are not equal!\n\t\t\n\t\tExpected 1 but got -2.\n\t\tAbsolute difference: 3\n\t\tRelative difference: 3.0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTracingCheckError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m midas \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mintel-isl/MiDaS\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMiDaS_small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m      2\u001b[0m model: torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule \u001b[38;5;241m=\u001b[39m midas\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39meval() \n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m384\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmidas_hybrid.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py:806\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    805\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    807\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    808\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    809\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    811\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    813\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    814\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    815\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    816\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    817\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    818\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    823\u001b[0m ):\n\u001b[1;32m    824\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py:1102\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1090\u001b[0m                 _check_trace(\n\u001b[1;32m   1091\u001b[0m                     check_inputs,\n\u001b[1;32m   1092\u001b[0m                     func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     example_inputs_is_kwarg\u001b[38;5;241m=\u001b[39mexample_inputs_is_kwarg,\n\u001b[1;32m   1100\u001b[0m                 )\n\u001b[1;32m   1101\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1102\u001b[0m                 \u001b[43m_check_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1104\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcheck_trace_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1109\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1110\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39m_trace\u001b[38;5;241m.\u001b[39m_trace_module_map \u001b[38;5;241m=\u001b[39m old_module_map\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py:577\u001b[0m, in \u001b[0;36m_check_trace\u001b[0;34m(check_inputs, func, traced_func, check_tolerance, strict, force_outplace, is_trace_module, _module_class, example_inputs_is_kwarg)\u001b[0m\n\u001b[1;32m    575\u001b[0m diag_info \u001b[38;5;241m=\u001b[39m graph_diagnostic_info()\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m diag_info):\n\u001b[0;32m--> 577\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m TracingCheckError(\u001b[38;5;241m*\u001b[39mdiag_info)\n",
      "\u001b[0;31mTracingCheckError\u001b[0m: Tracing failed sanity checks!\nERROR: Graphs differed across invocations!\n\tGraph diff:\n\t\t  graph(%self.1 : __torch__.midas.midas_net_custom.MidasNet_small,\n\t\t        %x.1 : Tensor):\n\t\t    %scratch : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %output_conv : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"output_conv\"](%scratch)\n\t\t    %scratch.17 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %refinenet1 : __torch__.midas.blocks.FeatureFusionBlock_custom = prim::GetAttr[name=\"refinenet1\"](%scratch.17)\n\t\t    %scratch.15 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %refinenet2 : __torch__.midas.blocks.FeatureFusionBlock_custom = prim::GetAttr[name=\"refinenet2\"](%scratch.15)\n\t\t    %scratch.13 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %refinenet3 : __torch__.midas.blocks.FeatureFusionBlock_custom = prim::GetAttr[name=\"refinenet3\"](%scratch.13)\n\t\t    %scratch.11 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %output_conv.1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"output_conv\"](%scratch.11)\n\t\t    %_3.9 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name=\"3\"](%output_conv.1)\n\t\t    %scratch.9 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %refinenet4 : __torch__.midas.blocks.FeatureFusionBlock_custom = prim::GetAttr[name=\"refinenet4\"](%scratch.9)\n\t\t    %scratch.7 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %layer4_rn : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"layer4_rn\"](%scratch.7)\n\t\t    %scratch.5 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %layer3_rn : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"layer3_rn\"](%scratch.5)\n\t\t    %scratch.3 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %layer2_rn : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"layer2_rn\"](%scratch.3)\n\t\t    %scratch.1 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t    %layer1_rn : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"layer1_rn\"](%scratch.1)\n\t\t    %pretrained : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"pretrained\"](%self.1)\n\t\t    %layer4 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"layer4\"](%pretrained)\n\t\t    %pretrained.5 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"pretrained\"](%self.1)\n\t\t    %layer3 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"layer3\"](%pretrained.5)\n\t\t    %pretrained.3 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"pretrained\"](%self.1)\n\t\t    %layer2 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"layer2\"](%pretrained.3)\n\t\t    %pretrained.1 : __torch__.torch.nn.modules.module.Module = prim::GetAttr[name=\"pretrained\"](%self.1)\n\t\t    %layer1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"layer1\"](%pretrained.1)\n\t\t    %46 : int = prim::Constant[value=144](), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t    %47 : int = prim::Constant[value=192](), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %48 : int = prim::Constant[value=32](), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %49 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer1/__module.pretrained.layer1.2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t    %50 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer1/__module.pretrained.layer1.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %51 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer1/__module.pretrained.layer1.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %52 : int = prim::Constant[value=2](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %53 : int = prim::Constant[value=3](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %54 : Tensor = prim::Constant[value={-2}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %55 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %56 : int = prim::Constant[value=1](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %57 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %58 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %59 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?     ^^^\n\t\t+   %52 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?     ^^^                                                                                                   +++++++++++++++++++++++++++++++++\n\t\t+   %53 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %54 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %55 : Tensor = prim::Constant[value={0}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %60 : NoneType = prim::Constant(), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?     -\n\t\t+   %56 : NoneType = prim::Constant(), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    +\n\t\t+   %57 : int = prim::Constant[value=2](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t-   %61 : int = prim::Constant[value=0](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^\n\t\t+   %58 : int = prim::Constant[value=0](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^\n\t\t+   %59 : int = prim::Constant[value=1](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t-   %62 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?     ^^^\n\t\t+   %60 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?     ^^^\n\t\t-   %63 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?     ^^^\n\t\t+   %61 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?     ^^^\n\t\t    %_4.1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"4\"](%layer1)\n\t\t    %_3.1 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"3\"](%layer1)\n\t\t    %_2.1 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"2\"](%layer1)\n\t\t    %_1.1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"1\"](%layer1)\n\t\t    %_0.1 : __torch__.geffnet.conv2d_layers.Conv2dSameExport = prim::GetAttr[name=\"0\"](%layer1)\n\t\t    %weight.329 : Tensor = prim::GetAttr[name=\"weight\"](%_0.1)\n\t\t+   %pad.1 : __torch__.torch.nn.modules.padding.ZeroPad2d = prim::GetAttr[name=\"pad\"](%_0.1)\n\t\t-   %70 : int = aten::size(%x.1, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.1 : Tensor = prim::NumToTensor(%70), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %72 : int = aten::size(%x.1, %53), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.3 : Tensor = prim::NumToTensor(%72), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %74 : int = aten::size(%weight.329, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.1 : Tensor = prim::NumToTensor(%74), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %76 : int = aten::size(%weight.329, %53), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.3 : Tensor = prim::NumToTensor(%76), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %78 : Tensor = aten::floor_divide(%i.1, %54), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %79 : Tensor = aten::neg(%78), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %80 : Tensor = aten::sub(%79, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %81 : Tensor = aten::mul(%80, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %82 : Tensor = aten::sub(%k.1, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %83 : Tensor = aten::mul(%82, %55), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %84 : Tensor = aten::add(%81, %83, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %85 : Tensor = aten::add(%84, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_h.1 : Tensor = aten::sub(%85, %i.1, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %87 : Tensor = aten::floor_divide(%i.3, %54), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %88 : Tensor = aten::neg(%87), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %89 : Tensor = aten::sub(%88, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %90 : Tensor = aten::mul(%89, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %91 : Tensor = aten::sub(%k.3, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %92 : Tensor = aten::mul(%91, %55), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %93 : Tensor = aten::add(%90, %92, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %94 : Tensor = aten::add(%93, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_w.1 : Tensor = aten::sub(%94, %i.3, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %96 : Tensor = aten::floor_divide(%pad_w.1, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %97 : int = aten::Int(%96), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?     -                    ^^\n\t\t+   %69 : int = aten::Int(%55), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad\n\t\t?    +                     ^^                                                                 +++++++++++++++++++++++++++++++++\n\t\t-   %98 : Tensor = aten::floor_divide(%pad_w.1, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %99 : Tensor = aten::sub(%pad_w.1, %98, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %100 : int = aten::Int(%99), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %101 : Tensor = aten::floor_divide(%pad_h.1, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %102 : int = aten::Int(%101), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %103 : Tensor = aten::floor_divide(%pad_h.1, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %104 : Tensor = aten::sub(%pad_h.1, %103, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %105 : int = aten::Int(%104), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    ^ -                    ^^\n\t\t+   %70 : int = aten::Int(%54), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad\n\t\t?    ^                     ^                                                                  +++++++++++++++++++++++++++++++++\n\t\t+   %71 : int = aten::Int(%55), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad\n\t\t+   %72 : int = aten::Int(%54), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad\n\t\t+   %73 : int[] = prim::ListConstruct(%69, %70, %71, %72), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad\n\t\t+   %x.3 : Tensor = aten::pad(%x.1, %73, %53, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.0/__module.pretrained.layer1.0.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %106 : int[] = prim::ListConstruct(%97, %100, %102, %105), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    ^^^                                ^    --------------\n\t\t+   %75 : int[] = prim::ListConstruct(%57, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    ^^                                ^     +\n\t\t-   %x.3 : Tensor = aten::pad(%x.1, %106, %58, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %76 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t+   %77 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %108 : int[] = prim::ListConstruct(%52, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    ^^                                  ^    ^\n\t\t+   %78 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t?    ^                                  ^    ^\n\t\t-   %109 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %110 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %111 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.0\n\t\t-   %input.1 : Tensor = aten::_convolution(%x.3, %weight.329, %60, %108, %109, %110, %62, %111, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                              ^^^^^^^    ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.1 : Tensor = aten::_convolution(%x.3, %weight.329, %56, %75, %76, %77, %60, %78, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                              ^^^^^^^^^^^^^^^^^^^^^^^^^^    ^    ^^^^^^^^^^^^^^^^^\n\t\t    %running_var.145 : Tensor = prim::GetAttr[name=\"running_var\"](%_1.1)\n\t\t    %running_mean.145 : Tensor = prim::GetAttr[name=\"running_mean\"](%_1.1)\n\t\t    %bias.187 : Tensor = prim::GetAttr[name=\"bias\"](%_1.1)\n\t\t    %weight.331 : Tensor = prim::GetAttr[name=\"weight\"](%_1.1)\n\t\t-   %input.3 : Tensor = aten::batch_norm(%input.1, %weight.331, %bias.187, %running_mean.145, %running_var.145, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                 -----     ^^   ^\n\t\t+   %input.3 : Tensor = aten::batch_norm(%input.1, %weight.331, %bias.187, %running_mean.145, %running_var.145, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                      ^^^^^^^   ^\n\t\t-   %input.5 : Tensor = aten::hardtanh_(%input.3, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                   ^\n\t\t+   %input.5 : Tensor = aten::hardtanh_(%input.3, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                   ^\n\t\t    %_0.3 : __torch__.geffnet.efficientnet_builder.DepthwiseSeparableConv = prim::GetAttr[name=\"0\"](%_3.1)\n\t\t    %act2.1 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"act2\"](%_0.3)\n\t\t    %bn2.1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.3)\n\t\t    %conv_pw.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.3)\n\t\t    %se.1 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.3)\n\t\t    %act1.1 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.3)\n\t\t    %bn1.1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.3)\n\t\t    %conv_dw.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_0.3)\n\t\t    %weight.333 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.1)\n\t\t-   %128 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t-   %129 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?    --                                  ^    ^\n\t\t+   %95 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?     +                                 ^    ^\n\t\t-   %130 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?    ^^^                                 ^    ^\n\t\t+   %96 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?    ^^                                 ^    ^\n\t\t-   %131 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?    ^^^                                ^^   ^^\n\t\t+   %97 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t?    ^^                                ^^   ^^\n\t\t+   %98 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw\n\t\t-   %input.7 : Tensor = aten::_convolution(%input.5, %weight.333, %60, %128, %129, %130, %62, %131, %48, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                  ^^^^^^^  -----------------------        ^^^^^^^^^^^^^^^^\n\t\t+   %input.7 : Tensor = aten::_convolution(%input.5, %weight.333, %56, %95, %96, %97, %60, %98, %48, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^          ^^^^^^^^^^^^^^^^\n\t\t    %running_var.147 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.1)\n\t\t    %running_mean.147 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.1)\n\t\t    %bias.189 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.1)\n\t\t    %weight.335 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.1)\n\t\t-   %input.9 : Tensor = aten::batch_norm(%input.7, %weight.335, %bias.189, %running_mean.147, %running_var.147, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                 ^^             ^\n\t\t+   %input.9 : Tensor = aten::batch_norm(%input.7, %weight.335, %bias.189, %running_mean.147, %running_var.147, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                 ^^             ^\n\t\t-   %input.11 : Tensor = aten::hardtanh_(%input.9, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^\n\t\t+   %input.11 : Tensor = aten::hardtanh_(%input.9, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^\n\t\t    %weight.337 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.1)\n\t\t-   %140 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?     -                                  ^    ^\n\t\t+   %107 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?      +                                 ^    ^\n\t\t-   %141 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t-   %142 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?     ^^                                 ^    ^\n\t\t+   %108 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?     ^^                                 ^    ^\n\t\t-   %143 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?     ^^                                ^^   ^^\n\t\t+   %109 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t?     ^^                                ^^   ^^\n\t\t+   %110 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw\n\t\t-   %input.13 : Tensor = aten::_convolution(%input.11, %weight.337, %60, %140, %141, %142, %62, %143, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                   ----------------------------------      ^^^^^^^^^^^^^^^^^\n\t\t+   %input.13 : Tensor = aten::_convolution(%input.11, %weight.337, %56, %107, %108, %109, %60, %110, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.149 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.1)\n\t\t    %running_mean.149 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.1)\n\t\t    %bias.191 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.1)\n\t\t    %weight.339 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.1)\n\t\t-   %input.15 : Tensor = aten::batch_norm(%input.13, %weight.339, %bias.191, %running_mean.149, %running_var.149, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.15 : Tensor = aten::batch_norm(%input.13, %weight.339, %bias.191, %running_mean.149, %running_var.149, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.3/__module.pretrained.layer1.3.0/__module.pretrained.layer1.3.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %_2.3 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"2\"](%_4.1)\n\t\t    %_1.3 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"1\"](%_4.1)\n\t\t    %_0.5 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_4.1)\n\t\t    %bn3.1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.5)\n\t\t    %conv_pwl.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.5)\n\t\t    %se.3 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.5)\n\t\t    %act2.3 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.5)\n\t\t    %bn2.3 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.5)\n\t\t    %conv_dw.3 : __torch__.geffnet.conv2d_layers.Conv2dSameExport = prim::GetAttr[name=\"conv_dw\"](%_0.5)\n\t\t    %act1.3 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.5)\n\t\t    %bn1.3 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.5)\n\t\t    %conv_pw.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.5)\n\t\t    %weight.341 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.3)\n\t\t-   %163 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?     -                                  ^    ^\n\t\t+   %130 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?      +                                 ^    ^\n\t\t-   %164 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t-   %165 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?     ^^                                 ^    ^\n\t\t+   %131 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?     ^^                                 ^    ^\n\t\t-   %166 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?     ^^                                ^^   ^^\n\t\t+   %132 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t?     ^^                                ^^   ^^\n\t\t+   %133 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw\n\t\t-   %input.17 : Tensor = aten::_convolution(%input.15, %weight.341, %60, %163, %164, %165, %62, %166, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ------------------- ^^^^    ^^^^   ^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.17 : Tensor = aten::_convolution(%input.15, %weight.341, %56, %130, %131, %132, %60, %133, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                     ^^^^^^^^^^^^^^^^^^    ^^^^^^^^^   ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.151 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.3)\n\t\t    %running_mean.151 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.3)\n\t\t    %bias.193 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.3)\n\t\t    %weight.343 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.3)\n\t\t-   %input.19 : Tensor = aten::batch_norm(%input.17, %weight.343, %bias.193, %running_mean.151, %running_var.151, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^             ^\n\t\t+   %input.19 : Tensor = aten::batch_norm(%input.17, %weight.343, %bias.193, %running_mean.151, %running_var.151, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^             ^\n\t\t-   %x.5 : Tensor = aten::hardtanh_(%input.19, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                ^\n\t\t+   %x.5 : Tensor = aten::hardtanh_(%input.19, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                ^\n\t\t    %weight.345 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.3)\n\t\t+   %pad.3 : __torch__.torch.nn.modules.padding.ZeroPad2d = prim::GetAttr[name=\"pad\"](%conv_dw.3)\n\t\t-   %175 : int = aten::size(%x.5, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.5 : Tensor = prim::NumToTensor(%175), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %177 : int = aten::size(%x.5, %53), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.7 : Tensor = prim::NumToTensor(%177), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %179 : int = aten::size(%weight.345, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.5 : Tensor = prim::NumToTensor(%179), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %181 : int = aten::size(%weight.345, %53), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.7 : Tensor = prim::NumToTensor(%181), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %183 : Tensor = aten::floor_divide(%i.5, %54), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %184 : Tensor = aten::neg(%183), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %185 : Tensor = aten::sub(%184, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %186 : Tensor = aten::mul(%185, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %187 : Tensor = aten::sub(%k.5, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %188 : Tensor = aten::mul(%187, %55), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %189 : Tensor = aten::add(%186, %188, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %190 : Tensor = aten::add(%189, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_h.3 : Tensor = aten::sub(%190, %i.5, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %192 : Tensor = aten::floor_divide(%i.7, %54), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %193 : Tensor = aten::neg(%192), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %194 : Tensor = aten::sub(%193, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %195 : Tensor = aten::mul(%194, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %196 : Tensor = aten::sub(%k.7, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %197 : Tensor = aten::mul(%196, %55), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %198 : Tensor = aten::add(%195, %197, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %199 : Tensor = aten::add(%198, %55, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_w.3 : Tensor = aten::sub(%199, %i.7, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %201 : Tensor = aten::floor_divide(%pad_w.3, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %202 : int = aten::Int(%201), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    ^^^^^^^^^              ^^^\n\t\t+   %143 : int = aten::Int(%55), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad\n\t\t?    ^^^^^^^^^              ^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t+   %144 : int = aten::Int(%54), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad\n\t\t-   %203 : Tensor = aten::floor_divide(%pad_w.3, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %204 : Tensor = aten::sub(%pad_w.3, %203, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %205 : int = aten::Int(%204), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    ^^                     ^^^\n\t\t+   %145 : int = aten::Int(%55), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad\n\t\t?    ^^                     ^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %206 : Tensor = aten::floor_divide(%pad_h.3, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %207 : int = aten::Int(%206), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    ^^^^^^^^^              ^^^\n\t\t+   %146 : int = aten::Int(%54), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad\n\t\t?    ^^^^^^^^^              ^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t+   %147 : int[] = prim::ListConstruct(%143, %144, %145, %146), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad\n\t\t+   %x.7 : Tensor = aten::pad(%x.5, %147, %53, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw/__module.pretrained.layer1.4.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %208 : Tensor = aten::floor_divide(%pad_h.3, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %209 : Tensor = aten::sub(%pad_h.3, %208, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %210 : int = aten::Int(%209), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %211 : int[] = prim::ListConstruct(%202, %205, %207, %210), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %x.7 : Tensor = aten::pad(%x.5, %211, %58, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %213 : int[] = prim::ListConstruct(%52, %52), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    - ^                                 ^    ^\n\t\t+   %149 : int[] = prim::ListConstruct(%57, %57), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?     ^^                                 ^    ^\n\t\t-   %214 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %215 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    -                                   ^    ^\n\t\t+   %150 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?      +                                 ^    ^\n\t\t-   %216 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?    - ^                                ^^   ^^\n\t\t+   %151 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t?     ^^                                ^^   ^^\n\t\t+   %152 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw\n\t\t-   %input.21 : Tensor = aten::_convolution(%x.7, %weight.345, %60, %213, %214, %215, %62, %216, %46, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                               ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.21 : Tensor = aten::_convolution(%x.7, %weight.345, %56, %149, %150, %151, %60, %152, %46, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.153 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.3)\n\t\t    %running_mean.153 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.3)\n\t\t    %bias.195 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.3)\n\t\t    %weight.347 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.3)\n\t\t-   %input.23 : Tensor = aten::batch_norm(%input.21, %weight.347, %bias.195, %running_mean.153, %running_var.153, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^^^^^^^^^^^   ^\n\t\t+   %input.23 : Tensor = aten::batch_norm(%input.21, %weight.347, %bias.195, %running_mean.153, %running_var.153, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^^^^^^^^^^^   ^\n\t\t-   %input.25 : Tensor = aten::hardtanh_(%input.23, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t+   %input.25 : Tensor = aten::hardtanh_(%input.23, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t    %weight.349 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.1)\n\t\t+   %161 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t-   %225 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?     --                                 ^    ^\n\t\t+   %162 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?    ++                                  ^    ^\n\t\t-   %226 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t-   %227 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?    ^^^                                 ^    ^\n\t\t+   %163 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?    ^^^                                 ^    ^\n\t\t-   %228 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?    ^^^                                ^^   ^^\n\t\t+   %164 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl\n\t\t?    ^^^                                ^^   ^^\n\t\t-   %input.27 : Tensor = aten::_convolution(%input.25, %weight.349, %60, %225, %226, %227, %62, %228, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.27 : Tensor = aten::_convolution(%input.25, %weight.349, %56, %161, %162, %163, %60, %164, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.155 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.1)\n\t\t    %running_mean.155 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.1)\n\t\t    %bias.197 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.1)\n\t\t    %weight.351 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.1)\n\t\t-   %input.29 : Tensor = aten::batch_norm(%input.27, %weight.351, %bias.197, %running_mean.155, %running_var.155, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.29 : Tensor = aten::batch_norm(%input.27, %weight.351, %bias.197, %running_mean.155, %running_var.155, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.0/__module.pretrained.layer1.4.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %bn3.3 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_1.3)\n\t\t    %conv_pwl.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_1.3)\n\t\t    %se.5 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_1.3)\n\t\t    %act2.5 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_1.3)\n\t\t    %bn2.5 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.3)\n\t\t    %conv_dw.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_1.3)\n\t\t    %act1.5 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_1.3)\n\t\t    %bn1.5 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.3)\n\t\t    %conv_pw.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_1.3)\n\t\t    %weight.353 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.5)\n\t\t+   %181 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t-   %245 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?     --                                 ^    ^\n\t\t+   %182 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?    ++                                  ^    ^\n\t\t-   %246 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?    ^^^                                ^^   ^^\n\t\t+   %183 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?    ^^^                                ^^   ^^\n\t\t-   %247 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?    ^ -                                 ^    ^\n\t\t+   %184 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t?    ^^                                  ^    ^\n\t\t-   %248 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw\n\t\t-   %input.31 : Tensor = aten::_convolution(%input.29, %weight.353, %60, %245, %246, %247, %62, %248, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                         ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.31 : Tensor = aten::_convolution(%input.29, %weight.353, %56, %181, %182, %183, %60, %184, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                   +++++++++++++++++++++++      ^^^^^^ ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.157 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.5)\n\t\t    %running_mean.157 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.5)\n\t\t    %bias.199 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.5)\n\t\t    %weight.355 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.5)\n\t\t-   %input.33 : Tensor = aten::batch_norm(%input.31, %weight.355, %bias.199, %running_mean.157, %running_var.157, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   -----     ^^   ^\n\t\t+   %input.33 : Tensor = aten::batch_norm(%input.31, %weight.355, %bias.199, %running_mean.157, %running_var.157, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                        ^^^^^^^   ^\n\t\t-   %input.35 : Tensor = aten::hardtanh_(%input.33, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t+   %input.35 : Tensor = aten::hardtanh_(%input.33, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t    %weight.357 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.5)\n\t\t-   %257 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t-   %258 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t-   %259 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t?    ^^                                  ^    ^\n\t\t+   %193 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t?    ^ +                                 ^    ^\n\t\t+   %194 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t+   %195 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t-   %260 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t?    ^ -                                ^^   ^^\n\t\t+   %196 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw\n\t\t?    ^^                                 ^^   ^^\n\t\t-   %input.37 : Tensor = aten::_convolution(%input.35, %weight.357, %60, %257, %258, %259, %62, %260, %47, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                         ^^    ------------------     ^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.37 : Tensor = aten::_convolution(%input.35, %weight.357, %56, %193, %194, %195, %60, %196, %47, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                   +++++++++++++++++++++++      ^^^^^^^         ^^^^^^^^^^^^\n\t\t    %running_var.159 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.5)\n\t\t    %running_mean.159 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.5)\n\t\t    %bias.201 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.5)\n\t\t    %weight.359 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.5)\n\t\t-   %input.39 : Tensor = aten::batch_norm(%input.37, %weight.359, %bias.201, %running_mean.159, %running_var.159, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.39 : Tensor = aten::batch_norm(%input.37, %weight.359, %bias.201, %running_mean.159, %running_var.159, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.41 : Tensor = aten::hardtanh_(%input.39, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t+   %input.41 : Tensor = aten::hardtanh_(%input.39, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t    %weight.361 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.3)\n\t\t+   %205 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t-   %269 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?      -                                 ^    ^\n\t\t+   %206 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?     +                                  ^    ^\n\t\t-   %270 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t-   %271 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?      -                                 ^    ^\n\t\t+   %207 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?     +                                  ^    ^\n\t\t-   %272 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?     ^^                                ^^   ^^\n\t\t+   %208 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl\n\t\t?     ^^                                ^^   ^^\n\t\t-   %input.43 : Tensor = aten::_convolution(%input.41, %weight.361, %60, %269, %270, %271, %62, %272, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.43 : Tensor = aten::_convolution(%input.41, %weight.361, %56, %205, %206, %207, %60, %208, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.161 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.3)\n\t\t    %running_mean.161 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.3)\n\t\t    %bias.203 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.3)\n\t\t    %weight.363 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.3)\n\t\t-   %x.9 : Tensor = aten::batch_norm(%input.43, %weight.363, %bias.203, %running_mean.161, %running_var.161, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                              ^^             ^\n\t\t+   %x.9 : Tensor = aten::batch_norm(%input.43, %weight.363, %bias.203, %running_mean.161, %running_var.161, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1/__module.pretrained.layer1.4.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                              ^^             ^\n\t\t-   %input.45 : Tensor = aten::add_(%x.9, %input.29, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                      ^\n\t\t+   %input.45 : Tensor = aten::add_(%x.9, %input.29, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                      ^\n\t\t    %bn3.5 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_2.3)\n\t\t    %conv_pwl.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_2.3)\n\t\t    %se.7 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_2.3)\n\t\t    %act2.7 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_2.3)\n\t\t    %bn2.7 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_2.3)\n\t\t    %conv_dw.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_2.3)\n\t\t    %act1.7 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_2.3)\n\t\t    %bn1.7 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_2.3)\n\t\t    %conv_pw.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_2.3)\n\t\t    %weight.365 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.7)\n\t\t-   %290 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t-   %291 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t-   %292 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t?     -                                  ^    ^\n\t\t+   %226 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t?      +                                 ^    ^\n\t\t+   %227 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t+   %228 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t-   %293 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t?      -                                ^^   ^^\n\t\t+   %229 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw\n\t\t?     +                                 ^^   ^^\n\t\t-   %input.47 : Tensor = aten::_convolution(%input.45, %weight.365, %60, %290, %291, %292, %62, %293, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.47 : Tensor = aten::_convolution(%input.45, %weight.365, %56, %226, %227, %228, %60, %229, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                   +++++++++++++++++++++++      +  +++++++++    ^^^^^^^^^^^^\n\t\t    %running_var.163 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.7)\n\t\t    %running_mean.163 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.7)\n\t\t    %bias.205 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.7)\n\t\t    %weight.367 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.7)\n\t\t-   %input.49 : Tensor = aten::batch_norm(%input.47, %weight.367, %bias.205, %running_mean.163, %running_var.163, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^             ^\n\t\t+   %input.49 : Tensor = aten::batch_norm(%input.47, %weight.367, %bias.205, %running_mean.163, %running_var.163, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^^             ^\n\t\t-   %input.51 : Tensor = aten::hardtanh_(%input.49, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t+   %input.51 : Tensor = aten::hardtanh_(%input.49, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t    %weight.369 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.7)\n\t\t-   %302 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?     ^^                                 ^    ^\n\t\t+   %238 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    + ^                                 ^    ^\n\t\t-   %303 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?     ^^                                 ^    ^\n\t\t+   %239 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    + ^                                 ^    ^\n\t\t-   %304 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    ^ -                                 ^    ^\n\t\t+   %240 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    ^^                                  ^    ^\n\t\t-   %305 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    ^^^                                ^^   ^^\n\t\t+   %241 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw\n\t\t?    ^^^                                ^^   ^^\n\t\t-   %input.53 : Tensor = aten::_convolution(%input.51, %weight.369, %60, %302, %303, %304, %62, %305, %47, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ------------------------------ ^        ^^^^^^^^^^^^^^^^\n\t\t+   %input.53 : Tensor = aten::_convolution(%input.51, %weight.369, %56, %238, %239, %240, %60, %241, %47, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^        ^^^^^^^^^^^^^^^^\n\t\t    %running_var.165 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.7)\n\t\t    %running_mean.165 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.7)\n\t\t    %bias.207 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.7)\n\t\t    %weight.371 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.7)\n\t\t-   %input.55 : Tensor = aten::batch_norm(%input.53, %weight.371, %bias.207, %running_mean.165, %running_var.165, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   -----     ^^   ^\n\t\t+   %input.55 : Tensor = aten::batch_norm(%input.53, %weight.371, %bias.207, %running_mean.165, %running_var.165, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                        ^^^^^^^   ^\n\t\t-   %input.57 : Tensor = aten::hardtanh_(%input.55, %59, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t+   %input.57 : Tensor = aten::hardtanh_(%input.55, %52, %49), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                     ^\n\t\t    %weight.373 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.5)\n\t\t+   %250 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t-   %314 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?    ^ -                                 ^    ^\n\t\t+   %251 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?    ^^                                  ^    ^\n\t\t-   %315 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?    ^^                                 ^^   ^^\n\t\t+   %252 : int[] = prim::ListConstruct(%59, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?    ^ +                                ^^   ^^\n\t\t-   %316 : int[] = prim::ListConstruct(%56, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?     --                                 ^    ^\n\t\t+   %253 : int[] = prim::ListConstruct(%58, %58), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t?    ++                                  ^    ^\n\t\t+   %input.59 : Tensor = aten::_convolution(%input.57, %weight.373, %56, %250, %251, %252, %60, %253, %59, %60, %60, %61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %317 : int[] = prim::ListConstruct(%61, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl\n\t\t-   %input.59 : Tensor = aten::_convolution(%input.57, %weight.373, %60, %314, %315, %316, %62, %317, %56, %62, %62, %63, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.167 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.5)\n\t\t    %running_mean.167 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.5)\n\t\t    %bias.209 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.5)\n\t\t    %weight.375 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.5)\n\t\t-   %x.11 : Tensor = aten::batch_norm(%input.59, %weight.375, %bias.209, %running_mean.167, %running_var.167, %62, %50, %51, %63), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.11 : Tensor = aten::batch_norm(%input.59, %weight.375, %bias.209, %running_mean.167, %running_var.167, %60, %50, %51, %61), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2/__module.pretrained.layer1.4.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.61 : Tensor = aten::add_(%x.11, %input.45, %56), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                       ^\n\t\t+   %input.61 : Tensor = aten::add_(%x.11, %input.45, %59), scope: __module.pretrained.layer1/__module.pretrained.layer1.4/__module.pretrained.layer1.4.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                       ^\n\t\t+   %261 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %262 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %263 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %264 : int = prim::Constant[value=2](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t-   %325 : int = prim::Constant[value=2](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t?    ^^                                                                                                                                                                                                                                                                       ^^\n\t\t+   %265 : int = prim::Constant[value=192](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^                               ++                                                                                                                                                                                                                                        ^^\n\t\t-   %326 : int = prim::Constant[value=3](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %327 : Tensor = prim::Constant[value={-2}](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %328 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %329 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %330 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %331 : int = prim::Constant[value=192](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t-   %332 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^\n\t\t+   %266 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^\n\t\t-   %333 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^\n\t\t+   %267 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^\n\t\t-   %334 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t+   %268 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t-   %335 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t+   %269 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t-   %336 : NoneType = prim::Constant(), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t?    ^^^\n\t\t+   %270 : NoneType = prim::Constant(), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t?    ^^^\n\t\t-   %337 : int = prim::Constant[value=1](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^ ^^^^^^\n\t\t+   %271 : int = prim::Constant[value=1](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^ ^^^^^^^\n\t\t-   %338 : int = prim::Constant[value=0](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t+   %272 : int = prim::Constant[value=0](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t-   %339 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^\n\t\t+   %273 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ++ ^^\n\t\t-   %340 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^ ^^^\n\t\t+   %274 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^ ^^\n\t\t-   %341 : int = prim::Constant[value=288](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t+   %275 : int = prim::Constant[value=288](), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t    %_0.9 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"0\"](%layer2)\n\t\t    %_2.5 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"2\"](%_0.9)\n\t\t    %_1.5 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"1\"](%_0.9)\n\t\t    %_0.7 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_0.9)\n\t\t    %bn3.7 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.7)\n\t\t    %conv_pwl.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.7)\n\t\t    %se.9 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.7)\n\t\t    %act2.9 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.7)\n\t\t    %bn2.9 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.7)\n\t\t    %conv_dw.9 : __torch__.geffnet.conv2d_layers.Conv2dSameExport = prim::GetAttr[name=\"conv_dw\"](%_0.7)\n\t\t    %act1.9 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.7)\n\t\t    %bn1.9 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.7)\n\t\t    %conv_pw.9 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.7)\n\t\t    %weight.377 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.9)\n\t\t+   %290 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t+   %291 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t+   %292 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t-   %356 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t?     --                                ^^    ^^\n\t\t+   %293 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t?    ++                                 ^ +   ^ +\n\t\t-   %357 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t-   %358 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t-   %359 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw\n\t\t-   %input.63 : Tensor = aten::_convolution(%input.61, %weight.377, %336, %356, %357, %358, %339, %359, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^ ^^^^^^^^^^^ ^^^^^ ^^^^ ^^^^^ -\n\t\t+   %input.63 : Tensor = aten::_convolution(%input.61, %weight.377, %270, %290, %291, %292, %273, %293, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^ ^^^^^ ^^^^^ ^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^\n\t\t    %running_var.169 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.9)\n\t\t    %running_mean.169 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.9)\n\t\t    %bias.211 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.9)\n\t\t    %weight.379 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.9)\n\t\t-   %input.65 : Tensor = aten::batch_norm(%input.63, %weight.379, %bias.211, %running_mean.169, %running_var.169, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^    ^^ ------------\n\t\t+   %input.65 : Tensor = aten::batch_norm(%input.63, %weight.379, %bias.211, %running_mean.169, %running_var.169, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ++ ^^^^^^^^^^^    ^^\n\t\t-   %x.13 : Tensor = aten::hardtanh_(%input.65, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                ^^^   ^^^\n\t\t+   %x.13 : Tensor = aten::hardtanh_(%input.65, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                ^^^   ^^^\n\t\t    %weight.381 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.9)\n\t\t-   %368 : int = aten::size(%x.13, %325), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t+   %pad.5 : __torch__.torch.nn.modules.padding.ZeroPad2d = prim::GetAttr[name=\"pad\"](%conv_dw.9)\n\t\t-   %i.9 : Tensor = prim::NumToTensor(%368), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^^^^^^^^^^^   ^^^^^^^^^^^^^^^^^   --\n\t\t+   %303 : int = aten::Int(%263), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad\n\t\t?    ^^^^^^^^^   ^^^^^^^^^  ++                                                                                                                                        +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %370 : int = aten::size(%x.13, %326), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.11 : Tensor = prim::NumToTensor(%370), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %372 : int = aten::size(%weight.381, %325), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.9 : Tensor = prim::NumToTensor(%372), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^^^^^^^^^^^   ^^^^^^^^^^^^^^^^^  ^^\n\t\t+   %304 : int = aten::Int(%262), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad\n\t\t?    ^^^^^^^^^   ^^^^^^^^^  ^^                                                                                                                                        +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %374 : int = aten::size(%weight.381, %326), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.11 : Tensor = prim::NumToTensor(%374), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %376 : Tensor = aten::floor_divide(%i.9, %327), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %377 : Tensor = aten::neg(%376), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %378 : Tensor = aten::sub(%377, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %379 : Tensor = aten::mul(%378, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %380 : Tensor = aten::sub(%k.9, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %381 : Tensor = aten::mul(%380, %328), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %382 : Tensor = aten::add(%379, %381, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %383 : Tensor = aten::add(%382, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_h.5 : Tensor = aten::sub(%383, %i.9, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %385 : Tensor = aten::floor_divide(%i.11, %327), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %386 : Tensor = aten::neg(%385), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %387 : Tensor = aten::sub(%386, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %388 : Tensor = aten::mul(%387, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %389 : Tensor = aten::sub(%k.11, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %390 : Tensor = aten::mul(%389, %328), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %391 : Tensor = aten::add(%388, %390, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %392 : Tensor = aten::add(%391, %328, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_w.5 : Tensor = aten::sub(%392, %i.11, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %394 : Tensor = aten::floor_divide(%pad_w.5, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %395 : int = aten::Int(%394), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?     ^                      --\n\t\t+   %305 : int = aten::Int(%263), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad\n\t\t?     ^                     ++                                                                                                                                        +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %396 : Tensor = aten::floor_divide(%pad_w.5, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %397 : Tensor = aten::sub(%pad_w.5, %396, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %398 : int = aten::Int(%397), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %399 : Tensor = aten::floor_divide(%pad_h.5, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %400 : int = aten::Int(%399), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %401 : Tensor = aten::floor_divide(%pad_h.5, %329), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %402 : Tensor = aten::sub(%pad_h.5, %401, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %403 : int = aten::Int(%402), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    -- ^^^^^^              ^^\n\t\t+   %306 : int = aten::Int(%262), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad\n\t\t?     ^^^^^^^^              ^^                                                                                                                                        +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %404 : int[] = prim::ListConstruct(%395, %398, %400, %403), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^^^^                               ^     ^^^^^^^^^^^^^^\n\t\t+   %307 : int[] = prim::ListConstruct(%303, %304, %305, %306), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad\n\t\t?    ^^^^^                               ^^^^^^^^^^^^^     ^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %x.15 : Tensor = aten::pad(%x.13, %404, %330, %332), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?                                      ^^^   ^^^   ^^^\n\t\t+   %x.15 : Tensor = aten::pad(%x.13, %307, %261, %266), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw/__module.pretrained.layer2.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?                                      ^^^   ^^^   ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %406 : int[] = prim::ListConstruct(%325, %325), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^ ^                                - ^   - ^\n\t\t+   %309 : int[] = prim::ListConstruct(%264, %264), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^ ^                                 ^^    ^^\n\t\t-   %407 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %408 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^ -                                ^^    ^^\n\t\t+   %310 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^                                 ^ +   ^ +\n\t\t-   %409 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^^                                ^^^   ^^^\n\t\t+   %311 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t?    ^^^                                ^^^   ^^^\n\t\t+   %312 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw\n\t\t-   %input.67 : Tensor = aten::_convolution(%x.15, %weight.381, %336, %406, %407, %408, %339, %409, %331, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                ^^ ^^^ ^^^^^ --------------------------------------------------\n\t\t+   %input.67 : Tensor = aten::_convolution(%x.15, %weight.381, %270, %309, %310, %311, %273, %312, %265, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^ ^^^^^\n\t\t    %running_var.171 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.9)\n\t\t    %running_mean.171 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.9)\n\t\t    %bias.213 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.9)\n\t\t    %weight.383 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.9)\n\t\t-   %input.69 : Tensor = aten::batch_norm(%input.67, %weight.383, %bias.213, %running_mean.171, %running_var.171, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ^^    ^^ ------------\n\t\t+   %input.69 : Tensor = aten::batch_norm(%input.67, %weight.383, %bias.213, %running_mean.171, %running_var.171, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ^^^^^^^^^^^^^^    ^^\n\t\t-   %input.71 : Tensor = aten::hardtanh_(%input.69, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t+   %input.71 : Tensor = aten::hardtanh_(%input.69, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t    %weight.385 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.7)\n\t\t-   %418 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^ -                                ^^    ^^\n\t\t+   %321 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^^                                 ^ +   ^ +\n\t\t-   %419 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t-   %420 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %322 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %421 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %323 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %324 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl\n\t\t-   %input.73 : Tensor = aten::_convolution(%input.71, %weight.385, %336, %418, %419, %420, %339, %421, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^  ^^^^ ^^^^^ --------------------------------------------\n\t\t+   %input.73 : Tensor = aten::_convolution(%input.71, %weight.385, %270, %321, %322, %323, %273, %324, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ +++++ ^^^^^^^^^^^^^^^^^ ^^^^^\n\t\t    %running_var.173 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.7)\n\t\t    %running_mean.173 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.7)\n\t\t    %bias.215 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.7)\n\t\t    %weight.387 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.7)\n\t\t-   %input.75 : Tensor = aten::batch_norm(%input.73, %weight.387, %bias.215, %running_mean.173, %running_var.173, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ^^    ^^ ------------\n\t\t+   %input.75 : Tensor = aten::batch_norm(%input.73, %weight.387, %bias.215, %running_mean.173, %running_var.173, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.0/__module.pretrained.layer2.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ^^^^^^^^^^^^^^    ^^\n\t\t    %bn3.9 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_1.5)\n\t\t    %conv_pwl.9 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_1.5)\n\t\t    %se.11 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_1.5)\n\t\t    %act2.11 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_1.5)\n\t\t    %bn2.11 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.5)\n\t\t    %conv_dw.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_1.5)\n\t\t    %act1.11 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_1.5)\n\t\t    %bn1.11 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.5)\n\t\t    %conv_pw.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_1.5)\n\t\t    %weight.389 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.11)\n\t\t+   %341 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t+   %342 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t-   %438 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t?      -                                ^^    ^^\n\t\t+   %343 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t?    +                                  ^ +   ^ +\n\t\t-   %439 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t-   %440 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t?      -                                ^^    ^^\n\t\t+   %344 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t?    +                                  ^ +   ^ +\n\t\t-   %441 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw\n\t\t-   %input.77 : Tensor = aten::_convolution(%input.75, %weight.389, %336, %438, %439, %440, %339, %441, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.77 : Tensor = aten::_convolution(%input.75, %weight.389, %270, %341, %342, %343, %273, %344, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.175 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.11)\n\t\t    %running_mean.175 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.11)\n\t\t    %bias.217 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.11)\n\t\t    %weight.391 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.11)\n\t\t-   %input.79 : Tensor = aten::batch_norm(%input.77, %weight.391, %bias.217, %running_mean.175, %running_var.175, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^    ^^ ^^^^^^^^^^^ ------------------------------------                                                            -------------------------------\n\t\t+   %input.79 : Tensor = aten::batch_norm(%input.77, %weight.391, %bias.217, %running_mean.175, %running_var.175, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ++ ^^^^^^^^^^^    ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                              ++\n\t\t-   %input.81 : Tensor = aten::hardtanh_(%input.79, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t+   %input.81 : Tensor = aten::hardtanh_(%input.79, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t    %weight.393 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.11)\n\t\t-   %450 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %353 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %451 : int[] = prim::ListConstruct(%325, %325), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?     --                                - ^   - ^\n\t\t+   %354 : int[] = prim::ListConstruct(%264, %264), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ++                                  ^^    ^^\n\t\t-   %452 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %355 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %453 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %356 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t-   %input.83 : Tensor = aten::_convolution(%input.81, %weight.393, %336, %450, %451, %452, %339, %453, %341, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.83 : Tensor = aten::_convolution(%input.81, %weight.393, %270, %353, %354, %355, %273, %356, %275, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.177 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.11)\n\t\t    %running_mean.177 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.11)\n\t\t    %bias.219 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.11)\n\t\t    %weight.395 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.11)\n\t\t-   %input.85 : Tensor = aten::batch_norm(%input.83, %weight.395, %bias.219, %running_mean.177, %running_var.177, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                   ^    ^^ ^^^^^^^^^^^ ------------------------------------                                                            -------------------------------\n\t\t+   %input.85 : Tensor = aten::batch_norm(%input.83, %weight.395, %bias.219, %running_mean.177, %running_var.177, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                  ++ ^^^^^^^^^^^    ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^                              ++\n\t\t-   %input.87 : Tensor = aten::hardtanh_(%input.85, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t+   %input.87 : Tensor = aten::hardtanh_(%input.85, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t    %weight.397 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.9)\n\t\t-   %462 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %365 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %463 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t-   %464 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %366 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %465 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %367 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %368 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl\n\t\t-   %input.89 : Tensor = aten::_convolution(%input.87, %weight.397, %336, %462, %463, %464, %339, %465, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^ ^^^^^ --------------------------------------------------\n\t\t+   %input.89 : Tensor = aten::_convolution(%input.87, %weight.397, %270, %365, %366, %367, %273, %368, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^\n\t\t    %running_var.179 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.9)\n\t\t    %running_mean.179 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.9)\n\t\t    %bias.221 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.9)\n\t\t    %weight.399 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.9)\n\t\t-   %x.17 : Tensor = aten::batch_norm(%input.89, %weight.399, %bias.221, %running_mean.179, %running_var.179, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.17 : Tensor = aten::batch_norm(%input.89, %weight.399, %bias.221, %running_mean.179, %running_var.179, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1/__module.pretrained.layer2.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.91 : Tensor = aten::add_(%x.17, %input.75, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                      ^^\n\t\t+   %input.91 : Tensor = aten::add_(%x.17, %input.75, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                      ^ +\n\t\t    %bn3.11 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_2.5)\n\t\t    %conv_pwl.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_2.5)\n\t\t    %se.13 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_2.5)\n\t\t    %act2.13 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_2.5)\n\t\t    %bn2.13 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_2.5)\n\t\t    %conv_dw.13 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_2.5)\n\t\t    %act1.13 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_2.5)\n\t\t    %bn1.13 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_2.5)\n\t\t    %conv_pw.13 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_2.5)\n\t\t    %weight.401 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.13)\n\t\t-   %483 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %386 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %484 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t-   %485 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %387 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %486 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %388 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %389 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw\n\t\t-   %input.93 : Tensor = aten::_convolution(%input.91, %weight.401, %336, %483, %484, %485, %339, %486, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^     ^^^^^ --------------------------------------------------\n\t\t+   %input.93 : Tensor = aten::_convolution(%input.91, %weight.401, %270, %386, %387, %388, %273, %389, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^    ++++++++++++++++++++++++++++++++++++++++++++ ^^^^^\n\t\t    %running_var.181 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.13)\n\t\t    %running_mean.181 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.13)\n\t\t    %bias.223 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.13)\n\t\t    %weight.403 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.13)\n\t\t-   %input.95 : Tensor = aten::batch_norm(%input.93, %weight.403, %bias.223, %running_mean.181, %running_var.181, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.95 : Tensor = aten::batch_norm(%input.93, %weight.403, %bias.223, %running_mean.181, %running_var.181, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.97 : Tensor = aten::hardtanh_(%input.95, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t+   %input.97 : Tensor = aten::hardtanh_(%input.95, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                    ^^^   ^^^\n\t\t    %weight.405 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.13)\n\t\t-   %495 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?    ^ ^                                ^^    ^^\n\t\t+   %398 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?    ^ ^                                ^ +   ^ +\n\t\t-   %496 : int[] = prim::ListConstruct(%325, %325), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?    ^ ^                                - ^   - ^\n\t\t+   %399 : int[] = prim::ListConstruct(%264, %264), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?    ^ ^                                 ^^    ^^\n\t\t-   %497 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?     ^^                                ^^    ^^\n\t\t+   %400 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?     ^^                                ^ +   ^ +\n\t\t-   %498 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?     ^^                                ^^^   ^^^\n\t\t+   %401 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw\n\t\t?     ^^                                ^^^   ^^^\n\t\t-   %input.99 : Tensor = aten::_convolution(%input.97, %weight.405, %336, %495, %496, %497, %339, %498, %341, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.99 : Tensor = aten::_convolution(%input.97, %weight.405, %270, %398, %399, %400, %273, %401, %275, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.183 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.13)\n\t\t    %running_mean.183 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.13)\n\t\t    %bias.225 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.13)\n\t\t    %weight.407 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.13)\n\t\t-   %input.101 : Tensor = aten::batch_norm(%input.99, %weight.407, %bias.225, %running_mean.183, %running_var.183, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.101 : Tensor = aten::batch_norm(%input.99, %weight.407, %bias.225, %running_mean.183, %running_var.183, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.103 : Tensor = aten::hardtanh_(%input.101, %332, %333), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.103 : Tensor = aten::hardtanh_(%input.101, %266, %267), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.409 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.11)\n\t\t-   %507 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^ -                                ^^    ^^\n\t\t+   %410 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^^                                 ^ +   ^ +\n\t\t-   %508 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t-   %509 : int[] = prim::ListConstruct(%337, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^^^                                ^^    ^^\n\t\t+   %411 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^^^                                ^ +   ^ +\n\t\t-   %510 : int[] = prim::ListConstruct(%338, %338), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %412 : int[] = prim::ListConstruct(%271, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t?    ^ ^                                ^^^   ^^^\n\t\t+   %413 : int[] = prim::ListConstruct(%272, %272), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl\n\t\t-   %input.105 : Tensor = aten::_convolution(%input.103, %weight.409, %336, %507, %508, %509, %339, %510, %337, %339, %339, %340, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.105 : Tensor = aten::_convolution(%input.103, %weight.409, %270, %410, %411, %412, %273, %413, %271, %273, %273, %274, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.185 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.11)\n\t\t    %running_mean.185 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.11)\n\t\t    %bias.227 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.11)\n\t\t    %weight.411 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.11)\n\t\t-   %x.19 : Tensor = aten::batch_norm(%input.105, %weight.411, %bias.227, %running_mean.185, %running_var.185, %339, %334, %335, %340), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.19 : Tensor = aten::batch_norm(%input.105, %weight.411, %bias.227, %running_mean.185, %running_var.185, %273, %268, %269, %274), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2/__module.pretrained.layer2.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.107 : Tensor = aten::add_(%x.19, %input.91, %337), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                       ^^\n\t\t+   %input.107 : Tensor = aten::add_(%x.19, %input.91, %271), scope: __module.pretrained.layer2/__module.pretrained.layer2.0/__module.pretrained.layer2.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                       ^ +\n\t\t-   %518 : int = prim::Constant[value=816](), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t+   %421 : int = prim::Constant[value=816](), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t+   %422 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %423 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %424 : Tensor = prim::Constant[value={0}](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %519 : int = prim::Constant[value=2](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t?     ^^^^^^^^                                                                                                                                                                                                                                                                ^^\n\t\t+   %425 : int = prim::Constant[value=2](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ++ ^^^^^^                                                                                                                                                                                                                                                                ^^\n\t\t-   %520 : int = prim::Constant[value=3](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %521 : Tensor = prim::Constant[value={-2}](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %522 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %523 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %524 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %525 : int = prim::Constant[value=288](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^^\n\t\t+   %426 : int = prim::Constant[value=288](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^^\n\t\t-   %526 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t-   %527 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^                                  ^\n\t\t+   %427 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^                                  ^\n\t\t+   %428 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t-   %528 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^ ^^^\n\t\t+   %429 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^ ^^^\n\t\t-   %529 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t+   %430 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t-   %530 : NoneType = prim::Constant(), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^ ^\n\t\t+   %431 : NoneType = prim::Constant(), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^ ^\n\t\t-   %531 : int = prim::Constant[value=1](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %532 : int = prim::Constant[value=0](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^                                ^\n\t\t+   %432 : int = prim::Constant[value=1](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^                                ^\n\t\t+   %433 : int = prim::Constant[value=0](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %533 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^\n\t\t+   %434 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^\n\t\t-   %534 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^\n\t\t+   %435 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ++ ^^\n\t\t-   %535 : int = prim::Constant[value=576](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t+   %436 : int = prim::Constant[value=576](), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t    %_1.11 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"1\"](%layer3)\n\t\t    %_0.13 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"0\"](%layer3)\n\t\t    %_4.3 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"4\"](%_0.13)\n\t\t    %_3.3 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"3\"](%_0.13)\n\t\t    %_2.7 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"2\"](%_0.13)\n\t\t    %_1.7 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"1\"](%_0.13)\n\t\t    %_0.11 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_0.13)\n\t\t    %bn3.13 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.11)\n\t\t    %conv_pwl.13 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.11)\n\t\t    %se.15 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.11)\n\t\t    %act2.15 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.11)\n\t\t    %bn2.15 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.11)\n\t\t    %conv_dw.15 : __torch__.geffnet.conv2d_layers.Conv2dSameExport = prim::GetAttr[name=\"conv_dw\"](%_0.11)\n\t\t    %act1.15 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.11)\n\t\t    %bn1.15 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.11)\n\t\t    %conv_pw.15 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.11)\n\t\t    %weight.413 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.15)\n\t\t-   %553 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t-   %554 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^                                  ^     ^\n\t\t+   %454 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^                                  ^     ^\n\t\t-   %555 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?      -                                ^ ^   ^ ^\n\t\t+   %455 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    +                                  ^ ^   ^ ^\n\t\t-   %556 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^                                  ^     ^\n\t\t+   %456 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t?    ^                                  ^     ^\n\t\t+   %457 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw\n\t\t-   %input.109 : Tensor = aten::_convolution(%input.107, %weight.413, %530, %553, %554, %555, %533, %556, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.109 : Tensor = aten::_convolution(%input.107, %weight.413, %431, %454, %455, %456, %434, %457, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.187 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.15)\n\t\t    %running_mean.187 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.15)\n\t\t    %bias.229 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.15)\n\t\t    %weight.415 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.15)\n\t\t-   %input.111 : Tensor = aten::batch_norm(%input.109, %weight.415, %bias.229, %running_mean.187, %running_var.187, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.111 : Tensor = aten::batch_norm(%input.109, %weight.415, %bias.229, %running_mean.187, %running_var.187, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %x.21 : Tensor = aten::hardtanh_(%input.111, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                 ^^^   ^^^\n\t\t+   %x.21 : Tensor = aten::hardtanh_(%input.111, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                 ^^^   ^^^\n\t\t    %weight.417 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.15)\n\t\t+   %pad.7 : __torch__.torch.nn.modules.padding.ZeroPad2d = prim::GetAttr[name=\"pad\"](%conv_dw.15)\n\t\t-   %565 : int = aten::size(%x.21, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.13 : Tensor = prim::NumToTensor(%565), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %567 : int = aten::size(%x.21, %520), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.15 : Tensor = prim::NumToTensor(%567), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %569 : int = aten::size(%weight.417, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.13 : Tensor = prim::NumToTensor(%569), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %571 : int = aten::size(%weight.417, %520), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.15 : Tensor = prim::NumToTensor(%571), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %573 : Tensor = aten::floor_divide(%i.13, %521), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %574 : Tensor = aten::neg(%573), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %575 : Tensor = aten::sub(%574, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %576 : Tensor = aten::mul(%575, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %577 : Tensor = aten::sub(%k.13, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %578 : Tensor = aten::mul(%577, %522), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %579 : Tensor = aten::add(%576, %578, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %580 : Tensor = aten::add(%579, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_h.7 : Tensor = aten::sub(%580, %i.13, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %582 : Tensor = aten::floor_divide(%i.15, %521), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %583 : Tensor = aten::neg(%582), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %584 : Tensor = aten::sub(%583, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %585 : Tensor = aten::mul(%584, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %586 : Tensor = aten::sub(%k.15, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %587 : Tensor = aten::mul(%586, %522), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %588 : Tensor = aten::add(%585, %587, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %589 : Tensor = aten::add(%588, %522, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_w.7 : Tensor = aten::sub(%589, %i.15, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %591 : Tensor = aten::floor_divide(%pad_w.7, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %592 : int = aten::Int(%591), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %593 : Tensor = aten::floor_divide(%pad_w.7, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %594 : Tensor = aten::sub(%pad_w.7, %593, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %595 : int = aten::Int(%594), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %596 : Tensor = aten::floor_divide(%pad_h.7, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %597 : int = aten::Int(%596), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    ^^                     ^^^\n\t\t+   %467 : int = aten::Int(%424), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad\n\t\t?    ^^                     ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %598 : Tensor = aten::floor_divide(%pad_h.7, %523), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %599 : Tensor = aten::sub(%pad_h.7, %598, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %600 : int = aten::Int(%599), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?     ^^^^^^^^              ^^^\n\t\t+   %468 : int = aten::Int(%423), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad\n\t\t?    + ^^^^^^^              ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t+   %469 : int = aten::Int(%424), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad\n\t\t+   %470 : int = aten::Int(%423), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad\n\t\t-   %601 : int[] = prim::ListConstruct(%592, %595, %597, %600), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    ^^                                 ^ ^^^^^^^^^^^^ -----\n\t\t+   %471 : int[] = prim::ListConstruct(%467, %468, %469, %470), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad\n\t\t?    ^^                                 ^^^^^^^^^^^^^^ ^^^^                                                                                                                                         +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %x.23 : Tensor = aten::pad(%x.21, %601, %524, %526), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?                                      ^^    ^^^   ^^^\n\t\t+   %x.23 : Tensor = aten::pad(%x.21, %471, %422, %427), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw/__module.pretrained.layer3.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?                                      ^^    ^^^   ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %603 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    ^^                                  --    --\n\t\t+   %473 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    ^^                                 ++    ++\n\t\t+   %474 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %604 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    --                                 ^     ^\n\t\t+   %475 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?     ++                                ^     ^\n\t\t-   %605 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?     --                                ^ ^   ^ ^\n\t\t+   %476 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t?    ++                                 ^ ^   ^ ^\n\t\t-   %606 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw\n\t\t-   %input.113 : Tensor = aten::_convolution(%x.23, %weight.417, %530, %603, %604, %605, %533, %606, %525, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                  ^^^^^ ^^^^^ ^^^^^^^     --------------------------------------\n\t\t+   %input.113 : Tensor = aten::_convolution(%x.23, %weight.417, %431, %473, %474, %475, %434, %476, %426, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                 ++++++++++++++++++++ ^^^^^^^^^^^ ^^^^^ ^^^^^^^^^^^^^^^^^    ++\n\t\t    %running_var.189 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.15)\n\t\t    %running_mean.189 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.15)\n\t\t    %bias.231 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.15)\n\t\t    %weight.419 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.15)\n\t\t-   %input.115 : Tensor = aten::batch_norm(%input.113, %weight.419, %bias.231, %running_mean.189, %running_var.189, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.115 : Tensor = aten::batch_norm(%input.113, %weight.419, %bias.231, %running_mean.189, %running_var.189, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.117 : Tensor = aten::hardtanh_(%input.115, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.117 : Tensor = aten::hardtanh_(%input.115, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.421 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.13)\n\t\t-   %615 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t-   %616 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t-   %617 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t-   %618 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t?    ^^                                 ^     ^\n\t\t+   %485 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t?    ^ +                                ^     ^\n\t\t+   %486 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t+   %487 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t+   %488 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl\n\t\t-   %input.119 : Tensor = aten::_convolution(%input.117, %weight.421, %530, %615, %616, %617, %533, %618, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ^^^^^ ^    ^^^^^^^^^^^^ --------------------------------------\n\t\t+   %input.119 : Tensor = aten::_convolution(%input.117, %weight.421, %431, %485, %486, %487, %434, %488, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ++++++++ ^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^\n\t\t    %running_var.191 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.13)\n\t\t    %running_mean.191 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.13)\n\t\t    %bias.233 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.13)\n\t\t    %weight.423 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.13)\n\t\t-   %input.121 : Tensor = aten::batch_norm(%input.119, %weight.423, %bias.233, %running_mean.191, %running_var.191, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.121 : Tensor = aten::batch_norm(%input.119, %weight.423, %bias.233, %running_mean.191, %running_var.191, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.0/__module.pretrained.layer3.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %bn3.15 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_1.7)\n\t\t    %conv_pwl.15 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_1.7)\n\t\t    %se.17 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_1.7)\n\t\t    %act2.17 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_1.7)\n\t\t    %bn2.17 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.7)\n\t\t    %conv_dw.17 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_1.7)\n\t\t    %act1.17 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_1.7)\n\t\t    %bn1.17 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.7)\n\t\t    %conv_pw.17 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_1.7)\n\t\t    %weight.425 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.17)\n\t\t-   %635 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t-   %636 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %505 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %637 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?     --                                ^ ^   ^ ^\n\t\t+   %506 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?    ++                                 ^ ^   ^ ^\n\t\t-   %638 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %507 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %input.123 : Tensor = aten::_convolution(%input.121, %weight.425, %530, %635, %636, %637, %533, %638, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %508 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw\n\t\t+   %input.123 : Tensor = aten::_convolution(%input.121, %weight.425, %431, %505, %506, %507, %434, %508, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.193 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.17)\n\t\t    %running_mean.193 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.17)\n\t\t    %bias.235 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.17)\n\t\t    %weight.427 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.17)\n\t\t-   %input.125 : Tensor = aten::batch_norm(%input.123, %weight.427, %bias.235, %running_mean.193, %running_var.193, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.125 : Tensor = aten::batch_norm(%input.123, %weight.427, %bias.235, %running_mean.193, %running_var.193, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.127 : Tensor = aten::hardtanh_(%input.125, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.127 : Tensor = aten::hardtanh_(%input.125, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.429 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.17)\n\t\t-   %647 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t-   %648 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t-   %649 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t-   %650 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t?    - ^                                ^     ^\n\t\t+   %517 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t?     ^^                                ^     ^\n\t\t-   %input.129 : Tensor = aten::_convolution(%input.127, %weight.429, %530, %647, %648, %649, %533, %650, %535, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %518 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t+   %519 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t+   %520 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw\n\t\t+   %input.129 : Tensor = aten::_convolution(%input.127, %weight.429, %431, %517, %518, %519, %434, %520, %436, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.195 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.17)\n\t\t    %running_mean.195 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.17)\n\t\t    %bias.237 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.17)\n\t\t    %weight.431 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.17)\n\t\t-   %input.131 : Tensor = aten::batch_norm(%input.129, %weight.431, %bias.237, %running_mean.195, %running_var.195, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.131 : Tensor = aten::batch_norm(%input.129, %weight.431, %bias.237, %running_mean.195, %running_var.195, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.133 : Tensor = aten::hardtanh_(%input.131, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.133 : Tensor = aten::hardtanh_(%input.131, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.433 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.15)\n\t\t-   %659 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t-   %660 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t-   %661 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t-   %662 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t?    ^^                                 ^     ^\n\t\t+   %529 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t?    ^ +                                ^     ^\n\t\t-   %input.135 : Tensor = aten::_convolution(%input.133, %weight.433, %530, %659, %660, %661, %533, %662, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %530 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t+   %531 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t+   %532 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl\n\t\t+   %input.135 : Tensor = aten::_convolution(%input.133, %weight.433, %431, %529, %530, %531, %434, %532, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.197 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.15)\n\t\t    %running_mean.197 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.15)\n\t\t    %bias.239 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.15)\n\t\t    %weight.435 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.15)\n\t\t-   %x.25 : Tensor = aten::batch_norm(%input.135, %weight.435, %bias.239, %running_mean.197, %running_var.197, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.25 : Tensor = aten::batch_norm(%input.135, %weight.435, %bias.239, %running_mean.197, %running_var.197, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1/__module.pretrained.layer3.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.137 : Tensor = aten::add_(%x.25, %input.121, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.137 : Tensor = aten::add_(%x.25, %input.121, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.17 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_2.7)\n\t\t    %conv_pwl.17 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_2.7)\n\t\t    %se.19 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_2.7)\n\t\t    %act2.19 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_2.7)\n\t\t    %bn2.19 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_2.7)\n\t\t    %conv_dw.19 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_2.7)\n\t\t    %act1.19 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_2.7)\n\t\t    %bn1.19 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_2.7)\n\t\t    %conv_pw.19 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_2.7)\n\t\t    %weight.437 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.19)\n\t\t-   %680 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t-   %681 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %550 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %682 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %551 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %683 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %552 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %input.139 : Tensor = aten::_convolution(%input.137, %weight.437, %530, %680, %681, %682, %533, %683, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %553 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw\n\t\t+   %input.139 : Tensor = aten::_convolution(%input.137, %weight.437, %431, %550, %551, %552, %434, %553, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.199 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.19)\n\t\t    %running_mean.199 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.19)\n\t\t    %bias.241 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.19)\n\t\t    %weight.439 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.19)\n\t\t-   %input.141 : Tensor = aten::batch_norm(%input.139, %weight.439, %bias.241, %running_mean.199, %running_var.199, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.141 : Tensor = aten::batch_norm(%input.139, %weight.439, %bias.241, %running_mean.199, %running_var.199, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.143 : Tensor = aten::hardtanh_(%input.141, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.143 : Tensor = aten::hardtanh_(%input.141, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.441 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.19)\n\t\t-   %692 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t-   %693 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t-   %694 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t-   %695 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t?     ^^                                ^     ^\n\t\t+   %562 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t?    + ^                                ^     ^\n\t\t-   %input.145 : Tensor = aten::_convolution(%input.143, %weight.441, %530, %692, %693, %694, %533, %695, %535, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %563 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t+   %564 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t+   %565 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw\n\t\t+   %input.145 : Tensor = aten::_convolution(%input.143, %weight.441, %431, %562, %563, %564, %434, %565, %436, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.201 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.19)\n\t\t    %running_mean.201 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.19)\n\t\t    %bias.243 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.19)\n\t\t    %weight.443 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.19)\n\t\t-   %input.147 : Tensor = aten::batch_norm(%input.145, %weight.443, %bias.243, %running_mean.201, %running_var.201, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.147 : Tensor = aten::batch_norm(%input.145, %weight.443, %bias.243, %running_mean.201, %running_var.201, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.149 : Tensor = aten::hardtanh_(%input.147, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.149 : Tensor = aten::hardtanh_(%input.147, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.445 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.17)\n\t\t-   %704 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t-   %705 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?     ^^                                ^     ^\n\t\t+   %574 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?    + ^                                ^     ^\n\t\t-   %706 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?     ^^                                ^ ^   ^ ^\n\t\t+   %575 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?    + ^                                ^ ^   ^ ^\n\t\t-   %707 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?     ^^                                ^     ^\n\t\t+   %576 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t?    + ^                                ^     ^\n\t\t-   %input.151 : Tensor = aten::_convolution(%input.149, %weight.445, %530, %704, %705, %706, %533, %707, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %577 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl\n\t\t+   %input.151 : Tensor = aten::_convolution(%input.149, %weight.445, %431, %574, %575, %576, %434, %577, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.203 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.17)\n\t\t    %running_mean.203 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.17)\n\t\t    %bias.245 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.17)\n\t\t    %weight.447 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.17)\n\t\t-   %x.27 : Tensor = aten::batch_norm(%input.151, %weight.447, %bias.245, %running_mean.203, %running_var.203, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.27 : Tensor = aten::batch_norm(%input.151, %weight.447, %bias.245, %running_mean.203, %running_var.203, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2/__module.pretrained.layer3.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.153 : Tensor = aten::add_(%x.27, %input.137, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.153 : Tensor = aten::add_(%x.27, %input.137, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.19 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_3.3)\n\t\t    %conv_pwl.19 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_3.3)\n\t\t    %se.21 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_3.3)\n\t\t    %act2.21 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_3.3)\n\t\t    %bn2.21 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_3.3)\n\t\t    %conv_dw.21 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_3.3)\n\t\t    %act1.21 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_3.3)\n\t\t    %bn1.21 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_3.3)\n\t\t    %conv_pw.21 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_3.3)\n\t\t    %weight.449 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.21)\n\t\t-   %725 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?    --                                 ^ ^   ^ ^\n\t\t+   %595 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?     ++                                ^ ^   ^ ^\n\t\t+   %596 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t-   %726 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?     --                                ^     ^\n\t\t+   %597 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?    ++                                 ^     ^\n\t\t-   %727 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t-   %728 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t+   %598 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t-   %input.155 : Tensor = aten::_convolution(%input.153, %weight.449, %530, %725, %726, %727, %533, %728, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.155 : Tensor = aten::_convolution(%input.153, %weight.449, %431, %595, %596, %597, %434, %598, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.205 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.21)\n\t\t    %running_mean.205 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.21)\n\t\t    %bias.247 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.21)\n\t\t    %weight.451 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.21)\n\t\t-   %input.157 : Tensor = aten::batch_norm(%input.155, %weight.451, %bias.247, %running_mean.205, %running_var.205, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.157 : Tensor = aten::batch_norm(%input.155, %weight.451, %bias.247, %running_mean.205, %running_var.205, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.159 : Tensor = aten::hardtanh_(%input.157, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.159 : Tensor = aten::hardtanh_(%input.157, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.453 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.21)\n\t\t-   %737 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t-   %738 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t-   %739 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t-   %740 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t?     --                                ^     ^\n\t\t+   %607 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t?    ++                                 ^     ^\n\t\t+   %608 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t+   %609 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t+   %610 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw\n\t\t-   %input.161 : Tensor = aten::_convolution(%input.159, %weight.453, %530, %737, %738, %739, %533, %740, %535, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^ ^^^^^^^    ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.161 : Tensor = aten::_convolution(%input.159, %weight.453, %431, %607, %608, %609, %434, %610, %436, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^ ^^^^^    ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.207 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.21)\n\t\t    %running_mean.207 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.21)\n\t\t    %bias.249 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.21)\n\t\t    %weight.455 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.21)\n\t\t-   %input.163 : Tensor = aten::batch_norm(%input.161, %weight.455, %bias.249, %running_mean.207, %running_var.207, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.163 : Tensor = aten::batch_norm(%input.161, %weight.455, %bias.249, %running_mean.207, %running_var.207, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.165 : Tensor = aten::hardtanh_(%input.163, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.165 : Tensor = aten::hardtanh_(%input.163, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.457 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.19)\n\t\t-   %749 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t-   %750 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %619 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t-   %751 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %620 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %752 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^^                                 ^     ^\n\t\t+   %621 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t?    ^ +                                ^     ^\n\t\t+   %622 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl\n\t\t-   %input.167 : Tensor = aten::_convolution(%input.165, %weight.457, %530, %749, %750, %751, %533, %752, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.167 : Tensor = aten::_convolution(%input.165, %weight.457, %431, %619, %620, %621, %434, %622, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.209 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.19)\n\t\t    %running_mean.209 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.19)\n\t\t    %bias.251 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.19)\n\t\t    %weight.459 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.19)\n\t\t-   %x.29 : Tensor = aten::batch_norm(%input.167, %weight.459, %bias.251, %running_mean.209, %running_var.209, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.29 : Tensor = aten::batch_norm(%input.167, %weight.459, %bias.251, %running_mean.209, %running_var.209, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3/__module.pretrained.layer3.0.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.169 : Tensor = aten::add_(%x.29, %input.153, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.169 : Tensor = aten::add_(%x.29, %input.153, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.21 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_4.3)\n\t\t    %conv_pwl.21 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_4.3)\n\t\t    %se.23 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_4.3)\n\t\t    %act2.23 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_4.3)\n\t\t    %bn2.23 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_4.3)\n\t\t    %conv_dw.23 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_4.3)\n\t\t    %act1.23 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_4.3)\n\t\t    %bn1.23 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_4.3)\n\t\t    %conv_pw.23 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_4.3)\n\t\t    %weight.461 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.23)\n\t\t-   %770 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t-   %771 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %640 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %772 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %641 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %773 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %642 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %input.171 : Tensor = aten::_convolution(%input.169, %weight.461, %530, %770, %771, %772, %533, %773, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %643 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw\n\t\t+   %input.171 : Tensor = aten::_convolution(%input.169, %weight.461, %431, %640, %641, %642, %434, %643, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.211 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.23)\n\t\t    %running_mean.211 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.23)\n\t\t    %bias.253 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.23)\n\t\t    %weight.463 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.23)\n\t\t-   %input.173 : Tensor = aten::batch_norm(%input.171, %weight.463, %bias.253, %running_mean.211, %running_var.211, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.173 : Tensor = aten::batch_norm(%input.171, %weight.463, %bias.253, %running_mean.211, %running_var.211, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.175 : Tensor = aten::hardtanh_(%input.173, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.175 : Tensor = aten::hardtanh_(%input.173, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.465 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.23)\n\t\t-   %782 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t-   %783 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t-   %784 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t-   %785 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t?    ^^                                 ^     ^\n\t\t+   %652 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t?    ^ +                                ^     ^\n\t\t-   %input.177 : Tensor = aten::_convolution(%input.175, %weight.465, %530, %782, %783, %784, %533, %785, %535, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %653 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t+   %654 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t+   %655 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw\n\t\t+   %input.177 : Tensor = aten::_convolution(%input.175, %weight.465, %431, %652, %653, %654, %434, %655, %436, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.213 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.23)\n\t\t    %running_mean.213 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.23)\n\t\t    %bias.255 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.23)\n\t\t    %weight.467 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.23)\n\t\t-   %input.179 : Tensor = aten::batch_norm(%input.177, %weight.467, %bias.255, %running_mean.213, %running_var.213, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.179 : Tensor = aten::batch_norm(%input.177, %weight.467, %bias.255, %running_mean.213, %running_var.213, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.181 : Tensor = aten::hardtanh_(%input.179, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.181 : Tensor = aten::hardtanh_(%input.179, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.469 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.21)\n\t\t-   %794 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t-   %795 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %664 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t-   %796 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?    --                                 ^ ^   ^ ^\n\t\t+   %665 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?     ++                                ^ ^   ^ ^\n\t\t-   %797 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %666 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t-   %input.183 : Tensor = aten::_convolution(%input.181, %weight.469, %530, %794, %795, %796, %533, %797, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %667 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl\n\t\t+   %input.183 : Tensor = aten::_convolution(%input.181, %weight.469, %431, %664, %665, %666, %434, %667, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.215 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.21)\n\t\t    %running_mean.215 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.21)\n\t\t    %bias.257 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.21)\n\t\t    %weight.471 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.21)\n\t\t-   %x.31 : Tensor = aten::batch_norm(%input.183, %weight.471, %bias.257, %running_mean.215, %running_var.215, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.31 : Tensor = aten::batch_norm(%input.183, %weight.471, %bias.257, %running_mean.215, %running_var.215, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4/__module.pretrained.layer3.0.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.185 : Tensor = aten::add_(%x.31, %input.169, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.185 : Tensor = aten::add_(%x.31, %input.169, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.0/__module.pretrained.layer3.0.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %_4.5 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"4\"](%_1.11)\n\t\t    %_3.5 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"3\"](%_1.11)\n\t\t    %_2.9 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"2\"](%_1.11)\n\t\t    %_1.9 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"1\"](%_1.11)\n\t\t    %_0.15 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_1.11)\n\t\t    %bn3.23 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.15)\n\t\t    %conv_pwl.23 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.15)\n\t\t    %se.25 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.15)\n\t\t    %act2.25 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.15)\n\t\t    %bn2.25 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.15)\n\t\t    %conv_dw.25 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_0.15)\n\t\t    %act1.25 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.15)\n\t\t    %bn1.25 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.15)\n\t\t    %conv_pw.25 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.15)\n\t\t    %weight.473 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.25)\n\t\t-   %820 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t+   %690 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t+   %691 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t-   %821 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^ -                                ^     ^\n\t\t+   %692 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^^                                 ^     ^\n\t\t-   %822 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t-   %823 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t+   %693 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t-   %input.187 : Tensor = aten::_convolution(%input.185, %weight.473, %530, %820, %821, %822, %533, %823, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.187 : Tensor = aten::_convolution(%input.185, %weight.473, %431, %690, %691, %692, %434, %693, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.217 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.25)\n\t\t    %running_mean.217 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.25)\n\t\t    %bias.259 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.25)\n\t\t    %weight.475 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.25)\n\t\t-   %input.189 : Tensor = aten::batch_norm(%input.187, %weight.475, %bias.259, %running_mean.217, %running_var.217, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.189 : Tensor = aten::batch_norm(%input.187, %weight.475, %bias.259, %running_mean.217, %running_var.217, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.191 : Tensor = aten::hardtanh_(%input.189, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.191 : Tensor = aten::hardtanh_(%input.189, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.477 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.25)\n\t\t-   %832 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t-   %833 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t-   %834 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t-   %835 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t?    ^^^                                ^     ^\n\t\t+   %702 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t?    ^^^                                ^     ^\n\t\t+   %703 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t+   %704 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t+   %705 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw\n\t\t-   %input.193 : Tensor = aten::_convolution(%input.191, %weight.477, %530, %832, %833, %834, %533, %835, %535, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^  ------------------------------\n\t\t+   %input.193 : Tensor = aten::_convolution(%input.191, %weight.477, %431, %702, %703, %704, %434, %705, %436, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ++++++++++++++++++++++++++++++++ ^^^^^^^^^^^^^^^^^^^^^^^ ^^^^\n\t\t    %running_var.219 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.25)\n\t\t    %running_mean.219 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.25)\n\t\t    %bias.261 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.25)\n\t\t    %weight.479 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.25)\n\t\t-   %input.195 : Tensor = aten::batch_norm(%input.193, %weight.479, %bias.261, %running_mean.219, %running_var.219, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.195 : Tensor = aten::batch_norm(%input.193, %weight.479, %bias.261, %running_mean.219, %running_var.219, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.197 : Tensor = aten::hardtanh_(%input.195, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.197 : Tensor = aten::hardtanh_(%input.195, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.481 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.23)\n\t\t-   %844 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t-   %845 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?    ^ -                                ^     ^\n\t\t+   %714 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?    ^^                                 ^     ^\n\t\t-   %846 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %715 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %847 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?    --                                 ^     ^\n\t\t+   %716 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t?     ++                                ^     ^\n\t\t-   %input.199 : Tensor = aten::_convolution(%input.197, %weight.481, %530, %844, %845, %846, %533, %847, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %717 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl\n\t\t+   %input.199 : Tensor = aten::_convolution(%input.197, %weight.481, %431, %714, %715, %716, %434, %717, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.221 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.23)\n\t\t    %running_mean.221 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.23)\n\t\t    %bias.263 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.23)\n\t\t    %weight.483 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.23)\n\t\t-   %input.201 : Tensor = aten::batch_norm(%input.199, %weight.483, %bias.263, %running_mean.221, %running_var.221, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.201 : Tensor = aten::batch_norm(%input.199, %weight.483, %bias.263, %running_mean.221, %running_var.221, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.0/__module.pretrained.layer3.1.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %bn3.25 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_1.9)\n\t\t    %conv_pwl.25 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_1.9)\n\t\t    %se.27 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_1.9)\n\t\t    %act2.27 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_1.9)\n\t\t    %bn2.27 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.9)\n\t\t    %conv_dw.27 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_1.9)\n\t\t    %act1.27 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_1.9)\n\t\t    %bn1.27 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.9)\n\t\t    %conv_pw.27 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_1.9)\n\t\t    %weight.485 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.27)\n\t\t-   %864 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t-   %865 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t-   %866 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t-   %867 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t?    --                                 ^     ^\n\t\t+   %734 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t?     ++                                ^     ^\n\t\t+   %735 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t+   %736 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t+   %737 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw\n\t\t-   %input.203 : Tensor = aten::_convolution(%input.201, %weight.485, %530, %864, %865, %866, %533, %867, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.203 : Tensor = aten::_convolution(%input.201, %weight.485, %431, %734, %735, %736, %434, %737, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.223 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.27)\n\t\t    %running_mean.223 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.27)\n\t\t    %bias.265 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.27)\n\t\t    %weight.487 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.27)\n\t\t-   %input.205 : Tensor = aten::batch_norm(%input.203, %weight.487, %bias.265, %running_mean.223, %running_var.223, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.205 : Tensor = aten::batch_norm(%input.203, %weight.487, %bias.265, %running_mean.223, %running_var.223, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.207 : Tensor = aten::hardtanh_(%input.205, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.207 : Tensor = aten::hardtanh_(%input.205, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.489 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.27)\n\t\t-   %876 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t-   %877 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t-   %878 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t-   %879 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t?    - ^                                ^     ^\n\t\t+   %746 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t?     ^^                                ^     ^\n\t\t+   %747 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t+   %748 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t+   %749 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw\n\t\t-   %input.209 : Tensor = aten::_convolution(%input.207, %weight.489, %530, %876, %877, %878, %533, %879, %518, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ^^^^^^^^^^^^^^^^^^^^^^^ --------------------------------------\n\t\t+   %input.209 : Tensor = aten::_convolution(%input.207, %weight.489, %431, %746, %747, %748, %434, %749, %421, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ^^^^^\n\t\t    %running_var.225 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.27)\n\t\t    %running_mean.225 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.27)\n\t\t    %bias.267 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.27)\n\t\t    %weight.491 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.27)\n\t\t-   %input.211 : Tensor = aten::batch_norm(%input.209, %weight.491, %bias.267, %running_mean.225, %running_var.225, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.211 : Tensor = aten::batch_norm(%input.209, %weight.491, %bias.267, %running_mean.225, %running_var.225, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.213 : Tensor = aten::hardtanh_(%input.211, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.213 : Tensor = aten::hardtanh_(%input.211, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.493 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.25)\n\t\t-   %888 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t-   %889 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?     --                                ^     ^\n\t\t+   %758 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?    ++                                 ^     ^\n\t\t-   %890 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?    ^ -                                ^ ^   ^ ^\n\t\t+   %759 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t-   %891 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %760 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %761 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl\n\t\t-   %input.215 : Tensor = aten::_convolution(%input.213, %weight.493, %530, %888, %889, %890, %533, %891, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.215 : Tensor = aten::_convolution(%input.213, %weight.493, %431, %758, %759, %760, %434, %761, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.227 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.25)\n\t\t    %running_mean.227 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.25)\n\t\t    %bias.269 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.25)\n\t\t    %weight.495 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.25)\n\t\t-   %x.33 : Tensor = aten::batch_norm(%input.215, %weight.495, %bias.269, %running_mean.227, %running_var.227, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                --------------------\n\t\t+   %x.33 : Tensor = aten::batch_norm(%input.215, %weight.495, %bias.269, %running_mean.227, %running_var.227, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1/__module.pretrained.layer3.1.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                               ++++++++++++++++++++\n\t\t-   %input.217 : Tensor = aten::add_(%x.33, %input.201, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.217 : Tensor = aten::add_(%x.33, %input.201, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.27 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_2.9)\n\t\t    %conv_pwl.27 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_2.9)\n\t\t    %se.29 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_2.9)\n\t\t    %act2.29 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_2.9)\n\t\t    %bn2.29 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_2.9)\n\t\t    %conv_dw.29 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_2.9)\n\t\t    %act1.29 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_2.9)\n\t\t    %bn1.29 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_2.9)\n\t\t    %conv_pw.29 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_2.9)\n\t\t    %weight.497 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.29)\n\t\t-   %909 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t-   %910 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?     --                                ^     ^\n\t\t+   %779 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?    ++                                 ^     ^\n\t\t-   %911 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %780 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %912 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?    ^ -                                ^     ^\n\t\t+   %781 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t?    ^^                                 ^     ^\n\t\t+   %782 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw\n\t\t-   %input.219 : Tensor = aten::_convolution(%input.217, %weight.497, %530, %909, %910, %911, %533, %912, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ^^^^^^^^^^^^^^^^^^^^^^^ --------------------------------------\n\t\t+   %input.219 : Tensor = aten::_convolution(%input.217, %weight.497, %431, %779, %780, %781, %434, %782, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ^^^^^\n\t\t    %running_var.229 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.29)\n\t\t    %running_mean.229 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.29)\n\t\t    %bias.271 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.29)\n\t\t    %weight.499 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.29)\n\t\t-   %input.221 : Tensor = aten::batch_norm(%input.219, %weight.499, %bias.271, %running_mean.229, %running_var.229, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.221 : Tensor = aten::batch_norm(%input.219, %weight.499, %bias.271, %running_mean.229, %running_var.229, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.223 : Tensor = aten::hardtanh_(%input.221, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.223 : Tensor = aten::hardtanh_(%input.221, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.501 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.29)\n\t\t-   %921 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t-   %922 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t-   %923 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t-   %924 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t?     ^^                                ^     ^\n\t\t+   %791 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t?    + ^                                ^     ^\n\t\t+   %792 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t+   %793 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t+   %794 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw\n\t\t-   %input.225 : Tensor = aten::_convolution(%input.223, %weight.501, %530, %921, %922, %923, %533, %924, %518, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^ ^^^^^  ^^^^ ^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.225 : Tensor = aten::_convolution(%input.223, %weight.501, %431, %791, %792, %793, %434, %794, %421, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^ ^^^^^  ^^^^ ^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.231 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.29)\n\t\t    %running_mean.231 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.29)\n\t\t    %bias.273 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.29)\n\t\t    %weight.503 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.29)\n\t\t-   %input.227 : Tensor = aten::batch_norm(%input.225, %weight.503, %bias.273, %running_mean.231, %running_var.231, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.227 : Tensor = aten::batch_norm(%input.225, %weight.503, %bias.273, %running_mean.231, %running_var.231, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.229 : Tensor = aten::hardtanh_(%input.227, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.229 : Tensor = aten::hardtanh_(%input.227, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.505 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.27)\n\t\t-   %933 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t-   %934 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^ -                                ^     ^\n\t\t+   %803 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^^                                 ^     ^\n\t\t-   %935 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t+   %804 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %936 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %805 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %806 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl\n\t\t-   %input.231 : Tensor = aten::_convolution(%input.229, %weight.505, %530, %933, %934, %935, %533, %936, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.231 : Tensor = aten::_convolution(%input.229, %weight.505, %431, %803, %804, %805, %434, %806, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.233 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.27)\n\t\t    %running_mean.233 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.27)\n\t\t    %bias.275 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.27)\n\t\t    %weight.507 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.27)\n\t\t-   %x.35 : Tensor = aten::batch_norm(%input.231, %weight.507, %bias.275, %running_mean.233, %running_var.233, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                --------------------\n\t\t+   %x.35 : Tensor = aten::batch_norm(%input.231, %weight.507, %bias.275, %running_mean.233, %running_var.233, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2/__module.pretrained.layer3.1.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                               ++++++++++++++++++++\n\t\t-   %input.233 : Tensor = aten::add_(%x.35, %input.217, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.233 : Tensor = aten::add_(%x.35, %input.217, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.29 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_3.5)\n\t\t    %conv_pwl.29 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_3.5)\n\t\t    %se.31 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_3.5)\n\t\t    %act2.31 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_3.5)\n\t\t    %bn2.31 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_3.5)\n\t\t    %conv_dw.31 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_3.5)\n\t\t    %act1.31 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_3.5)\n\t\t    %bn1.31 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_3.5)\n\t\t    %conv_pw.31 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_3.5)\n\t\t    %weight.509 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.31)\n\t\t-   %954 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t-   %955 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %824 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %956 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^ -                                ^ ^   ^ ^\n\t\t+   %825 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t-   %957 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t+   %826 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t?    ^^^                                ^     ^\n\t\t-   %input.235 : Tensor = aten::_convolution(%input.233, %weight.509, %530, %954, %955, %956, %533, %957, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %827 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw\n\t\t+   %input.235 : Tensor = aten::_convolution(%input.233, %weight.509, %431, %824, %825, %826, %434, %827, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.235 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.31)\n\t\t    %running_mean.235 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.31)\n\t\t    %bias.277 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.31)\n\t\t    %weight.511 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.31)\n\t\t-   %input.237 : Tensor = aten::batch_norm(%input.235, %weight.511, %bias.277, %running_mean.235, %running_var.235, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ^^^^^^^^^^^^^     ^^^\n\t\t+   %input.237 : Tensor = aten::batch_norm(%input.235, %weight.511, %bias.277, %running_mean.235, %running_var.235, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ^^^^^^^     ^^^^^^^^^\n\t\t-   %input.239 : Tensor = aten::hardtanh_(%input.237, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.239 : Tensor = aten::hardtanh_(%input.237, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.513 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.31)\n\t\t-   %966 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t-   %967 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t-   %968 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t-   %969 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t?    ^ -                                ^     ^\n\t\t+   %836 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t?    ^^                                 ^     ^\n\t\t+   %837 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t+   %838 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t+   %839 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw\n\t\t-   %input.241 : Tensor = aten::_convolution(%input.239, %weight.513, %530, %966, %967, %968, %533, %969, %518, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ^^^^^^^^^^^^^^^^^^^^^^^ --------------------------------------\n\t\t+   %input.241 : Tensor = aten::_convolution(%input.239, %weight.513, %431, %836, %837, %838, %434, %839, %421, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ ^^^^^\n\t\t    %running_var.237 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.31)\n\t\t    %running_mean.237 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.31)\n\t\t    %bias.279 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.31)\n\t\t    %weight.515 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.31)\n\t\t-   %input.243 : Tensor = aten::batch_norm(%input.241, %weight.515, %bias.279, %running_mean.237, %running_var.237, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.243 : Tensor = aten::batch_norm(%input.241, %weight.515, %bias.279, %running_mean.237, %running_var.237, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.245 : Tensor = aten::hardtanh_(%input.243, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.245 : Tensor = aten::hardtanh_(%input.243, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.517 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.29)\n\t\t-   %978 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t-   %979 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t-   %980 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t-   %981 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t?    - ^                                ^     ^\n\t\t+   %848 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t?     ^^                                ^     ^\n\t\t+   %849 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t+   %850 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t+   %851 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl\n\t\t-   %input.247 : Tensor = aten::_convolution(%input.245, %weight.517, %530, %978, %979, %980, %533, %981, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.247 : Tensor = aten::_convolution(%input.245, %weight.517, %431, %848, %849, %850, %434, %851, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.239 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.29)\n\t\t    %running_mean.239 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.29)\n\t\t    %bias.281 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.29)\n\t\t    %weight.519 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.29)\n\t\t-   %x.37 : Tensor = aten::batch_norm(%input.247, %weight.519, %bias.281, %running_mean.239, %running_var.239, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                --------------------\n\t\t+   %x.37 : Tensor = aten::batch_norm(%input.247, %weight.519, %bias.281, %running_mean.239, %running_var.239, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3/__module.pretrained.layer3.1.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                               ++++++++++++++++++++\n\t\t-   %input.249 : Tensor = aten::add_(%x.37, %input.233, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.249 : Tensor = aten::add_(%x.37, %input.233, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t    %bn3.31 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_4.5)\n\t\t    %conv_pwl.31 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_4.5)\n\t\t    %se.33 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_4.5)\n\t\t    %act2.33 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_4.5)\n\t\t    %bn2.33 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_4.5)\n\t\t    %conv_dw.33 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_4.5)\n\t\t    %act1.33 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_4.5)\n\t\t    %bn1.33 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_4.5)\n\t\t    %conv_pw.33 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_4.5)\n\t\t    %weight.521 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.33)\n\t\t-   %999 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?     --                                ^ ^   ^ ^\n\t\t+   %869 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?    ++                                 ^ ^   ^ ^\n\t\t+   %870 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t-   %1000 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?     ---                                ^     ^\n\t\t+   %871 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?    ++                                 ^     ^\n\t\t-   %1001 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t-   %1002 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?    ^^^                                 ^ ^   ^ ^\n\t\t+   %872 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw\n\t\t?    ^^                                 ^ ^   ^ ^\n\t\t-   %input.251 : Tensor = aten::_convolution(%input.249, %weight.521, %530, %999, %1000, %1001, %533, %1002, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.251 : Tensor = aten::_convolution(%input.249, %weight.521, %431, %869, %870, %871, %434, %872, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.241 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.33)\n\t\t    %running_mean.241 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.33)\n\t\t    %bias.283 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.33)\n\t\t    %weight.523 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.33)\n\t\t-   %input.253 : Tensor = aten::batch_norm(%input.251, %weight.523, %bias.283, %running_mean.241, %running_var.241, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                     --------------------\n\t\t+   %input.253 : Tensor = aten::batch_norm(%input.251, %weight.523, %bias.283, %running_mean.241, %running_var.241, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ++++++++++++++++++++\n\t\t-   %input.255 : Tensor = aten::hardtanh_(%input.253, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.255 : Tensor = aten::hardtanh_(%input.253, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.525 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.33)\n\t\t-   %1011 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t-   %1012 : int[] = prim::ListConstruct(%519, %519), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t-   %1013 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t-   %1014 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t?     ---                                ^     ^\n\t\t+   %881 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t?    ++                                 ^     ^\n\t\t+   %882 : int[] = prim::ListConstruct(%425, %425), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t+   %883 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t+   %884 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw\n\t\t-   %input.257 : Tensor = aten::_convolution(%input.255, %weight.525, %530, %1011, %1012, %1013, %533, %1014, %518, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.257 : Tensor = aten::_convolution(%input.255, %weight.525, %431, %881, %882, %883, %434, %884, %421, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.243 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.33)\n\t\t    %running_mean.243 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.33)\n\t\t    %bias.285 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.33)\n\t\t    %weight.527 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.33)\n\t\t-   %input.259 : Tensor = aten::batch_norm(%input.257, %weight.527, %bias.285, %running_mean.243, %running_var.243, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ^^^^^^^^^^^^^     ^^^\n\t\t+   %input.259 : Tensor = aten::batch_norm(%input.257, %weight.527, %bias.285, %running_mean.243, %running_var.243, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                    ^^^^^^^     ^^^^^^^^^\n\t\t-   %input.261 : Tensor = aten::hardtanh_(%input.259, %526, %527), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t+   %input.261 : Tensor = aten::hardtanh_(%input.259, %427, %428), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.529 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.31)\n\t\t-   %1023 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t-   %1024 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^^                                ^     ^\n\t\t+   %893 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t-   %1025 : int[] = prim::ListConstruct(%531, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^^                                ^ ^   ^ ^\n\t\t+   %894 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^                                ^ ^   ^ ^\n\t\t-   %1026 : int[] = prim::ListConstruct(%532, %532), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^^                                ^     ^\n\t\t+   %895 : int[] = prim::ListConstruct(%432, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t?    ^^^                                ^     ^\n\t\t+   %896 : int[] = prim::ListConstruct(%433, %433), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl\n\t\t-   %input.263 : Tensor = aten::_convolution(%input.261, %weight.529, %530, %1023, %1024, %1025, %533, %1026, %531, %533, %533, %534, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.263 : Tensor = aten::_convolution(%input.261, %weight.529, %431, %893, %894, %895, %434, %896, %432, %434, %434, %435, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.245 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.31)\n\t\t    %running_mean.245 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.31)\n\t\t    %bias.287 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.31)\n\t\t    %weight.531 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.31)\n\t\t-   %x.39 : Tensor = aten::batch_norm(%input.263, %weight.531, %bias.287, %running_mean.245, %running_var.245, %533, %528, %529, %534), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                                --------------------\n\t\t+   %x.39 : Tensor = aten::batch_norm(%input.263, %weight.531, %bias.287, %running_mean.245, %running_var.245, %434, %429, %430, %435), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4/__module.pretrained.layer3.1.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?                                                                                                               ++++++++++++++++++++\n\t\t-   %input.265 : Tensor = aten::add_(%x.39, %input.249, %531), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t+   %input.265 : Tensor = aten::add_(%x.39, %input.249, %432), scope: __module.pretrained.layer3/__module.pretrained.layer3.1/__module.pretrained.layer3.1.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        ^^^\n\t\t-   %1034 : int = prim::Constant[value=2](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %1035 : int = prim::Constant[value=3](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t+   %904 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %905 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %1036 : Tensor = prim::Constant[value={-2}](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t?    ^^^                                   ^^                                                                                                                                                                                          ^^^^^^^^^^^ ^^\n\t\t+   %906 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t?    ^^                                   ^                                                                                                                                          +++++++++++++++++++++++++++++++++++++++++++                                                ^^^^^^^^^^^^^^^^^^^ ^\n\t\t-   %1037 : Tensor = prim::Constant[value={1}](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t?    ^^^    ^^^^^^                        ^^^                                                                                                                                                                                                                                      ^^\n\t\t+   %907 : int = prim::Constant[value=2](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^    ^^^                        ^                                                                                                                                                                                                                                      ^^^\n\t\t-   %1038 : Tensor = prim::Constant[value={2}](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1039 : str = prim::Constant[value=\"constant\"](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %1040 : int = prim::Constant[value=816](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^^^\n\t\t+   %908 : int = prim::Constant[value=816](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?    ^^^^^^^^^\n\t\t-   %1041 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^^\n\t\t+   %909 : float = prim::Constant[value=0.](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    ^^^^^\n\t\t-   %1042 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?      ^^^^\n\t\t+   %910 : float = prim::Constant[value=6.](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?    +  ^^\n\t\t-   %1043 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^^\n\t\t+   %911 : float = prim::Constant[value=0.10000000000000001](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    ^^^^^\n\t\t-   %1044 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?     ^^^^^\n\t\t+   %912 : float = prim::Constant[value=0.001](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t?    + ^^^\n\t\t-   %1045 : NoneType = prim::Constant(), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?     ^^^\n\t\t+   %913 : NoneType = prim::Constant(), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    + ^\n\t\t-   %1046 : int = prim::Constant[value=1](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t+   %914 : int = prim::Constant[value=1](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    + ^^^^^^^\n\t\t-   %1047 : int = prim::Constant[value=0](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t+   %915 : int = prim::Constant[value=0](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    + ^^^^^^^\n\t\t-   %1048 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %916 : bool = prim::Constant[value=0](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    + ^^^\n\t\t-   %1049 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %917 : bool = prim::Constant[value=1](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    + ^^^\n\t\t-   %1050 : int = prim::Constant[value=1392](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^^\n\t\t+   %918 : int = prim::Constant[value=1392](), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?    ^^^^^^^^^\n\t\t    %_1.15 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"1\"](%layer4)\n\t\t    %_0.19 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name=\"0\"](%layer4)\n\t\t    %_5.1 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"5\"](%_0.19)\n\t\t    %_4.7 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"4\"](%_0.19)\n\t\t    %_3.7 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"3\"](%_0.19)\n\t\t    %_2.11 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"2\"](%_0.19)\n\t\t    %_1.13 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"1\"](%_0.19)\n\t\t    %_0.17 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_0.19)\n\t\t    %bn3.33 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.17)\n\t\t    %conv_pwl.33 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.17)\n\t\t    %se.35 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.17)\n\t\t    %act2.35 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.17)\n\t\t    %bn2.35 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.17)\n\t\t    %conv_dw.35 : __torch__.geffnet.conv2d_layers.Conv2dSameExport = prim::GetAttr[name=\"conv_dw\"](%_0.17)\n\t\t    %act1.35 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.17)\n\t\t    %bn1.35 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.17)\n\t\t    %conv_pw.35 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.17)\n\t\t    %weight.533 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.35)\n\t\t-   %1069 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    ---                                  - -    - -\n\t\t+   %937 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?     ++                                +     +\n\t\t+   %938 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t-   %1070 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    ^^^^                                 - -    - -\n\t\t+   %939 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    ^^^                                +     +\n\t\t-   %1071 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    ^ --                                 ^^^    ^^^\n\t\t+   %940 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t?    ^^                                 + ^   + ^\n\t\t+   %input.267 : Tensor = aten::_convolution(%input.265, %weight.533, %913, %937, %938, %939, %916, %940, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1072 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw\n\t\t-   %input.267 : Tensor = aten::_convolution(%input.265, %weight.533, %1045, %1069, %1070, %1071, %1048, %1072, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.247 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.35)\n\t\t    %running_mean.247 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.35)\n\t\t    %bias.289 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.35)\n\t\t    %weight.535 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.35)\n\t\t-   %input.269 : Tensor = aten::batch_norm(%input.267, %weight.535, %bias.289, %running_mean.247, %running_var.247, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.269 : Tensor = aten::batch_norm(%input.267, %weight.535, %bias.289, %running_mean.247, %running_var.247, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %x.41 : Tensor = aten::hardtanh_(%input.269, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                 ^^^^   ^^^^\n\t\t+   %x.41 : Tensor = aten::hardtanh_(%input.269, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                 ^^^   ^^^\n\t\t    %weight.537 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.35)\n\t\t+   %pad : __torch__.torch.nn.modules.padding.ZeroPad2d = prim::GetAttr[name=\"pad\"](%conv_dw.35)\n\t\t-   %1081 : int = aten::size(%x.41, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i.17 : Tensor = prim::NumToTensor(%1081), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1083 : int = aten::size(%x.41, %1035), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:104:0\n\t\t-   %i : Tensor = prim::NumToTensor(%1083), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^^^^^^^^   ^^^^^^^^^^^^^^^^^  ^^^^\n\t\t+   %950 : int = aten::Int(%906), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad\n\t\t?    ^^^^^^^^^   ^^^^^^^^^  ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %1085 : int = aten::size(%weight.537, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k.17 : Tensor = prim::NumToTensor(%1085), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1087 : int = aten::size(%weight.537, %1035), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:106:0\n\t\t-   %k : Tensor = prim::NumToTensor(%1087), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1089 : Tensor = aten::floor_divide(%i.17, %1036), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1090 : Tensor = aten::neg(%1089), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1091 : Tensor = aten::sub(%1090, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1092 : Tensor = aten::mul(%1091, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1093 : Tensor = aten::sub(%k.17, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1094 : Tensor = aten::mul(%1093, %1037), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1095 : Tensor = aten::add(%1092, %1094, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1096 : Tensor = aten::add(%1095, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_h : Tensor = aten::sub(%1096, %i.17, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1098 : Tensor = aten::floor_divide(%i, %1036), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1099 : Tensor = aten::neg(%1098), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1100 : Tensor = aten::sub(%1099, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1101 : Tensor = aten::mul(%1100, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1102 : Tensor = aten::sub(%k, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1103 : Tensor = aten::mul(%1102, %1037), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1104 : Tensor = aten::add(%1101, %1103, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1105 : Tensor = aten::add(%1104, %1037, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %pad_w : Tensor = aten::sub(%1105, %i, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:47:0\n\t\t-   %1107 : Tensor = aten::floor_divide(%pad_w, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1108 : int = aten::Int(%1107), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?     ^^^^^^^^^              ^^^^\n\t\t+   %951 : int = aten::Int(%905), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad\n\t\t?    ++ ^^^^^^              ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %1109 : Tensor = aten::floor_divide(%pad_w, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1110 : Tensor = aten::sub(%pad_w, %1109, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %1111 : int = aten::Int(%1110), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^^^^^^^^              ^^^^\n\t\t+   %952 : int = aten::Int(%906), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad\n\t\t?    ^^^^^^^^^              ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t-   %1112 : Tensor = aten::floor_divide(%pad_h, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1113 : int = aten::Int(%1112), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^                     ^^^^\n\t\t+   %953 : int = aten::Int(%905), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad\n\t\t?    ^^                     ^^^                                                                                                                                       +++++++++++++++++++++++++++++++++++++++++++\n\t\t+   %954 : int[] = prim::ListConstruct(%950, %951, %952, %953), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad\n\t\t+   %x.43 : Tensor = aten::pad(%x.41, %954, %904, %909), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw/__module.pretrained.layer4.0.0.conv_dw.pad # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t-   %1114 : Tensor = aten::floor_divide(%pad_h, %1038), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\t\t-   %1115 : Tensor = aten::sub(%pad_h, %1114, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:55:0\n\t\t-   %1116 : int = aten::Int(%1115), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1117 : int[] = prim::ListConstruct(%1108, %1111, %1113, %1116), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^^                                ^^ ^   ^^^^^^^^^^^^^^^^^^\n\t\t+   %956 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^                                ^ ^   ^^^\n\t\t-   %x.43 : Tensor = aten::pad(%x.41, %1117, %1039, %1041), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4495:0\n\t\t+   %957 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1119 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ---                                  --     --\n\t\t+   %958 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?     ++                                +     +\n\t\t-   %1120 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^^                                 ^^^    ^^^\n\t\t+   %959 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t?    ^^^                                + ^   + ^\n\t\t-   %1121 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %1122 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw\n\t\t-   %input.271 : Tensor = aten::_convolution(%x.43, %weight.537, %1045, %1119, %1120, %1121, %1048, %1122, %1040, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^\n\t\t+   %input.271 : Tensor = aten::_convolution(%x.43, %weight.537, %913, %956, %957, %958, %916, %959, %908, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_dw # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py:112:0\n\t\t?                                                                 ^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.249 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.35)\n\t\t    %running_mean.249 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.35)\n\t\t    %bias.291 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.35)\n\t\t    %weight.539 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.35)\n\t\t-   %input.273 : Tensor = aten::batch_norm(%input.271, %weight.539, %bias.291, %running_mean.249, %running_var.249, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.273 : Tensor = aten::batch_norm(%input.271, %weight.539, %bias.291, %running_mean.249, %running_var.249, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.275 : Tensor = aten::hardtanh_(%input.273, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.275 : Tensor = aten::hardtanh_(%input.273, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.541 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.33)\n\t\t-   %1131 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?    ^^^^                                 - -    - -\n\t\t+   %968 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?    ^^^                                +     +\n\t\t+   %969 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t-   %1132 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?    ^^^^                                 - -    - -\n\t\t+   %970 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?    ^^^                                +     +\n\t\t-   %1133 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?     ---                                 ^^^    ^^^\n\t\t+   %971 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t?    ++                                 + ^   + ^\n\t\t+   %input.277 : Tensor = aten::_convolution(%input.275, %weight.541, %913, %968, %969, %970, %916, %971, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1134 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl\n\t\t-   %input.277 : Tensor = aten::_convolution(%input.275, %weight.541, %1045, %1131, %1132, %1133, %1048, %1134, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.251 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.33)\n\t\t    %running_mean.251 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.33)\n\t\t    %bias.293 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.33)\n\t\t    %weight.543 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.33)\n\t\t-   %input.279 : Tensor = aten::batch_norm(%input.277, %weight.543, %bias.293, %running_mean.251, %running_var.251, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.279 : Tensor = aten::batch_norm(%input.277, %weight.543, %bias.293, %running_mean.251, %running_var.251, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.0/__module.pretrained.layer4.0.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t    %bn3.35 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_1.13)\n\t\t    %conv_pwl.35 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_1.13)\n\t\t    %se.37 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_1.13)\n\t\t    %act2.37 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_1.13)\n\t\t    %bn2.37 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_1.13)\n\t\t    %conv_dw.37 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_1.13)\n\t\t    %act1.37 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_1.13)\n\t\t    %bn1.37 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_1.13)\n\t\t    %conv_pw.37 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_1.13)\n\t\t    %weight.545 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.37)\n\t\t-   %1151 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?    ^^^^                                 - -    - -\n\t\t+   %988 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?    ^^^                                +     +\n\t\t+   %989 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t-   %1152 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?    ^^^^                                 - -    - -\n\t\t+   %990 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?    ^^^                                +     +\n\t\t-   %1153 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?     ---                                 ^^^    ^^^\n\t\t+   %991 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t?    ++                                 + ^   + ^\n\t\t-   %1154 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw\n\t\t-   %input.281 : Tensor = aten::_convolution(%input.279, %weight.545, %1045, %1151, %1152, %1153, %1048, %1154, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.281 : Tensor = aten::_convolution(%input.279, %weight.545, %913, %988, %989, %990, %916, %991, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^    ^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.253 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.37)\n\t\t    %running_mean.253 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.37)\n\t\t    %bias.295 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.37)\n\t\t    %weight.547 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.37)\n\t\t-   %input.283 : Tensor = aten::batch_norm(%input.281, %weight.547, %bias.295, %running_mean.253, %running_var.253, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.283 : Tensor = aten::batch_norm(%input.281, %weight.547, %bias.295, %running_mean.253, %running_var.253, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.285 : Tensor = aten::hardtanh_(%input.283, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.285 : Tensor = aten::hardtanh_(%input.283, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.549 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.37)\n\t\t-   %1163 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1000 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t?     ^^^                                +     +\n\t\t-   %1164 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t-   %1165 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t-   %1166 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t?      --                                ^ -    ^ -\n\t\t+   %1001 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t?     ++                                 ^     ^\n\t\t+   %1002 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t+   %1003 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw\n\t\t-   %input.287 : Tensor = aten::_convolution(%input.285, %weight.549, %1045, %1163, %1164, %1165, %1048, %1166, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^      ^  ^^^^^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.287 : Tensor = aten::_convolution(%input.285, %weight.549, %913, %1000, %1001, %1002, %916, %1003, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^  ++++++    ^^^^^^^  ^^^^  ^^^^^^^^^^^^\n\t\t    %running_var.255 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.37)\n\t\t    %running_mean.255 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.37)\n\t\t    %bias.297 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.37)\n\t\t    %weight.551 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.37)\n\t\t-   %input.289 : Tensor = aten::batch_norm(%input.287, %weight.551, %bias.297, %running_mean.255, %running_var.255, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.289 : Tensor = aten::batch_norm(%input.287, %weight.551, %bias.297, %running_mean.255, %running_var.255, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.291 : Tensor = aten::hardtanh_(%input.289, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.291 : Tensor = aten::hardtanh_(%input.289, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.553 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.35)\n\t\t-   %1175 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?      ^^                                 - -    - -\n\t\t+   %1012 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?     + ^                                +     +\n\t\t+   %1013 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t-   %1176 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?      ^^                                 - -    - -\n\t\t+   %1014 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?     + ^                                +     +\n\t\t-   %1177 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?      ^^                                 ^^^    ^^^\n\t\t+   %1015 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t?     + ^                                + ^   + ^\n\t\t-   %1178 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl\n\t\t-   %input.293 : Tensor = aten::_convolution(%input.291, %weight.553, %1045, %1175, %1176, %1177, %1048, %1178, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^    ^  ^^^^^  ---------------------------------------------------------\n\t\t+   %input.293 : Tensor = aten::_convolution(%input.291, %weight.553, %913, %1012, %1013, %1014, %916, %1015, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^  ^^^^\n\t\t    %running_var.257 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.35)\n\t\t    %running_mean.257 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.35)\n\t\t    %bias.299 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.35)\n\t\t    %weight.555 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.35)\n\t\t-   %x.45 : Tensor = aten::batch_norm(%input.293, %weight.555, %bias.299, %running_mean.257, %running_var.257, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.45 : Tensor = aten::batch_norm(%input.293, %weight.555, %bias.299, %running_mean.257, %running_var.257, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1/__module.pretrained.layer4.0.1.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.295 : Tensor = aten::add_(%x.45, %input.279, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                         ^^^\n\t\t+   %input.295 : Tensor = aten::add_(%x.45, %input.279, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.1 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        + ^\n\t\t    %bn3.37 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_2.11)\n\t\t    %conv_pwl.37 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_2.11)\n\t\t    %se.39 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_2.11)\n\t\t    %act2.39 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_2.11)\n\t\t    %bn2.39 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_2.11)\n\t\t    %conv_dw.39 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_2.11)\n\t\t    %act1.39 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_2.11)\n\t\t    %bn1.39 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_2.11)\n\t\t    %conv_pw.39 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_2.11)\n\t\t    %weight.557 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.39)\n\t\t-   %1196 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1033 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                +     +\n\t\t+   %1034 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t-   %1197 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1035 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                +     +\n\t\t-   %1198 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1036 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t?     ^^^                                + ^   + ^\n\t\t+   %input.297 : Tensor = aten::_convolution(%input.295, %weight.557, %913, %1033, %1034, %1035, %916, %1036, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1199 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw\n\t\t-   %input.297 : Tensor = aten::_convolution(%input.295, %weight.557, %1045, %1196, %1197, %1198, %1048, %1199, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.259 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.39)\n\t\t    %running_mean.259 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.39)\n\t\t    %bias.301 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.39)\n\t\t    %weight.559 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.39)\n\t\t-   %input.299 : Tensor = aten::batch_norm(%input.297, %weight.559, %bias.301, %running_mean.259, %running_var.259, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.299 : Tensor = aten::batch_norm(%input.297, %weight.559, %bias.301, %running_mean.259, %running_var.259, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.301 : Tensor = aten::hardtanh_(%input.299, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.301 : Tensor = aten::hardtanh_(%input.299, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.561 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.39)\n\t\t-   %1208 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?     - ^                                 - -    - -\n\t\t+   %1045 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?      ^^                                +     +\n\t\t+   %1046 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t-   %1209 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?     - ^                                 --     --\n\t\t+   %1047 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?      ^^                                +     +\n\t\t-   %1210 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?     --                                  ^^^    ^^^\n\t\t+   %1048 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t?      ++                                + ^   + ^\n\t\t+   %input.303 : Tensor = aten::_convolution(%input.301, %weight.561, %913, %1045, %1046, %1047, %916, %1048, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1211 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw\n\t\t-   %input.303 : Tensor = aten::_convolution(%input.301, %weight.561, %1045, %1208, %1209, %1210, %1048, %1211, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.261 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.39)\n\t\t    %running_mean.261 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.39)\n\t\t    %bias.303 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.39)\n\t\t    %weight.563 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.39)\n\t\t-   %input.305 : Tensor = aten::batch_norm(%input.303, %weight.563, %bias.303, %running_mean.261, %running_var.261, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.305 : Tensor = aten::batch_norm(%input.303, %weight.563, %bias.303, %running_mean.261, %running_var.261, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.307 : Tensor = aten::hardtanh_(%input.305, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.307 : Tensor = aten::hardtanh_(%input.305, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.565 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.37)\n\t\t-   %1220 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?     --                                  - -    - -\n\t\t+   %1057 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?      ++                                +     +\n\t\t+   %1058 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t-   %1221 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1059 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?     ^^^                                +     +\n\t\t-   %1222 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1060 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t?     ^^^                                + ^   + ^\n\t\t+   %input.309 : Tensor = aten::_convolution(%input.307, %weight.565, %913, %1057, %1058, %1059, %916, %1060, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1223 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl\n\t\t-   %input.309 : Tensor = aten::_convolution(%input.307, %weight.565, %1045, %1220, %1221, %1222, %1048, %1223, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.263 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.37)\n\t\t    %running_mean.263 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.37)\n\t\t    %bias.305 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.37)\n\t\t    %weight.567 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.37)\n\t\t-   %x.47 : Tensor = aten::batch_norm(%input.309, %weight.567, %bias.305, %running_mean.263, %running_var.263, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.47 : Tensor = aten::batch_norm(%input.309, %weight.567, %bias.305, %running_mean.263, %running_var.263, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2/__module.pretrained.layer4.0.2.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.311 : Tensor = aten::add_(%x.47, %input.295, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                         ^^^\n\t\t+   %input.311 : Tensor = aten::add_(%x.47, %input.295, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.2 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        + ^\n\t\t    %bn3.39 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_3.7)\n\t\t    %conv_pwl.39 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_3.7)\n\t\t    %se.41 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_3.7)\n\t\t    %act2.41 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_3.7)\n\t\t    %bn2.41 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_3.7)\n\t\t    %conv_dw.41 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_3.7)\n\t\t    %act1.41 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_3.7)\n\t\t    %bn1.41 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_3.7)\n\t\t    %conv_pw.41 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_3.7)\n\t\t    %weight.569 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.41)\n\t\t-   %1241 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1078 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                +     +\n\t\t+   %1079 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t-   %1242 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1080 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                +     +\n\t\t-   %1243 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1081 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t?     ^^^                                + ^   + ^\n\t\t+   %input.313 : Tensor = aten::_convolution(%input.311, %weight.569, %913, %1078, %1079, %1080, %916, %1081, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1244 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw\n\t\t-   %input.313 : Tensor = aten::_convolution(%input.311, %weight.569, %1045, %1241, %1242, %1243, %1048, %1244, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.265 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.41)\n\t\t    %running_mean.265 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.41)\n\t\t    %bias.307 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.41)\n\t\t    %weight.571 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.41)\n\t\t-   %input.315 : Tensor = aten::batch_norm(%input.313, %weight.571, %bias.307, %running_mean.265, %running_var.265, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.315 : Tensor = aten::batch_norm(%input.313, %weight.571, %bias.307, %running_mean.265, %running_var.265, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.317 : Tensor = aten::hardtanh_(%input.315, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.317 : Tensor = aten::hardtanh_(%input.315, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.573 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.41)\n\t\t+   %1090 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t+   %1091 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t-   %1253 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t?      --                                 - -    - -\n\t\t+   %1092 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t?     ++                                 +     +\n\t\t-   %1254 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1093 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t?     ^^^                                + ^   + ^\n\t\t+   %input.319 : Tensor = aten::_convolution(%input.317, %weight.573, %913, %1090, %1091, %1092, %916, %1093, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1255 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t-   %1256 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw\n\t\t-   %input.319 : Tensor = aten::_convolution(%input.317, %weight.573, %1045, %1253, %1254, %1255, %1048, %1256, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.267 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.41)\n\t\t    %running_mean.267 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.41)\n\t\t    %bias.309 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.41)\n\t\t    %weight.575 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.41)\n\t\t-   %input.321 : Tensor = aten::batch_norm(%input.319, %weight.575, %bias.309, %running_mean.267, %running_var.267, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.321 : Tensor = aten::batch_norm(%input.319, %weight.575, %bias.309, %running_mean.267, %running_var.267, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.323 : Tensor = aten::hardtanh_(%input.321, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.323 : Tensor = aten::hardtanh_(%input.321, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.577 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.39)\n\t\t-   %1265 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?      --                                 - -    - -\n\t\t+   %1102 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?     ++                                 +     +\n\t\t+   %1103 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t-   %1266 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1104 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?     ^^^                                +     +\n\t\t-   %1267 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1105 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t?     ^^^                                + ^   + ^\n\t\t-   %1268 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl\n\t\t-   %input.325 : Tensor = aten::_convolution(%input.323, %weight.577, %1045, %1265, %1266, %1267, %1048, %1268, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^    ^^ ^^^^^^ ^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.325 : Tensor = aten::_convolution(%input.323, %weight.577, %913, %1102, %1103, %1104, %916, %1105, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^ ^^^^^ ^^^^^    ^^^\n\t\t    %running_var.269 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.39)\n\t\t    %running_mean.269 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.39)\n\t\t    %bias.311 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.39)\n\t\t    %weight.579 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.39)\n\t\t-   %x.49 : Tensor = aten::batch_norm(%input.325, %weight.579, %bias.311, %running_mean.269, %running_var.269, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.49 : Tensor = aten::batch_norm(%input.325, %weight.579, %bias.311, %running_mean.269, %running_var.269, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3/__module.pretrained.layer4.0.3.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.327 : Tensor = aten::add_(%x.49, %input.311, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                         ^^^\n\t\t+   %input.327 : Tensor = aten::add_(%x.49, %input.311, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.3 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        + ^\n\t\t    %bn3.41 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_4.7)\n\t\t    %conv_pwl.41 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_4.7)\n\t\t    %se.43 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_4.7)\n\t\t    %act2.43 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_4.7)\n\t\t    %bn2.43 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_4.7)\n\t\t    %conv_dw.43 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_4.7)\n\t\t    %act1.43 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_4.7)\n\t\t    %bn1.43 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_4.7)\n\t\t    %conv_pw.43 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_4.7)\n\t\t    %weight.581 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.43)\n\t\t-   %1286 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?      ^^                                 - -    - -\n\t\t+   %1123 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?     + ^                                +     +\n\t\t+   %1124 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t-   %1287 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?      ^^                                 - -    - -\n\t\t+   %1125 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?     + ^                                +     +\n\t\t-   %1288 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?      ^^                                 ^^^    ^^^\n\t\t+   %1126 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t?     + ^                                + ^   + ^\n\t\t+   %input.329 : Tensor = aten::_convolution(%input.327, %weight.581, %913, %1123, %1124, %1125, %916, %1126, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1289 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw\n\t\t-   %input.329 : Tensor = aten::_convolution(%input.327, %weight.581, %1045, %1286, %1287, %1288, %1048, %1289, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.271 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.43)\n\t\t    %running_mean.271 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.43)\n\t\t    %bias.313 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.43)\n\t\t    %weight.583 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.43)\n\t\t-   %input.331 : Tensor = aten::batch_norm(%input.329, %weight.583, %bias.313, %running_mean.271, %running_var.271, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.331 : Tensor = aten::batch_norm(%input.329, %weight.583, %bias.313, %running_mean.271, %running_var.271, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.333 : Tensor = aten::hardtanh_(%input.331, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.333 : Tensor = aten::hardtanh_(%input.331, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.585 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.43)\n\t\t-   %1298 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t-   %1299 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t-   %1300 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t?      ^^                                 - -    - -\n\t\t+   %1135 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t?     + ^                                +     +\n\t\t-   %1301 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t?      ^^                                ^ -    ^ -\n\t\t+   %1136 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t?     + ^                                ^     ^\n\t\t-   %input.335 : Tensor = aten::_convolution(%input.333, %weight.585, %1045, %1298, %1299, %1300, %1048, %1301, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %1137 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t+   %1138 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw\n\t\t+   %input.335 : Tensor = aten::_convolution(%input.333, %weight.585, %913, %1135, %1136, %1137, %916, %1138, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.273 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.43)\n\t\t    %running_mean.273 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.43)\n\t\t    %bias.315 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.43)\n\t\t    %weight.587 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.43)\n\t\t-   %input.337 : Tensor = aten::batch_norm(%input.335, %weight.587, %bias.315, %running_mean.273, %running_var.273, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.337 : Tensor = aten::batch_norm(%input.335, %weight.587, %bias.315, %running_mean.273, %running_var.273, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.339 : Tensor = aten::hardtanh_(%input.337, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.339 : Tensor = aten::hardtanh_(%input.337, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.589 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.41)\n\t\t-   %1310 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?     - ^                                 - -    - -\n\t\t+   %1147 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?      ^^                                +     +\n\t\t+   %1148 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t-   %1311 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?     - ^                                 - -    - -\n\t\t+   %1149 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?      ^^                                +     +\n\t\t-   %1312 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?     - ^                                 ^^^    ^^^\n\t\t+   %1150 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t?      ^^                                + ^   + ^\n\t\t-   %1313 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl\n\t\t-   %input.341 : Tensor = aten::_convolution(%input.339, %weight.589, %1045, %1310, %1311, %1312, %1048, %1313, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.341 : Tensor = aten::_convolution(%input.339, %weight.589, %913, %1147, %1148, %1149, %916, %1150, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^    ^^^^^^^^^^^^^^^\n\t\t    %running_var.275 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.41)\n\t\t    %running_mean.275 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.41)\n\t\t    %bias.317 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.41)\n\t\t    %weight.591 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.41)\n\t\t-   %x.51 : Tensor = aten::batch_norm(%input.341, %weight.591, %bias.317, %running_mean.275, %running_var.275, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.51 : Tensor = aten::batch_norm(%input.341, %weight.591, %bias.317, %running_mean.275, %running_var.275, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4/__module.pretrained.layer4.0.4.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.343 : Tensor = aten::add_(%x.51, %input.327, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                         ^^^\n\t\t+   %input.343 : Tensor = aten::add_(%x.51, %input.327, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.4 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        + ^\n\t\t    %bn3.43 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_5.1)\n\t\t    %conv_pwl.43 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_5.1)\n\t\t    %se.45 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_5.1)\n\t\t    %act2.45 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_5.1)\n\t\t    %bn2.45 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_5.1)\n\t\t    %conv_dw.45 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_5.1)\n\t\t    %act1.45 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_5.1)\n\t\t    %bn1.45 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_5.1)\n\t\t    %conv_pw.45 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_5.1)\n\t\t    %weight.593 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw.45)\n\t\t-   %1331 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?     --                                  - -    - -\n\t\t+   %1168 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?      ++                                +     +\n\t\t+   %1169 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t-   %1332 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1170 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?     ^^^                                +     +\n\t\t-   %1333 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1171 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t?     ^^^                                + ^   + ^\n\t\t+   %input.345 : Tensor = aten::_convolution(%input.343, %weight.593, %913, %1168, %1169, %1170, %916, %1171, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1334 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw\n\t\t-   %input.345 : Tensor = aten::_convolution(%input.343, %weight.593, %1045, %1331, %1332, %1333, %1048, %1334, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.277 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1.45)\n\t\t    %running_mean.277 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1.45)\n\t\t    %bias.319 : Tensor = prim::GetAttr[name=\"bias\"](%bn1.45)\n\t\t    %weight.595 : Tensor = prim::GetAttr[name=\"weight\"](%bn1.45)\n\t\t-   %input.347 : Tensor = aten::batch_norm(%input.345, %weight.595, %bias.319, %running_mean.277, %running_var.277, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.347 : Tensor = aten::batch_norm(%input.345, %weight.595, %bias.319, %running_mean.277, %running_var.277, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.349 : Tensor = aten::hardtanh_(%input.347, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.349 : Tensor = aten::hardtanh_(%input.347, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.597 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw.45)\n\t\t-   %1343 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1180 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t?     ^^^                                +     +\n\t\t-   %1344 : int[] = prim::ListConstruct(%1034, %1034), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t-   %1345 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t-   %1346 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t?     ^^^                                ^ -    ^ -\n\t\t+   %1181 : int[] = prim::ListConstruct(%907, %907), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t?     ^^^                                ^     ^\n\t\t+   %1182 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t+   %1183 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw\n\t\t-   %input.351 : Tensor = aten::_convolution(%input.349, %weight.597, %1045, %1343, %1344, %1345, %1048, %1346, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.351 : Tensor = aten::_convolution(%input.349, %weight.597, %913, %1180, %1181, %1182, %916, %1183, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %running_var.279 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2.45)\n\t\t    %running_mean.279 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2.45)\n\t\t    %bias.321 : Tensor = prim::GetAttr[name=\"bias\"](%bn2.45)\n\t\t    %weight.599 : Tensor = prim::GetAttr[name=\"weight\"](%bn2.45)\n\t\t-   %input.353 : Tensor = aten::batch_norm(%input.351, %weight.599, %bias.321, %running_mean.279, %running_var.279, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.353 : Tensor = aten::batch_norm(%input.351, %weight.599, %bias.321, %running_mean.279, %running_var.279, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.355 : Tensor = aten::hardtanh_(%input.353, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                        ---------\n\t\t+   %input.355 : Tensor = aten::hardtanh_(%input.353, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      +++++++\n\t\t    %weight.601 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl.43)\n\t\t-   %1355 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1192 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^^^                                +     +\n\t\t+   %1193 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t-   %1356 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1194 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^^^                                +     +\n\t\t-   %1357 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^ -                                 ^^^    ^^^\n\t\t+   %1195 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t?     ^^                                 + ^   + ^\n\t\t+   %input.357 : Tensor = aten::_convolution(%input.355, %weight.601, %913, %1192, %1193, %1194, %916, %1195, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1358 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl\n\t\t-   %input.357 : Tensor = aten::_convolution(%input.355, %weight.601, %1045, %1355, %1356, %1357, %1048, %1358, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.281 : Tensor = prim::GetAttr[name=\"running_var\"](%bn3.43)\n\t\t    %running_mean.281 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3.43)\n\t\t    %bias.323 : Tensor = prim::GetAttr[name=\"bias\"](%bn3.43)\n\t\t    %weight.603 : Tensor = prim::GetAttr[name=\"weight\"](%bn3.43)\n\t\t-   %x.53 : Tensor = aten::batch_norm(%input.357, %weight.603, %bias.323, %running_mean.281, %running_var.281, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %x.53 : Tensor = aten::batch_norm(%input.357, %weight.603, %bias.323, %running_mean.281, %running_var.281, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5/__module.pretrained.layer4.0.5.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.359 : Tensor = aten::add_(%x.53, %input.343, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                         ^^^\n\t\t+   %input.359 : Tensor = aten::add_(%x.53, %input.343, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.0/__module.pretrained.layer4.0.5 # /root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/efficientnet_builder.py:250:0\n\t\t?                                                        + ^\n\t\t    %_0.21 : __torch__.geffnet.efficientnet_builder.InvertedResidual = prim::GetAttr[name=\"0\"](%_1.15)\n\t\t    %bn3 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn3\"](%_0.21)\n\t\t    %conv_pwl : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pwl\"](%_0.21)\n\t\t    %se : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"se\"](%_0.21)\n\t\t    %act2 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act2\"](%_0.21)\n\t\t    %bn2 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn2\"](%_0.21)\n\t\t    %conv_dw : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_dw\"](%_0.21)\n\t\t    %act1 : __torch__.torch.nn.modules.activation.ReLU6 = prim::GetAttr[name=\"act1\"](%_0.21)\n\t\t    %bn1 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name=\"bn1\"](%_0.21)\n\t\t    %conv_pw : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv_pw\"](%_0.21)\n\t\t    %weight.605 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pw)\n\t\t-   %1377 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1214 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^^^                                +     +\n\t\t+   %1215 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t-   %1378 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^^^                                 - -    - -\n\t\t+   %1216 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^^^                                +     +\n\t\t-   %1379 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^ -                                 ^^^    ^^^\n\t\t+   %1217 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t?     ^^                                 + ^   + ^\n\t\t+   %input.361 : Tensor = aten::_convolution(%input.359, %weight.605, %913, %1214, %1215, %1216, %916, %1217, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1380 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw\n\t\t-   %input.361 : Tensor = aten::_convolution(%input.359, %weight.605, %1045, %1377, %1378, %1379, %1048, %1380, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.283 : Tensor = prim::GetAttr[name=\"running_var\"](%bn1)\n\t\t    %running_mean.283 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn1)\n\t\t    %bias.325 : Tensor = prim::GetAttr[name=\"bias\"](%bn1)\n\t\t    %weight.607 : Tensor = prim::GetAttr[name=\"weight\"](%bn1)\n\t\t-   %input.363 : Tensor = aten::batch_norm(%input.361, %weight.607, %bias.325, %running_mean.283, %running_var.283, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.363 : Tensor = aten::batch_norm(%input.361, %weight.607, %bias.325, %running_mean.283, %running_var.283, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.365 : Tensor = aten::hardtanh_(%input.363, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.365 : Tensor = aten::hardtanh_(%input.363, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.609 : Tensor = prim::GetAttr[name=\"weight\"](%conv_dw)\n\t\t-   %1389 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t-   %1390 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t-   %1391 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t-   %1392 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t?     --                                  - -    - -\n\t\t+   %1226 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t?      ++                                +     +\n\t\t-   %input.367 : Tensor = aten::_convolution(%input.365, %weight.609, %1045, %1389, %1390, %1391, %1048, %1392, %1050, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %1227 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t+   %1228 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t+   %1229 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw\n\t\t+   %input.367 : Tensor = aten::_convolution(%input.365, %weight.609, %913, %1226, %1227, %1228, %916, %1229, %918, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_dw # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var.285 : Tensor = prim::GetAttr[name=\"running_var\"](%bn2)\n\t\t    %running_mean.285 : Tensor = prim::GetAttr[name=\"running_mean\"](%bn2)\n\t\t    %bias.327 : Tensor = prim::GetAttr[name=\"bias\"](%bn2)\n\t\t    %weight.611 : Tensor = prim::GetAttr[name=\"weight\"](%bn2)\n\t\t-   %input.369 : Tensor = aten::batch_norm(%input.367, %weight.611, %bias.327, %running_mean.285, %running_var.285, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.369 : Tensor = aten::batch_norm(%input.367, %weight.611, %bias.327, %running_mean.285, %running_var.285, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %input.371 : Tensor = aten::hardtanh_(%input.369, %1041, %1042), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^^   ^^^^\n\t\t+   %input.371 : Tensor = aten::hardtanh_(%input.369, %909, %910), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1522:0\n\t\t?                                                      ^^^   ^^^\n\t\t    %weight.613 : Tensor = prim::GetAttr[name=\"weight\"](%conv_pwl)\n\t\t+   %1238 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t+   %1239 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t-   %1401 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t?       -                                 - -    - -\n\t\t+   %1240 : int[] = prim::ListConstruct(%914, %914), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t?     +                                  +     +\n\t\t-   %1402 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t?      ^^                                 ^^^    ^^^\n\t\t+   %1241 : int[] = prim::ListConstruct(%915, %915), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t?     + ^                                + ^   + ^\n\t\t+   %input.373 : Tensor = aten::_convolution(%input.371, %weight.613, %913, %1238, %1239, %1240, %916, %1241, %914, %916, %916, %917, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1403 : int[] = prim::ListConstruct(%1046, %1046), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t-   %1404 : int[] = prim::ListConstruct(%1047, %1047), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl\n\t\t-   %input.373 : Tensor = aten::_convolution(%input.371, %weight.613, %1045, %1401, %1402, %1403, %1048, %1404, %1046, %1048, %1048, %1049, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.conv_pwl # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %running_var : Tensor = prim::GetAttr[name=\"running_var\"](%bn3)\n\t\t    %running_mean : Tensor = prim::GetAttr[name=\"running_mean\"](%bn3)\n\t\t    %bias.329 : Tensor = prim::GetAttr[name=\"bias\"](%bn3)\n\t\t    %weight.615 : Tensor = prim::GetAttr[name=\"weight\"](%bn3)\n\t\t-   %input.375 : Tensor = aten::batch_norm(%input.373, %weight.615, %bias.329, %running_mean, %running_var, %1048, %1043, %1044, %1049), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t+   %input.375 : Tensor = aten::batch_norm(%input.373, %weight.615, %bias.329, %running_mean, %running_var, %916, %911, %912, %917), scope: __module.pretrained.layer4/__module.pretrained.layer4.1/__module.pretrained.layer4.1.0/__module.pretrained.layer4.1.0.bn3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:2482:0\n\t\t-   %1411 : bool = prim::Constant[value=1](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t+   %1248 : bool = prim::Constant[value=1](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     + ^\n\t\t-   %1412 : int = prim::Constant[value=0](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t+   %1249 : int = prim::Constant[value=0](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     + ^\n\t\t-   %1413 : bool = prim::Constant[value=0](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1250 : bool = prim::Constant[value=0](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1414 : int = prim::Constant[value=1](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^ -\n\t\t+   %1251 : int = prim::Constant[value=1](), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^\n\t\t-   %1415 : NoneType = prim::Constant(), scope: __module.scratch.layer1_rn\n\t\t?     ^^\n\t\t+   %1252 : NoneType = prim::Constant(), scope: __module.scratch.layer1_rn\n\t\t?     ^ +\n\t\t    %weight.617 : Tensor = prim::GetAttr[name=\"weight\"](%layer1_rn)\n\t\t-   %1417 : int[] = prim::ListConstruct(%1414, %1414), scope: __module.scratch.layer1_rn\n\t\t?      --                                 ^ -    ^ -\n\t\t+   %1254 : int[] = prim::ListConstruct(%1251, %1251), scope: __module.scratch.layer1_rn\n\t\t?     ++                                  ^^     ^^\n\t\t-   %1418 : int[] = prim::ListConstruct(%1414, %1414), scope: __module.scratch.layer1_rn\n\t\t?     ^^^                                 ^ -    ^ -\n\t\t+   %1255 : int[] = prim::ListConstruct(%1251, %1251), scope: __module.scratch.layer1_rn\n\t\t?     ^^^                                 ^^     ^^\n\t\t-   %1419 : int[] = prim::ListConstruct(%1414, %1414), scope: __module.scratch.layer1_rn\n\t\t?     ^^^                                 ^ -    ^ -\n\t\t+   %1256 : int[] = prim::ListConstruct(%1251, %1251), scope: __module.scratch.layer1_rn\n\t\t?     ^^^                                 ^^     ^^\n\t\t-   %1420 : int[] = prim::ListConstruct(%1412, %1412), scope: __module.scratch.layer1_rn\n\t\t?     - ^                                    ---- ^^\n\t\t+   %1257 : int[] = prim::ListConstruct(%1249, %1249), scope: __module.scratch.layer1_rn\n\t\t?      ^^                                 + ++++   ^\n\t\t-   %input.429 : Tensor = aten::_convolution(%input.61, %weight.617, %1415, %1417, %1418, %1419, %1413, %1420, %1414, %1413, %1413, %1411, %1411), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.429 : Tensor = aten::_convolution(%input.61, %weight.617, %1252, %1254, %1255, %1256, %1250, %1257, %1251, %1250, %1250, %1248, %1248), scope: __module.scratch.layer1_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1422 : bool = prim::Constant[value=1](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     - ^\n\t\t+   %1259 : bool = prim::Constant[value=1](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t-   %1423 : int = prim::Constant[value=0](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     - ^\n\t\t+   %1260 : int = prim::Constant[value=0](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t-   %1424 : bool = prim::Constant[value=0](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     - ^\n\t\t+   %1261 : bool = prim::Constant[value=0](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t-   %1425 : int = prim::Constant[value=1](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     - ^\n\t\t+   %1262 : int = prim::Constant[value=1](), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^\n\t\t-   %1426 : NoneType = prim::Constant(), scope: __module.scratch.layer2_rn\n\t\t?     -\n\t\t+   %1263 : NoneType = prim::Constant(), scope: __module.scratch.layer2_rn\n\t\t?       +\n\t\t    %weight.619 : Tensor = prim::GetAttr[name=\"weight\"](%layer2_rn)\n\t\t+   %1265 : int[] = prim::ListConstruct(%1262, %1262), scope: __module.scratch.layer2_rn\n\t\t+   %1266 : int[] = prim::ListConstruct(%1262, %1262), scope: __module.scratch.layer2_rn\n\t\t+   %1267 : int[] = prim::ListConstruct(%1262, %1262), scope: __module.scratch.layer2_rn\n\t\t-   %1428 : int[] = prim::ListConstruct(%1425, %1425), scope: __module.scratch.layer2_rn\n\t\t?     -                                   - ^    - ^\n\t\t+   %1268 : int[] = prim::ListConstruct(%1260, %1260), scope: __module.scratch.layer2_rn\n\t\t?      +                                   ^^     ^^\n\t\t+   %input.409 : Tensor = aten::_convolution(%input.107, %weight.619, %1263, %1265, %1266, %1267, %1261, %1268, %1262, %1261, %1261, %1259, %1259), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1429 : int[] = prim::ListConstruct(%1425, %1425), scope: __module.scratch.layer2_rn\n\t\t-   %1430 : int[] = prim::ListConstruct(%1425, %1425), scope: __module.scratch.layer2_rn\n\t\t-   %1431 : int[] = prim::ListConstruct(%1423, %1423), scope: __module.scratch.layer2_rn\n\t\t-   %input.409 : Tensor = aten::_convolution(%input.107, %weight.619, %1426, %1428, %1429, %1430, %1424, %1431, %1425, %1424, %1424, %1422, %1422), scope: __module.scratch.layer2_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1433 : bool = prim::Constant[value=1](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1270 : bool = prim::Constant[value=1](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1434 : int = prim::Constant[value=0](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1271 : int = prim::Constant[value=0](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1435 : bool = prim::Constant[value=0](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1272 : bool = prim::Constant[value=0](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1436 : int = prim::Constant[value=1](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^ -\n\t\t+   %1273 : int = prim::Constant[value=1](), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^\n\t\t-   %1437 : NoneType = prim::Constant(), scope: __module.scratch.layer3_rn\n\t\t?      --\n\t\t+   %1274 : NoneType = prim::Constant(), scope: __module.scratch.layer3_rn\n\t\t?     ++\n\t\t    %weight.621 : Tensor = prim::GetAttr[name=\"weight\"](%layer3_rn)\n\t\t-   %1439 : int[] = prim::ListConstruct(%1436, %1436), scope: __module.scratch.layer3_rn\n\t\t-   %1440 : int[] = prim::ListConstruct(%1436, %1436), scope: __module.scratch.layer3_rn\n\t\t-   %1441 : int[] = prim::ListConstruct(%1436, %1436), scope: __module.scratch.layer3_rn\n\t\t-   %1442 : int[] = prim::ListConstruct(%1434, %1434), scope: __module.scratch.layer3_rn\n\t\t?     --                                  ^ -    ^ -\n\t\t+   %1276 : int[] = prim::ListConstruct(%1273, %1273), scope: __module.scratch.layer3_rn\n\t\t?      ++                                 ^^     ^^\n\t\t+   %1277 : int[] = prim::ListConstruct(%1273, %1273), scope: __module.scratch.layer3_rn\n\t\t+   %1278 : int[] = prim::ListConstruct(%1273, %1273), scope: __module.scratch.layer3_rn\n\t\t+   %1279 : int[] = prim::ListConstruct(%1271, %1271), scope: __module.scratch.layer3_rn\n\t\t-   %input.389 : Tensor = aten::_convolution(%input.265, %weight.621, %1437, %1439, %1440, %1441, %1435, %1442, %1436, %1435, %1435, %1433, %1433), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                        ^^^^^^^^     ^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.389 : Tensor = aten::_convolution(%input.265, %weight.621, %1274, %1276, %1277, %1278, %1272, %1279, %1273, %1272, %1272, %1270, %1270), scope: __module.scratch.layer3_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                       ++ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^     ^^^\n\t\t-   %1444 : bool = prim::Constant[value=1](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1281 : bool = prim::Constant[value=1](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1445 : int = prim::Constant[value=0](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1282 : int = prim::Constant[value=0](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1446 : bool = prim::Constant[value=0](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1283 : bool = prim::Constant[value=0](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1447 : int = prim::Constant[value=1](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      --\n\t\t+   %1284 : int = prim::Constant[value=1](), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ++\n\t\t-   %1448 : NoneType = prim::Constant(), scope: __module.scratch.layer4_rn\n\t\t?     ^^\n\t\t+   %1285 : NoneType = prim::Constant(), scope: __module.scratch.layer4_rn\n\t\t?     ^ +\n\t\t    %weight.623 : Tensor = prim::GetAttr[name=\"weight\"](%layer4_rn)\n\t\t-   %1450 : int[] = prim::ListConstruct(%1447, %1447), scope: __module.scratch.layer4_rn\n\t\t-   %1451 : int[] = prim::ListConstruct(%1447, %1447), scope: __module.scratch.layer4_rn\n\t\t-   %1452 : int[] = prim::ListConstruct(%1447, %1447), scope: __module.scratch.layer4_rn\n\t\t?     --                                   --     --\n\t\t+   %1287 : int[] = prim::ListConstruct(%1284, %1284), scope: __module.scratch.layer4_rn\n\t\t?      ++                                 ++     ++\n\t\t-   %1453 : int[] = prim::ListConstruct(%1445, %1445), scope: __module.scratch.layer4_rn\n\t\t?     ^^^                                  --     --\n\t\t+   %1288 : int[] = prim::ListConstruct(%1284, %1284), scope: __module.scratch.layer4_rn\n\t\t?     ^^^                                 ++     ++\n\t\t-   %input.377 : Tensor = aten::_convolution(%input.375, %weight.623, %1448, %1450, %1451, %1452, %1446, %1453, %1447, %1446, %1446, %1444, %1444), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %1289 : int[] = prim::ListConstruct(%1284, %1284), scope: __module.scratch.layer4_rn\n\t\t+   %1290 : int[] = prim::ListConstruct(%1282, %1282), scope: __module.scratch.layer4_rn\n\t\t+   %input.377 : Tensor = aten::_convolution(%input.375, %weight.623, %1285, %1287, %1288, %1289, %1283, %1290, %1284, %1283, %1283, %1281, %1281), scope: __module.scratch.layer4_rn # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1455 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet4 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t+   %1292 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet4 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t-   %1456 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %1293 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t-   %1457 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t+   %1294 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t-   %1458 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^ ^^^\n\t\t+   %1295 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^ ^^\n\t\t-   %1459 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^ ^^^^^^\n\t\t+   %1296 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^ ^^^^^^^\n\t\t-   %1460 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t+   %1297 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t    %out_conv.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"out_conv\"](%refinenet4)\n\t\t    %resConfUnit2.1 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit2\"](%refinenet4)\n\t\t    %skip_add.1 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit2.1)\n\t\t    %activation_post_process.1 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.1)\n\t\t    %conv2.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit2.1)\n\t\t    %conv1.1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit2.1)\n\t\t    %input.379 : Tensor = aten::relu(%input.377), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.331 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.1)\n\t\t    %weight.625 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.1)\n\t\t-   %1470 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t?     ^ -                                 ^^     ^^\n\t\t+   %1307 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t?     ^^                                  ^ +    ^ +\n\t\t+   %1308 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t+   %1309 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t-   %1471 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t?     ^^                                   --     --\n\t\t+   %1310 : int[] = prim::ListConstruct(%1294, %1294), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t?     ^ +                                 ++     ++\n\t\t+   %input.381 : Tensor = aten::_convolution(%input.379, %weight.625, %bias.331, %1307, %1308, %1309, %1295, %1310, %1296, %1295, %1295, %1293, %1293), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1472 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t-   %1473 : int[] = prim::ListConstruct(%1457, %1457), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1\n\t\t-   %input.381 : Tensor = aten::_convolution(%input.379, %weight.625, %bias.331, %1470, %1471, %1472, %1458, %1473, %1459, %1458, %1458, %1456, %1456), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %input.383 : Tensor = aten::relu(%input.381), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.333 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.1)\n\t\t    %weight.627 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.1)\n\t\t+   %1315 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t+   %1316 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t-   %1478 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t?     ^ -                                 ^^     ^^\n\t\t+   %1317 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t?     ^^                                  ^ +    ^ +\n\t\t-   %1479 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t-   %1480 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t?     ^ -                                  --     --\n\t\t+   %1318 : int[] = prim::ListConstruct(%1294, %1294), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t?     ^^                                  ++     ++\n\t\t+   %x.55 : Tensor = aten::_convolution(%input.383, %weight.627, %bias.333, %1315, %1316, %1317, %1295, %1318, %1296, %1295, %1295, %1293, %1293), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1481 : int[] = prim::ListConstruct(%1457, %1457), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2\n\t\t-   %x.55 : Tensor = aten::_convolution(%input.383, %weight.627, %bias.333, %1478, %1479, %1480, %1458, %1481, %1459, %1458, %1458, %1456, %1456), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2/__module.scratch.refinenet4.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %input.385 : Tensor = aten::add(%x.55, %input.377, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                        ^^\n\t\t+   %input.385 : Tensor = aten::add(%x.55, %input.377, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                        ^ +\n\t\t-   %1484 : float[] = prim::ListConstruct(%1455, %1455), scope: __module.scratch.refinenet4\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t+   %1321 : float[] = prim::ListConstruct(%1292, %1292), scope: __module.scratch.refinenet4\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t-   %input.387 : Tensor = aten::upsample_bilinear2d(%input.385, %1460, %1456, %1484), scope: __module.scratch.refinenet4 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^^^\n\t\t+   %input.387 : Tensor = aten::upsample_bilinear2d(%input.385, %1297, %1293, %1321), scope: __module.scratch.refinenet4 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^^^\n\t\t    %bias.335 : Tensor = prim::GetAttr[name=\"bias\"](%out_conv.1)\n\t\t    %weight.629 : Tensor = prim::GetAttr[name=\"weight\"](%out_conv.1)\n\t\t+   %1325 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t+   %1326 : int[] = prim::ListConstruct(%1294, %1294), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t+   %1327 : int[] = prim::ListConstruct(%1296, %1296), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t-   %1488 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t?     ^ -                                  --     --\n\t\t+   %1328 : int[] = prim::ListConstruct(%1294, %1294), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t?     ^^                                  ++     ++\n\t\t+   %x.59 : Tensor = aten::_convolution(%input.387, %weight.629, %bias.335, %1325, %1326, %1327, %1295, %1328, %1296, %1295, %1295, %1293, %1293), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1489 : int[] = prim::ListConstruct(%1457, %1457), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t-   %1490 : int[] = prim::ListConstruct(%1459, %1459), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t-   %1491 : int[] = prim::ListConstruct(%1457, %1457), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv\n\t\t-   %x.59 : Tensor = aten::_convolution(%input.387, %weight.629, %bias.335, %1488, %1489, %1490, %1458, %1491, %1459, %1458, %1458, %1456, %1456), scope: __module.scratch.refinenet4/__module.scratch.refinenet4.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1493 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     --\n\t\t+   %1330 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?      ++\n\t\t-   %1494 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %1331 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t-   %1495 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t+   %1332 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t-   %1496 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %1333 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t-   %1497 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^^^^^^^\n\t\t+   %1334 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ++ ^^^^^^\n\t\t-   %1498 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t+   %1335 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t    %out_conv.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"out_conv\"](%refinenet3)\n\t\t    %resConfUnit2.3 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit2\"](%refinenet3)\n\t\t    %skip_add.5 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%refinenet3)\n\t\t    %activation_post_process.5 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.5)\n\t\t    %resConfUnit1.1 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit1\"](%refinenet3)\n\t\t    %skip_add.3 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit1.1)\n\t\t    %activation_post_process.3 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.3)\n\t\t    %conv2.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit1.1)\n\t\t    %conv1.3 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit1.1)\n\t\t    %input.391 : Tensor = aten::relu(%input.389), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.337 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.3)\n\t\t    %weight.631 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.3)\n\t\t-   %1511 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t-   %1512 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t-   %1513 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t?     --                                   --     --\n\t\t+   %1348 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t?      ++                                 ++     ++\n\t\t-   %1514 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t?     ^^                                   --     --\n\t\t+   %1349 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t?     ^ +                                 ++     ++\n\t\t+   %1350 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t+   %1351 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1\n\t\t-   %input.393 : Tensor = aten::_convolution(%input.391, %weight.631, %bias.337, %1511, %1512, %1513, %1496, %1514, %1497, %1496, %1496, %1494, %1494), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^  ^^^^^ ^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.393 : Tensor = aten::_convolution(%input.391, %weight.631, %bias.337, %1348, %1349, %1350, %1333, %1351, %1334, %1333, %1333, %1331, %1331), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^  ^^^^^ ^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %input.395 : Tensor = aten::relu(%input.393), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.339 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.3)\n\t\t    %weight.633 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.3)\n\t\t-   %1519 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?      ^^                                  --     --\n\t\t+   %1356 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?     + ^                                 ++     ++\n\t\t-   %1520 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?      ^^                                  --     --\n\t\t+   %1357 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?     + ^                                 ++     ++\n\t\t-   %1521 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?      ^^                                  --     --\n\t\t+   %1358 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?     + ^                                 ++     ++\n\t\t-   %1522 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?      ^^                                 ^^^    ^^^\n\t\t+   %1359 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2\n\t\t?     + ^                                 ^^^    ^^^\n\t\t-   %x.57 : Tensor = aten::_convolution(%input.395, %weight.633, %bias.339, %1519, %1520, %1521, %1496, %1522, %1497, %1496, %1496, %1494, %1494), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^     ^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.57 : Tensor = aten::_convolution(%input.395, %weight.633, %bias.339, %1356, %1357, %1358, %1333, %1359, %1334, %1333, %1333, %1331, %1331), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1/__module.scratch.refinenet3.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %y.1 : Tensor = aten::add(%x.57, %input.389, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                   --\n\t\t+   %y.1 : Tensor = aten::add(%x.57, %input.389, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ++\n\t\t-   %input.397 : Tensor = aten::add(%x.59, %y.1, %1497), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                   --\n\t\t+   %input.397 : Tensor = aten::add(%x.59, %y.1, %1334), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ++\n\t\t    %skip_add.7 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit2.3)\n\t\t    %activation_post_process.7 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.7)\n\t\t    %conv2.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit2.3)\n\t\t    %conv1.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit2.3)\n\t\t    %input.399 : Tensor = aten::relu(%input.397), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.341 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.5)\n\t\t    %weight.635 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.5)\n\t\t-   %1533 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?     - ^                                  --     --\n\t\t+   %1370 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?      ^^                                 ++     ++\n\t\t-   %1534 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?     - ^                                  --     --\n\t\t+   %1371 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?      ^^                                 ++     ++\n\t\t-   %1535 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?     - ^                                  --     --\n\t\t+   %1372 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?      ^^                                 ++     ++\n\t\t-   %1536 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?     - ^                                 ^^^    ^^^\n\t\t+   %1373 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1\n\t\t?      ^^                                 ^^^    ^^^\n\t\t-   %input.401 : Tensor = aten::_convolution(%input.399, %weight.635, %bias.341, %1533, %1534, %1535, %1496, %1536, %1497, %1496, %1496, %1494, %1494), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.401 : Tensor = aten::_convolution(%input.399, %weight.635, %bias.341, %1370, %1371, %1372, %1333, %1373, %1334, %1333, %1333, %1331, %1331), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %input.403 : Tensor = aten::relu(%input.401), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.343 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.5)\n\t\t    %weight.637 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.5)\n\t\t-   %1541 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t-   %1542 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t-   %1543 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t?     --                                   --     --\n\t\t+   %1378 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t?      ++                                 ++     ++\n\t\t-   %1544 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t?     ^^^                                  --     --\n\t\t+   %1379 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t?     ^^^                                 ++     ++\n\t\t+   %1380 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t+   %1381 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2\n\t\t-   %x.61 : Tensor = aten::_convolution(%input.403, %weight.637, %bias.343, %1541, %1542, %1543, %1496, %1544, %1497, %1496, %1496, %1494, %1494), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.61 : Tensor = aten::_convolution(%input.403, %weight.637, %bias.343, %1378, %1379, %1380, %1333, %1381, %1334, %1333, %1333, %1331, %1331), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2/__module.scratch.refinenet3.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %input.405 : Tensor = aten::add(%x.61, %input.397, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                         --\n\t\t+   %input.405 : Tensor = aten::add(%x.61, %input.397, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                        ++\n\t\t-   %1547 : float[] = prim::ListConstruct(%1493, %1493), scope: __module.scratch.refinenet3\n\t\t?     ^ -                                   --     --\n\t\t+   %1384 : float[] = prim::ListConstruct(%1330, %1330), scope: __module.scratch.refinenet3\n\t\t?     ^^                                     ++     ++\n\t\t-   %input.407 : Tensor = aten::upsample_bilinear2d(%input.405, %1498, %1494, %1547), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^ -\n\t\t+   %input.407 : Tensor = aten::upsample_bilinear2d(%input.405, %1335, %1331, %1384), scope: __module.scratch.refinenet3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^^\n\t\t    %bias.345 : Tensor = prim::GetAttr[name=\"bias\"](%out_conv.3)\n\t\t    %weight.639 : Tensor = prim::GetAttr[name=\"weight\"](%out_conv.3)\n\t\t-   %1551 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t-   %1552 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t-   %1553 : int[] = prim::ListConstruct(%1497, %1497), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t?     --                                   --     --\n\t\t+   %1388 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t?      ++                                 ++     ++\n\t\t+   %1389 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t-   %1554 : int[] = prim::ListConstruct(%1495, %1495), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t?     ^^^                                  --     --\n\t\t+   %1390 : int[] = prim::ListConstruct(%1334, %1334), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t?     ^^^                                 ++     ++\n\t\t+   %1391 : int[] = prim::ListConstruct(%1332, %1332), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv\n\t\t-   %x.65 : Tensor = aten::_convolution(%input.407, %weight.639, %bias.345, %1551, %1552, %1553, %1496, %1554, %1497, %1496, %1496, %1494, %1494), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.65 : Tensor = aten::_convolution(%input.407, %weight.639, %bias.345, %1388, %1389, %1390, %1333, %1391, %1334, %1333, %1333, %1331, %1331), scope: __module.scratch.refinenet3/__module.scratch.refinenet3.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1556 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t+   %1393 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t-   %1557 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t+   %1394 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^\n\t\t-   %1558 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ^^^^^^^^\n\t\t+   %1395 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ++ ^^^^^^\n\t\t-   %1559 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^ ^^\n\t\t+   %1396 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^ ^^^\n\t\t-   %1560 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t+   %1397 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^^^^^^^\n\t\t-   %1561 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t+   %1398 : NoneType = prim::Constant()\n\t\t?     ^^^\n\t\t    %out_conv.5 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"out_conv\"](%refinenet2)\n\t\t    %resConfUnit2.5 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit2\"](%refinenet2)\n\t\t    %skip_add.11 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%refinenet2)\n\t\t    %activation_post_process.11 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.11)\n\t\t    %resConfUnit1.3 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit1\"](%refinenet2)\n\t\t    %skip_add.9 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit1.3)\n\t\t    %activation_post_process.9 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.9)\n\t\t    %conv2.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit1.3)\n\t\t    %conv1.7 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit1.3)\n\t\t    %input.411 : Tensor = aten::relu(%input.409), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.347 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.7)\n\t\t    %weight.641 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.7)\n\t\t+   %1411 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t+   %1412 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t+   %1413 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t-   %1574 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t?     --                                   --     --\n\t\t+   %1414 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t?      ++                                 ++     ++\n\t\t-   %1575 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t-   %1576 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t-   %1577 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1\n\t\t-   %input.413 : Tensor = aten::_convolution(%input.411, %weight.641, %bias.347, %1574, %1575, %1576, %1559, %1577, %1560, %1559, %1559, %1557, %1557), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.413 : Tensor = aten::_convolution(%input.411, %weight.641, %bias.347, %1411, %1412, %1413, %1396, %1414, %1397, %1396, %1396, %1394, %1394), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %input.415 : Tensor = aten::relu(%input.413), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.349 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.7)\n\t\t    %weight.643 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.7)\n\t\t+   %1419 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t+   %1420 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t+   %1421 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t-   %1582 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t?     ^^                                   --     --\n\t\t+   %1422 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t?     ^ +                                 ++     ++\n\t\t-   %1583 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t-   %1584 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t-   %1585 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2\n\t\t-   %x.63 : Tensor = aten::_convolution(%input.415, %weight.643, %bias.349, %1582, %1583, %1584, %1559, %1585, %1560, %1559, %1559, %1557, %1557), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^     ^^^\n\t\t+   %x.63 : Tensor = aten::_convolution(%input.415, %weight.643, %bias.349, %1419, %1420, %1421, %1396, %1422, %1397, %1396, %1396, %1394, %1394), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1/__module.scratch.refinenet2.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %y.3 : Tensor = aten::add(%x.63, %input.409, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ^^^\n\t\t+   %y.3 : Tensor = aten::add(%x.63, %input.409, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ^^^\n\t\t-   %input.417 : Tensor = aten::add(%x.65, %y.3, %1560), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ^^^\n\t\t+   %input.417 : Tensor = aten::add(%x.65, %y.3, %1397), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                  ^^^\n\t\t    %skip_add.13 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit2.5)\n\t\t    %activation_post_process.13 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.13)\n\t\t    %conv2.9 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit2.5)\n\t\t    %conv1.9 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit2.5)\n\t\t    %input.419 : Tensor = aten::relu(%input.417), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.351 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.9)\n\t\t    %weight.645 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.9)\n\t\t+   %1433 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t+   %1434 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t+   %1435 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t-   %1596 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t?     ^^                                   --     --\n\t\t+   %1436 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t?     ^^                                  ++     ++\n\t\t-   %1597 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t-   %1598 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t-   %1599 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1\n\t\t-   %input.421 : Tensor = aten::_convolution(%input.419, %weight.645, %bias.351, %1596, %1597, %1598, %1559, %1599, %1560, %1559, %1559, %1557, %1557), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                   ^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.421 : Tensor = aten::_convolution(%input.419, %weight.645, %bias.351, %1433, %1434, %1435, %1396, %1436, %1397, %1396, %1396, %1394, %1394), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ++++++++++++++++ ^^^^^^^^^^^^^^^^^^^      ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %input.423 : Tensor = aten::relu(%input.421), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.353 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.9)\n\t\t    %weight.647 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.9)\n\t\t+   %1441 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t+   %1442 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t+   %1443 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t-   %1604 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t?     --                                   --     --\n\t\t+   %1444 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t?      ++                                 ++     ++\n\t\t-   %1605 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t-   %1606 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t-   %1607 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2\n\t\t-   %x.67 : Tensor = aten::_convolution(%input.423, %weight.647, %bias.353, %1604, %1605, %1606, %1559, %1607, %1560, %1559, %1559, %1557, %1557), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.67 : Tensor = aten::_convolution(%input.423, %weight.647, %bias.353, %1441, %1442, %1443, %1396, %1444, %1397, %1396, %1396, %1394, %1394), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2/__module.scratch.refinenet2.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %input.425 : Tensor = aten::add(%x.67, %input.417, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                        ^^^\n\t\t+   %input.425 : Tensor = aten::add(%x.67, %input.417, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                        ^^^\n\t\t-   %1610 : float[] = prim::ListConstruct(%1556, %1556), scope: __module.scratch.refinenet2\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t+   %1447 : float[] = prim::ListConstruct(%1393, %1393), scope: __module.scratch.refinenet2\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t-   %input.427 : Tensor = aten::upsample_bilinear2d(%input.425, %1561, %1557, %1610), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^^^\n\t\t+   %input.427 : Tensor = aten::upsample_bilinear2d(%input.425, %1398, %1394, %1447), scope: __module.scratch.refinenet2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^    ^^^    ^^^\n\t\t    %bias.355 : Tensor = prim::GetAttr[name=\"bias\"](%out_conv.5)\n\t\t    %weight.649 : Tensor = prim::GetAttr[name=\"weight\"](%out_conv.5)\n\t\t+   %1451 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t-   %1614 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t?     --                                   --     --\n\t\t+   %1452 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t?      ++                                 ++     ++\n\t\t+   %1453 : int[] = prim::ListConstruct(%1397, %1397), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t-   %1615 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t?     ^^                                   --     --\n\t\t+   %1454 : int[] = prim::ListConstruct(%1395, %1395), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t?     ^ +                                 ++     ++\n\t\t-   %1616 : int[] = prim::ListConstruct(%1560, %1560), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t-   %1617 : int[] = prim::ListConstruct(%1558, %1558), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv\n\t\t-   %x.71 : Tensor = aten::_convolution(%input.427, %weight.649, %bias.355, %1614, %1615, %1616, %1559, %1617, %1560, %1559, %1559, %1557, %1557), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.71 : Tensor = aten::_convolution(%input.427, %weight.649, %bias.355, %1451, %1452, %1453, %1396, %1454, %1397, %1396, %1396, %1394, %1394), scope: __module.scratch.refinenet2/__module.scratch.refinenet2.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1619 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?      --\n\t\t+   %1456 : float = prim::Constant[value=2.](), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ++\n\t\t+   %1457 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %1458 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %1459 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1620 : bool = prim::Constant[value=1](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      -    ^^^^\n\t\t+   %1460 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     +     ^^^\n\t\t-   %1621 : int = prim::Constant[value=0](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1622 : bool = prim::Constant[value=0](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1623 : int = prim::Constant[value=1](), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1624 : NoneType = prim::Constant()\n\t\t?      ^^\n\t\t+   %1461 : NoneType = prim::Constant()\n\t\t?     + ^\n\t\t    %out_conv : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"out_conv\"](%refinenet1)\n\t\t    %resConfUnit2 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit2\"](%refinenet1)\n\t\t    %skip_add.17 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%refinenet1)\n\t\t    %activation_post_process.17 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.17)\n\t\t    %resConfUnit1 : __torch__.midas.blocks.ResidualConvUnit_custom = prim::GetAttr[name=\"resConfUnit1\"](%refinenet1)\n\t\t    %skip_add.15 : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit1)\n\t\t    %activation_post_process.15 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add.15)\n\t\t    %conv2.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit1)\n\t\t    %conv1.11 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit1)\n\t\t    %input.431 : Tensor = aten::relu(%input.429), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.357 : Tensor = prim::GetAttr[name=\"bias\"](%conv1.11)\n\t\t    %weight.651 : Tensor = prim::GetAttr[name=\"weight\"](%conv1.11)\n\t\t-   %1637 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t?     ^^                                   ^^     ^^\n\t\t+   %1474 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t?     ^ +                                 + ^    + ^\n\t\t-   %1638 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t-   %1639 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t-   %1640 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t?     - ^                                  ^^     ^^\n\t\t+   %1475 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t?      ^^                                 + ^    + ^\n\t\t+   %1476 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t+   %1477 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1\n\t\t-   %input.433 : Tensor = aten::_convolution(%input.431, %weight.651, %bias.357, %1637, %1638, %1639, %1622, %1640, %1623, %1622, %1622, %1620, %1620), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                   ^^^^^^ ^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.433 : Tensor = aten::_convolution(%input.431, %weight.651, %bias.357, %1474, %1475, %1476, %1459, %1477, %1460, %1459, %1459, %1457, %1457), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ++++++++++++++++ ^^^^^^^^^^^^^^^^^^^ ^^^^^^^     ^^^^^^^^^^^^^^^^^\n\t\t    %input.435 : Tensor = aten::relu(%input.433), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.359 : Tensor = prim::GetAttr[name=\"bias\"](%conv2.11)\n\t\t    %weight.653 : Tensor = prim::GetAttr[name=\"weight\"](%conv2.11)\n\t\t-   %1645 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t-   %1646 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t-   %1647 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t-   %1648 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t?     -                                    ^^     ^^\n\t\t+   %1482 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t?       +                                 + ^    + ^\n\t\t+   %1483 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t+   %1484 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t+   %1485 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2\n\t\t-   %x.69 : Tensor = aten::_convolution(%input.435, %weight.653, %bias.359, %1645, %1646, %1647, %1622, %1648, %1623, %1622, %1622, %1620, %1620), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                              ^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x.69 : Tensor = aten::_convolution(%input.435, %weight.653, %bias.359, %1482, %1483, %1484, %1459, %1485, %1460, %1459, %1459, %1457, %1457), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1/__module.scratch.refinenet1.resConfUnit1.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                             ++++++++++++++++++++++++++++++++++++ ^^^^^^^^^^^^^^^^^^^^^     ^^^\n\t\t-   %y : Tensor = aten::add(%x.69, %input.429, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                 ^^\n\t\t+   %y : Tensor = aten::add(%x.69, %input.429, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                + ^\n\t\t-   %input.437 : Tensor = aten::add(%x.71, %y, %1623), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                 ^^\n\t\t+   %input.437 : Tensor = aten::add(%x.71, %y, %1460), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                + ^\n\t\t    %skip_add : __torch__.torch.ao.nn.quantized.modules.functional_modules.FloatFunctional = prim::GetAttr[name=\"skip_add\"](%resConfUnit2)\n\t\t    %activation_post_process : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"activation_post_process\"](%skip_add)\n\t\t    %conv2 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv2\"](%resConfUnit2)\n\t\t    %conv1 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"conv1\"](%resConfUnit2)\n\t\t    %input.439 : Tensor = aten::relu(%input.437), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.361 : Tensor = prim::GetAttr[name=\"bias\"](%conv1)\n\t\t    %weight.655 : Tensor = prim::GetAttr[name=\"weight\"](%conv1)\n\t\t-   %1659 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?      --                                  ^^     ^^\n\t\t+   %1496 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ++                                  + ^    + ^\n\t\t-   %1660 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                  ^^     ^^\n\t\t+   %1497 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                 + ^    + ^\n\t\t-   %1661 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                  ^^     ^^\n\t\t+   %1498 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                 + ^    + ^\n\t\t-   %1662 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1499 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t-   %input.441 : Tensor = aten::_convolution(%input.439, %weight.655, %bias.361, %1659, %1660, %1661, %1622, %1662, %1623, %1622, %1622, %1620, %1620), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.441 : Tensor = aten::_convolution(%input.439, %weight.655, %bias.361, %1496, %1497, %1498, %1459, %1499, %1460, %1459, %1459, %1457, %1457), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t    %input.443 : Tensor = aten::relu(%input.441), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias.363 : Tensor = prim::GetAttr[name=\"bias\"](%conv2)\n\t\t    %weight.657 : Tensor = prim::GetAttr[name=\"weight\"](%conv2)\n\t\t-   %1667 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t-   %1668 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t-   %1669 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t-   %1670 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t?     ^^                                   ^^     ^^\n\t\t+   %1504 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t?     ^ +                                 + ^    + ^\n\t\t+   %1505 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t+   %1506 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t+   %1507 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2\n\t\t-   %x : Tensor = aten::_convolution(%input.443, %weight.657, %bias.363, %1667, %1668, %1669, %1622, %1670, %1623, %1622, %1622, %1620, %1620), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                          ^^     ^^^^^^^^^     ^^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %x : Tensor = aten::_convolution(%input.443, %weight.657, %bias.363, %1504, %1505, %1506, %1459, %1507, %1460, %1459, %1459, %1457, %1457), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2/__module.scratch.refinenet1.resConfUnit2.conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^     ^^^^^^^^^ ^^^^^^^\n\t\t-   %input.445 : Tensor = aten::add(%x, %input.437, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                      ^^\n\t\t+   %input.445 : Tensor = aten::add(%x, %input.437, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.resConfUnit2 # /usr/local/lib/python3.8/dist-packages/torch/ao/nn/quantized/modules/functional_modules.py:45:0\n\t\t?                                                     + ^\n\t\t-   %1673 : float[] = prim::ListConstruct(%1619, %1619), scope: __module.scratch.refinenet1\n\t\t?     ^^^                                    --     --\n\t\t+   %1510 : float[] = prim::ListConstruct(%1456, %1456), scope: __module.scratch.refinenet1\n\t\t?     ^^^                                   ++     ++\n\t\t-   %input.447 : Tensor = aten::upsample_bilinear2d(%input.445, %1624, %1620, %1673), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                  ^^    ^^^    ^^^\n\t\t+   %input.447 : Tensor = aten::upsample_bilinear2d(%input.445, %1461, %1457, %1510), scope: __module.scratch.refinenet1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 + ^    ^^^    ^^^\n\t\t    %bias.365 : Tensor = prim::GetAttr[name=\"bias\"](%out_conv)\n\t\t    %weight.659 : Tensor = prim::GetAttr[name=\"weight\"](%out_conv)\n\t\t+   %1514 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t+   %1515 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t-   %1677 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t?      --                                  ^^     ^^\n\t\t+   %1516 : int[] = prim::ListConstruct(%1460, %1460), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t?     ++                                  + ^    + ^\n\t\t-   %1678 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t?     ^ -                                 ^^^    ^^^\n\t\t+   %1517 : int[] = prim::ListConstruct(%1458, %1458), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t?     ^^                                  ^^^    ^^^\n\t\t-   %1679 : int[] = prim::ListConstruct(%1623, %1623), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t-   %1680 : int[] = prim::ListConstruct(%1621, %1621), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv\n\t\t-   %input.449 : Tensor = aten::_convolution(%input.447, %weight.659, %bias.365, %1677, %1678, %1679, %1622, %1680, %1623, %1622, %1622, %1620, %1620), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.449 : Tensor = aten::_convolution(%input.447, %weight.659, %bias.365, %1514, %1515, %1516, %1459, %1517, %1460, %1459, %1459, %1457, %1457), scope: __module.scratch.refinenet1/__module.scratch.refinenet1.out_conv # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^     ^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t-   %1682 : NoneType = prim::Constant(), scope: __module.scratch.output_conv/__module.scratch.output_conv.1\n\t\t?     ^^^\n\t\t+   %1519 : NoneType = prim::Constant(), scope: __module.scratch.output_conv/__module.scratch.output_conv.1\n\t\t?     ^^^\n\t\t-   %1683 : float = prim::Constant[value=2.](), scope: __module.scratch.output_conv/__module.scratch.output_conv.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t+   %1520 : float = prim::Constant[value=2.](), scope: __module.scratch.output_conv/__module.scratch.output_conv.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?     ^^^\n\t\t-   %1684 : int = prim::Constant[value=1](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1521 : int = prim::Constant[value=1](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1685 : bool = prim::Constant[value=0](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     --\n\t\t+   %1522 : bool = prim::Constant[value=0](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?      ++\n\t\t-   %1686 : int = prim::Constant[value=0](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1523 : int = prim::Constant[value=0](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t-   %1687 : bool = prim::Constant[value=1](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t+   %1524 : bool = prim::Constant[value=1](), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?     ^^^\n\t\t    %_6 : __torch__.torch.nn.modules.linear.Identity = prim::GetAttr[name=\"6\"](%output_conv)\n\t\t    %_5 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name=\"5\"](%output_conv)\n\t\t    %_4 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"4\"](%output_conv)\n\t\t    %_3 : __torch__.torch.nn.modules.activation.ReLU = prim::GetAttr[name=\"3\"](%output_conv)\n\t\t    %_2 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"2\"](%output_conv)\n\t\t    %_1 : __torch__.midas.blocks.Interpolate = prim::GetAttr[name=\"1\"](%output_conv)\n\t\t    %_0 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name=\"0\"](%output_conv)\n\t\t    %bias.367 : Tensor = prim::GetAttr[name=\"bias\"](%_0)\n\t\t    %weight.661 : Tensor = prim::GetAttr[name=\"weight\"](%_0)\n\t\t+   %1534 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t+   %1535 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t-   %1697 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t?      --                                 ^^^    ^^^\n\t\t+   %1536 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t?     ++                                  ^^^    ^^^\n\t\t-   %1698 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t-   %1699 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t-   %1700 : int[] = prim::ListConstruct(%1686, %1686), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t?      --                                 ^^^    ^^^\n\t\t+   %1537 : int[] = prim::ListConstruct(%1523, %1523), scope: __module.scratch.output_conv/__module.scratch.output_conv.0\n\t\t?     ++                                  ^^^    ^^^\n\t\t-   %input.451 : Tensor = aten::_convolution(%input.449, %weight.661, %bias.367, %1697, %1698, %1699, %1685, %1700, %1684, %1685, %1685, %1687, %1687), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t+   %input.451 : Tensor = aten::_convolution(%input.449, %weight.661, %bias.367, %1534, %1535, %1536, %1522, %1537, %1521, %1522, %1522, %1524, %1524), scope: __module.scratch.output_conv/__module.scratch.output_conv.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t-   %1702 : float[] = prim::ListConstruct(%1683, %1683), scope: __module.scratch.output_conv/__module.scratch.output_conv.1\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t+   %1539 : float[] = prim::ListConstruct(%1520, %1520), scope: __module.scratch.output_conv/__module.scratch.output_conv.1\n\t\t?     ^^^                                   ^^^    ^^^\n\t\t-   %input.453 : Tensor = aten::upsample_bilinear2d(%input.451, %1682, %1685, %1702), scope: __module.scratch.output_conv/__module.scratch.output_conv.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^ -------------\n\t\t+   %input.453 : Tensor = aten::upsample_bilinear2d(%input.451, %1519, %1522, %1539), scope: __module.scratch.output_conv/__module.scratch.output_conv.1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:4038:0\n\t\t?                                                                 ^^^^^^^^  +++++++\n\t\t    %bias.369 : Tensor = prim::GetAttr[name=\"bias\"](%_2)\n\t\t    %weight.663 : Tensor = prim::GetAttr[name=\"weight\"](%_2)\n\t\t+   %1543 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t+   %1544 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t+   %1545 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t-   %1706 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t?     ^^                                  ^^^    ^^^\n\t\t+   %1546 : int[] = prim::ListConstruct(%1523, %1523), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t?     ^^                                  ^^^    ^^^\n\t\t-   %1707 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t-   %1708 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t-   %1709 : int[] = prim::ListConstruct(%1686, %1686), scope: __module.scratch.output_conv/__module.scratch.output_conv.2\n\t\t-   %input.455 : Tensor = aten::_convolution(%input.453, %weight.663, %bias.369, %1706, %1707, %1708, %1685, %1709, %1684, %1685, %1685, %1687, %1687), scope: __module.scratch.output_conv/__module.scratch.output_conv.2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input.455 : Tensor = aten::_convolution(%input.453, %weight.663, %bias.369, %1543, %1544, %1545, %1522, %1546, %1521, %1522, %1522, %1524, %1524), scope: __module.scratch.output_conv/__module.scratch.output_conv.2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %input.457 : Tensor = aten::relu(%input.455), scope: __module.scratch.output_conv/__module.scratch.output_conv.3 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1473:0\n\t\t    %bias : Tensor = prim::GetAttr[name=\"bias\"](%_4)\n\t\t    %weight : Tensor = prim::GetAttr[name=\"weight\"](%_4)\n\t\t-   %1714 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^ -                                 ^^^    ^^^\n\t\t+   %1551 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^^                                  ^^^    ^^^\n\t\t-   %1715 : int[] = prim::ListConstruct(%1686, %1686), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     --                                  ^^^    ^^^\n\t\t+   %1552 : int[] = prim::ListConstruct(%1523, %1523), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?      ++                                 ^^^    ^^^\n\t\t-   %1716 : int[] = prim::ListConstruct(%1684, %1684), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1553 : int[] = prim::ListConstruct(%1521, %1521), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t-   %1717 : int[] = prim::ListConstruct(%1686, %1686), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t+   %1554 : int[] = prim::ListConstruct(%1523, %1523), scope: __module.scratch.output_conv/__module.scratch.output_conv.4\n\t\t?     ^^^                                 ^^^    ^^^\n\t\t-   %input : Tensor = aten::_convolution(%input.457, %weight, %bias, %1714, %1715, %1716, %1685, %1717, %1684, %1685, %1685, %1687, %1687), scope: __module.scratch.output_conv/__module.scratch.output_conv.4 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t+   %input : Tensor = aten::_convolution(%input.457, %weight, %bias, %1551, %1552, %1553, %1522, %1554, %1521, %1522, %1522, %1524, %1524), scope: __module.scratch.output_conv/__module.scratch.output_conv.4 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:456:0\n\t\t?                                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n\t\t    %out : Tensor = aten::relu_(%input), scope: __module.scratch.output_conv/__module.scratch.output_conv.5 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1471:0\n\t\t    %44 : int = prim::Constant[value=1]() # /root/.cache/torch/hub/intel-isl_MiDaS_master/midas/midas_net_custom.py:105:0\n\t\t    %45 : Tensor = aten::squeeze(%out, %44) # /root/.cache/torch/hub/intel-isl_MiDaS_master/midas/midas_net_custom.py:105:0\n\t\t    return (%45)\n\tFirst diverging operator:\n\tNode diff:\n\t\t- %scratch : __torch__.torch.nn.modules.module.___torch_mangle_983.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t?                                                              ^^\n\t\t+ %scratch : __torch__.torch.nn.modules.module.___torch_mangle_1320.Module = prim::GetAttr[name=\"scratch\"](%self.1)\n\t\t?                                                              ^ ++\nERROR: Tensor-valued Constant nodes differed in value across invocations. This often indicates that the tracer has encountered untraceable code.\n\tNode:\n\t\t%54 : Tensor = prim::Constant[value={-2}](), scope: __module.pretrained.layer1/__module.pretrained.layer1.0 # /usr/local/lib/python3.8/dist-packages/torch/_tensor.py:974:0\n\tSource Location:\n\t\t/usr/local/lib/python3.8/dist-packages/torch/_tensor.py(974): __floordiv__\n\t\t/usr/local/lib/python3.8/dist-packages/torch/_tensor.py(40): wrapped\n\t\t/root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py(47): _calc_same_pad\n\t\t/root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py(53): _same_pad_arg\n\t\t/root/.cache/torch/hub/rwightman_gen-efficientnet-pytorch_master/geffnet/conv2d_layers.py(106): forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1501): _slow_forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1520): _call_impl\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1511): _wrapped_call_impl\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/container.py(217): forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1501): _slow_forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1520): _call_impl\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1511): _wrapped_call_impl\n\t\t/root/.cache/torch/hub/intel-isl_MiDaS_master/midas/midas_net_custom.py(87): forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1501): _slow_forward\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1520): _call_impl\n\t\t/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py(1511): _wrapped_call_impl\n\t\t/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py(1074): trace_module\n\t\t/usr/local/lib/python3.8/dist-packages/torch/jit/_trace.py(806): trace\n\t\t/tmp/ipykernel_120010/1151187925.py(3): <module>\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3508): run_code\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3448): run_ast_nodes\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3269): run_cell_async\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/async_helpers.py(129): _pseudo_sync_runner\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3064): _run_cell\n\t\t/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py(3009): run_cell\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/zmqshell.py(549): run_cell\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(446): do_execute\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(775): execute_request\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/ipkernel.py(359): execute_request\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(437): dispatch_shell\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(531): process_one\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/kernelbase.py(542): dispatch_queue\n\t\t/usr/lib/python3.8/asyncio/events.py(81): _run\n\t\t/usr/lib/python3.8/asyncio/base_events.py(1859): _run_once\n\t\t/usr/lib/python3.8/asyncio/base_events.py(570): run_forever\n\t\t/usr/local/lib/python3.8/dist-packages/tornado/platform/asyncio.py(205): start\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel/kernelapp.py(739): start\n\t\t/usr/local/lib/python3.8/dist-packages/traitlets/config/application.py(1075): launch_instance\n\t\t/usr/local/lib/python3.8/dist-packages/ipykernel_launcher.py(17): <module>\n\t\t/usr/lib/python3.8/runpy.py(87): _run_code\n\t\t/usr/lib/python3.8/runpy.py(194): _run_module_as_main\n\tComparison exception: \tScalars are not equal!\n\t\t\n\t\tExpected 1 but got -2.\n\t\tAbsolute difference: 3\n\t\tRelative difference: 3.0\n"
     ]
    }
   ],
   "source": [
    "midas = torch.hub.load(\"intel-isl/MiDaS\", \"MiDaS_small\").eval()\n",
    "model: torch.nn.Module = midas.to(device=\"cuda\").eval() \n",
    "torch.jit.trace(model, torch.rand(1, 3, 384, 384, device=device)).save(\"midas_hybrid.pt\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
